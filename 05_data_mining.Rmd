---
title: "ADPStudy"
author: "tingyuan"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
output:
  bookdown::gitbook: default
  #bookdown::pdf_book: default
---
# 정형 데이터마이닝
## 데이터 분할과 성과분석
### 데이터 분할
#### sample
<b>[함수사용법]</b>
```{}
sample(x, size, replace=FALSE, prob...)
```
__Q. credit 데이터를 train, validation, test로 분할해보자.__
```{r}
credit.df<-read.csv("./data/german_credit_dataset.csv", header=TRUE, sep=",")
str(credit.df)

set.seed(1111)
idx<-sample(3, nrow(credit.df), replace=TRUE, prob=c(0.5,0.3,0.2))
train<-credit.df[idx==1,]
validation<-credit.df[idx==2,]
test<-credit.df[idx==3,]
```

```{r}
nrow(train)
nrow(validation)
nrow(test)
```

#### createDataPartition
- caret 패키지에서 목적변수를 고려한 데이터 분리를 지원하며, 함수를 사용해 분리한 데이터는 변수값의 비율이 원본 데이터와 같게 유지된다. 
- <b>[함수사용법]</b>
```{}
createDataPartition(y, times, p, list=TRUE, ...)
```

__Q. credit 데이터를 train, test로 분할해 보자.__
```{r}
install.packages(setdiff("caret", rownames(installed.packages())))
library(caret)
# 목적변수로 credit.rating을 지정, 생성할 데이터 분할은 1개로 지정, 훈련데이터는 70%로 설정
part<-createDataPartition(credit.df$credit.rating, times=1, p=0.7)
parts<-as.vector(part$Resample1)
train<-credit.df[parts,]
test<-credit.df[-parts,]
```

### 성과분석

#### 오분류표 (Confusion Matrix)
##### 개념
- 목표 변수의 <b>실제 범주</b>와 <b>모형에 의해 예측된 분류 범주</b> 사이의 관계를 나타내는 표
- TP (True Positive)<br/>
TN (True Negative)<br/>
FP (False Positive)<br/>
FN (False Negative)

##### 분석 지표
- 정분류율 : 전체 관측치 중 실제값과 예측치가 일치한 정도<br/>
$Accuracy=\frac{TN+TP}{TN+TP+FN+FP}$
- 오분류율 : 전체 관측치 중 실제값과 예측치가 다른 정도<br/>
$1 - Accuracy$
- 민감도 (Sensitivity (TPR: True Positive Rate)) : 실제값이 True인 관측치 중 예측치가 적중한 정도<br/>
$Sensitivity=\frac{TP}{TP+FN}$
- 특이도 (Specificity (TNR: True Negative Rate)) : 실제값이 False인 관측치 중 예측치가 적중한 정도<br/>
$Specificity=\frac{TN}{TN+FP}$
- 정확도 (Precision) : True로 예측된 것 중 실제로 True인 것들의 비율<br/>
$Precision=\frac{TP}{TP+FP}$
- 재현율 (Recall) : 실제 True인 값 중 True를 얼마나 찾았는지에 대한 비율<br/>
$Recall=\frac{TP}{TP+FN} (=Sensitivity)$
- F1-score : 정확도와 재현율을 보정하여 하나의 지표로 나타낸 값<br/>
$F_{1}=2\times \frac{Precision \times Recall}{Precision+Recall}$

- <b>[함수사용법]</b>
```{}
confusionMatrix(data, reference)
```

__Q. 임의의 값을 활용하여 Confusion Matrix를 그려보자.__
```{r}
install.packages(setdiff("caret", rownames(installed.packages())))
library(caret)
predicted<-factor(c(1,0,0,1,1,1,0,0,0,1,1,1))
actual<-factor(c(1,0,0,1,1,0,1,1,0,1,1,1))
xtabs(~predicted + actual)
```

```{r}
sum(predicted==actual)/NROW(actual) # 정분류율을 직접 식으로 계산
confusionMatrix(predicted, actual)
```

#### ROC 그래프
-  ROC 그래프의 x축에는 FP Ratio(1-특이도)를 나타내며, y축에는 민감도를 나타내 이 두 평가값의 관계로 모형을 평가한다. 
- 모형의 성과를 평가하는 기준은 ROC 그래프의 밑부분 면적이며, 면적이 넓을수록 좋은 모형으로 평가한다. 
- <b>[함수사용법]</b>
```{}
prediction(predictions, labels)
```

```{}
performance(prediction.object, acc(accuracy), fpr(FP Rate), tpr(TP Rate), ...)
```

__Q. 임의의 값으로 ROC Curve를 그려보자.__
```{r}
library(ROCR)
set.seed(12345)
probability<-runif(100)
(labels<-ifelse(probability>0.5&runif(100)<0.4, 1, 2))
pred<-prediction(probability, labels)
plot(performance(pred, "tpr", "fpr"))
performance(pred, "auc")@y.values # AUROC
```


## 분류 분석
분류 분석은 반응변수의 속성값에 대해 다양한 변수를 이용하여 모형을 구축하고 이를 사용해 새로운 자료에 대한 예측 및 분류를 수행하는 분석이다. 반응변수가 범주형인 경우의 예측 모형은 새로 입력되는 자료에 대한 분류가 주목적이며, 반응변수가 연속형인 경우에는 그 값을 예측하는 것이 주목적이다. 예측 민 분류 기법은 목표 마케팅, 성과예측, 의학진단, 사기검출, 제조 등 다양한 분야에 이용되고 있다. 

### 로지스틱 회귀분석

- 로지스틱 회귀모형은 반응변수가 범주형인 경우에 적용되는 회귀분석 모형이다. 이 방법은 새로운 설명변수의 값이 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여, 추정 확률을 기준치에 따라분류하는 목적으로 활용된다. 이 때, 모형의 적합을 통해 추정된 확률을 사후확률 (Posterior Probability)라고 한다. 
- 반응변수 y에 대한 다중 로지스틱 회귀모형은 다음과 같다. 
- 로지스틱 회귀모형은 오즈(odds)의 관점에서 해석이 가능하다. exp($\beta_{1}$)의 의미는 나머지 변수(x~1~, ...,x~k~)가 주어질 때, 한단위 증가할 때마다 성공(y=1)의 오즈가 몇 배 증가하는지를 나타내는 값이다. 
- 오즈비(odds ratio) : 오즈는 성공할 확률이 실패할 확률의 몇배인지를 나타내는 확률이며, 오즈비는 오즈의 비율이다. 

#### R을 이용한 이항 로지스틱 회귀분석

<b>[함수사용법]</b>
```{}
glm(formula, data, family="binomial"...)
```
|인자|설명|
|----|----|
|formula|수식(종속변수~독립변수)|
|data|분석하고자 하는 데이터|
|family|분석에 따른 link function 선택, binomial(이항), gaussian(가우시안), Gamma(감마), poisson(포아송) 등이 있음.|

```{}
predict(model, newdata, type, ...)
```
|인자|설명|
|----|----|
|model|개발한 모형|
|newdata|예측을 수행할 test 데이터|
|type|예측 결과의 유형 지정, link(log-odds값), class(범주형(factor)값), response(0~1 확률값)|

__Q. credit 데이터를 분할하고, train 데이터로 로지스틱 회귀모델을 만들어 보자.__

```{r}
credit<-read.csv("./data/credit_final.csv")
class(credit$credit.rating) # 종속변수 factor 변환
credit$credit.rating<-factor(credit$credit.rating)
str(credit)

set.seed(123)
idx<-sample(1:nrow(credit), nrow(credit)*0.7, replace=FALSE)
train<-credit[idx,]
test<-credit[-idx,]

logistic<-glm(credit.rating~.,data=train,family="binomial")
summary(logistic)
```

- 회귀계수의 p-value가 유의수준 0.05보다 높게 나타나는 변수가 많으므로, step 함수에서 단계적 선택법을 이용하여 로지스틱 회귀분석을 다시 실시한다. 

```{r}
step.logistic<-step(glm(credit.rating~1, data=train, family="binomial"), 
  scope=list(lower~1, upper=~account.balance+credit.duration.months+previous.credit.payment.status+credit.purpose+credit.amount+savings+employment.duration+installment.rate+marital.status+guarantor+residence.duration+current.assets+age+other.credits+apartment.type+bank.credits+occupation+dependents+telephone+foreign.worker), direction="both")

summary(step.logistic)
```

- 총 20개의 독립변수 중 13개의 독립변수가 선택되었으며, *과 .은 각 유의확률에서 채택이 되는지를 알 수 있다. 로지스틱 회귀식은 아래와 같이 나타난다. <br/>
$P(credit.rating)=\frac{1}{1+exp[-(-1.45+0.88account.balance+...-0.15installment.rate)]}$
- estimate가 양수이면 독립변수가 1단위 증가할 때 확률이 1에 가까워지고, estimate가 음수이면 독립변수가 1단위 증가할 때 확률이 0에 가까워진다. 

```{r}
library(caret)
(pred<-predict(step.logistic, test[,-1], type="response")) # 예측값을 "response"로 지정하여 확률값을 출력
```


```{r}
pred1<-as.data.frame(pred)
pred1$grade<-ifelse(pred1$pred<0.5, pred1$grade<-0, pred1$grade<-1)
confusionMatrix(data=as.factor(pred1$grade), reference=test[,1], positive='1')
```

- 구축된 로지스틱 회귀모형으로 test 데이터의 기존 credit.rating 열을 제외한 데이터로 예측을 한다. 정분류율을 확인하기 전에 예측값이 확률로 나타나기 때문에 기준이 되는 확률보다 크면 1, 작으면 0으로 범주를 추가한다. 
- 정분류율(Accuracy)은 0.75이며, 민감도는 0.8878로 높게 나타났다. 또 특이도는 0.4526이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다. 

```{r}
install.packages(setdiff("ROCR", rownames(installed.packages())))
library(ROCR)
pred.logistic.roc<-prediction(as.numeric(pred1$grade), as.numeric(test[,1]))
plot(performance(pred.logistic.roc, "tpr", "fpr"))
abline(a=0, b=1, lty=2, col="black")
performance(pred.logistic.roc,"auc")@y.values
```

- prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 @y.values값으로 확인할 결과 0.67로 나타났다. 

#### R을 이용한 다항 로지스틱 회귀분석

- 예측하고자 하는 분류가 3개 이상이 된다면 다항 로지스틱 회귀분석을 사용한다. R에서는 <b>nnet 패키지의 multinom</b> 등의 함수로 분석을 한다. 

```{}
multinom(formula, data)
```

__Q. iris 데이터의 Species를 분류하는 다항 로지스틱 회귀분석을 실시하고 오분류표를 만들어 보자.__
```{r}
idx<-sample(1:nrow(iris), nrow(iris)*0.7, replace=FALSE)
train.iris<-iris[idx,]
test.iris<-iris[-idx,]

library(nnet)
mul.iris<-multinom(Species~., train.iris)

# 예측을 통한 정분류율 확인
pred.mul<-predict(mul.iris, test.iris[,-5])
confusionMatrix(pred.mul, test.iris[,5])
```

### 의사결정나무

- 의사결정나무는 분류함수를 의사결정 규칙으로 이뤄진 나무 모양으로 그리는 방법이다. 계산 결과가 의사결정나무에 직접 나타나기 때문에 해석이 간편하다. 
- 의사결정나무는 주어진 입력값에 대하여 출력값을 예측하는 모형으로 분류나무와 회귀나무 모형이 있다. 

#### 의사결정나무의 분석 과정

- 의사결정나무의 형성과정은 크게 성장, 가지치기, 타당성 평가, 해석 및 예측으로 이루어진다. 

##### 성장단계
- 각 마디에서 적절한 최적의 분류규칙을 찾아서 나무를 성장시키는 과정으로 적절한 정지규칙을 만족하면 중단한다. 
- 분리 규칙을 설정하는 분리 기준은 이산형 목표변수, 연속형 목표변수에 따라 나뉘며 아래와 같은 기준값을 사용한다. 

- 이산형 목표변수
  
| 기준값|분리기준 |
|-------|---------|
|카이제곱 통계량 p값|p값이 가장 작은 예측변수와 그때의 최적분리에 의해서 자식마디를 형성|
|지니 지수|지니 지수를 감소시켜주는 예측변수와 그 때의 최적 분리에 의해서 자식 마디를 형성|
|엔트로피 지수|엔트로피 지수가 가장 작은 예측 변수와 이 때의 최적분리에 의해 자식 마디를 형성|

- 연속형 목표변수
  
| 기준값|분리기준 |
|-------|---------|
|분산분석에서 F통계량|p값이 가장 작은 예측변수와 그때의 최적분리에 의해서 자식마디를 형성|
|분산의 감소량|분산의 감소량을 최대화 하는 기준의 최적분리에 의해서 자식마디를 형성|

- 정지규칙은 더 이상 분리가 일어나지 않고, 현재의 마디가 끝마디가 되도록 하는 규칙이며, 의사결정나무의 깊이를 지정하거나 끝마디의 레코드 수의 최소 개수를 지정한다. 

##### 가지치기 단계
- 오차를 크게 할 위험이 높거나 부적절한 추론 규칙을 가지고 있는 가지 또는 불필요한 가지를 제거하는 단계이다. 
- 나무의 크기를 모형의 복잡도로 볼 수 있으며, 최적의 나무 크기는 자료로부터 추정하게 된다. 일반적으로 사용되는 방법은 마디에 속하는 자료가 일정수 이하일 때 분할을 정지하고 비용-복잡도 가지치기를 이용하여 성장시킨 나무를 가지치기하게 된다. 

##### 타당성 평가 단계

- 이익도표, 위험도표 혹은 시험자료를 이용하여 의사결정나무를 평가하는 단계이다. 

##### 해설 및 예측 단계
- 구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용하는 단계이다. 

#### 의사결정나무 알고리즘
##### CART (Classification and Regression Tree)
##### C4.5와 C5.0
##### CHAID (SHi-squared Automatic Interaction Detection)

#### R을 이용한 의사결정나무 분석

<b>[함수사용법]</b>
```{}
rpart(formula, data, method, control=rpart.control(), ...)
```

__Q. 앞서 분할한 credit 데이터의 train 데이터로 의사결정나무 모델을 만들어 보자.__
```{r}
library(rpart)
library(rpart.plot)
dt.model<-rpart(credit.rating~., method="class", data=train, control=rpart.control(maxdepth=5, minsplit=15))
prp(dt.model, type=4, extra=2)
```

- 총 700개의 관측치 중 495개의 관측치를 1로 분류했으며, account.balance >= 3인 325개의 노드 중 288이 1로 분류되었음을 의미한다. prp 함수는 rpart.plot 패키지에 속한 함수이며, type, extra 등의 인자를 사용하여 그래프의 모양을 바꿀 수 있다. 

```{r}
# rpart 함수를 활용하여 의사결정나무분석 실시 (최적 나무 선정)
dt.model$cptable
(opt<-which.min(dt.model$cptable[,"xerror"]))
(cp<-dt.model$cptable[opt, "CP"])
(prune.c<-prune(dt.model, cp=cp))
```

- cptable 인자를 통해서 교차타당성 오차를 제공하여 의사결정나무 모델의 가지치기, 트리의 최대 크기조절에 사용한다. nsplit은 분할횟수, xerror는 해당 CP에서 cross validation 했을 때 오류율, xstd는 해당 CP에서 cross validation 했을 때 편차를 나타낸다. cptable에서 xerror가 가장 낮은 split 개수를 선택한다. 

- 위 결과를 확인했을 때, xerror가 가장 낮을 때 nsplit은 5이며, 앞선 모형의 그래프를 봤을 때 의사 결정나무 모델이 분할을 5번까지 한다고 할 수 있다. 

```{r}
plotcp(dt.model)
```

- plotcp의 결과에서도 xerror가 가장 낮을 때 결과에 따라 교차타당성오차를 최소로 하는 트리를 형성한다. 결과적으로 나무의 크기가 6일 때 최적의 나무라고 할 수 있다. 

```{r}
install.packages(setdiff("caret", rownames(installed.packages())))
library(caret)
pred.dt<-predict(dt.model, test[,-1], type="class")
confusionMatrix(data=pred.dt, reference=test[,1], positive='1')
```

- 정분류율(Accuracy)은 0.7533며, 민감도는 0.8976로 높게 나타났다. 또, 특이도는 0.4421이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다. 

```{r}
# ROC 커브 그리기 및 AUC 산출
install.packages(setdiff("ROCR", rownames(installed.packages())))
library(ROCR)
pred.dt.roc<-prediction(as.numeric(pred.dt), as.numeric(test[,1]))
plot(performance(pred.dt.roc,"tpr", "fpr"))
abline(a=0,b=1,lty=2,col="black")
performance(pred.dt.roc,"auc")@y.values
```

- prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 @y.values값으로 확인한 결과 0.6698로 나타났다. 

__Q. 앞서 분리한 iris 데이터의 Species를 분류하는 의사결정나무분석을 실시하고 오분류표를 만들어 보자.__
```{r}
install.packages(setdiff("rpart", rownames(installed.packages())))
library(rpart)
library(rpart.plot)
dt.model2<-rpart(Species~., data=train.iris)
prp(dt.model2, type=4, extra=2)
```

```{r}
pred.dt2<-predict(dt.model2, test.iris[,-5], type="class")
confusionMatrix(data=pred.dt2, reference=test.iris[,5])
```


### 앙상블 기법
- 앙상블 기법은 주어진 자료로부터 여러개의 예측모형들을 만든 후 예측모형들을 조합하여 하나의 최종 예측모형을 만드는 방법이다. 학습방법이 가장 불안전한 의사결정나무에 주로 사용한다. 

#### 배깅 (Bagging)
##### 개념

- 주어진 자료에서 여러개의 부트스트랩 자료를 생성하고 각 부트스트랩 자료에 예측모형을 만든후 결합하여 최종 예측모형을 만드는 방법이다. 
- 보팅은 여러개의 모형으로부터 산출된 결과 중 다수결에 의해서 최종 결과를 선정하는 과정이다. 
- 최적의 의사결정나무를 구축할 때 가장 어려운 부분이 가지치기이지만 배깅에서는 가지치기를 하지 않고 최대로 성정한 의사결정나무들을 활용한다. 
- 훈련자료의 모집단의 분포를 모르기 때문에 실제 문제에서는 평균예측모형을 구할 수 없다. 배깅은 이러한 문제를 해결하기 위해 훈련자료를 모집단으로 생각하고 평균예측모형을 구하여 분산을 줄이고 예측력을 향상시킬 수 있다. 

##### R을 이용한 Bagging 분석
```{}
bagging(formula, data, mfinal, control=, ...)
```

|인자|설명|
|----|----|
|formula|수식|
|data|분석하고자하는 데이터|
|mfinal|반복수 또는 사용할 트리의 수 (default=100)|
|control|의사결정나무를 만들 때 사용할 option을 설정

__Q. 앞서 분할한 credit 데이터의 train 데이터로 Bagging 모델을 만들어 보자.__
```{r}
install.packages(setdiff("adabag", rownames(installed.packages())))
library(adabag)
bag<-bagging(credit.rating~., data=train, mfinal=15)
names(bag)
```

- names 함수를 통해 bagging 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다. 
  + trees: bagging을 통해 생성된 의사결정나무들을 확인할 수 있다. 
  + votes: 각 의사결정나무들이 1행 데이터에 대해 1 또는 2열의 분류를 가진다는 것에 대한 투표를 진행한 것이다.
  + prob: 각 행에 대해 1 또는 2열의 특징으로 분류되는 확률을 나타내는 것이다. 
  + class: bagging 기법을 활용해 각 행의 분류를 예측한 것이다. 
  + samples: 각 의사결정나무에 사용된 부트스트랩 데이터의 레코드 번호를 나타낸다. 
  + importance: 변수의 상대적인 중요도를 나타내며, 지니지수의 gain을 고려한 측도이다. 

```{r}
bag$importance
```

- importance 인자에서 변수의 상대적 중요도를 봤을 때, account.balance, credit.duration.months, age 순서로 변수 중요도가 크다는 것을 파악할 수 있다. 

```{r}
library(caret)
pred.bg<-predict(bag, test, type="class")
confusionMatrix(data=as.factor(pred.bg$class), reference=test$credit.rating, positive='1')
```

- 로지스틱 회귀모형, 의사결정나무 모형과 동일한 형태로 정분류율을 확인할 수 있으며, 분석 결과에서 예측한 값의 class가 numeric형이므로 as.factor 함수를 이용하여 factor로 변형을 해야 한다. 
- 정분류율은 0.7467이며, 민감도는 0.8488로 높게 나타났다. 또, 특이도는 0.5263이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다. 

```{r}
library(ROCR)
pred.bg.roc<-prediction(as.numeric(pred.bg$class), as.numeric(test[,1]))
plot(performance(pred.bg.roc, "tpr", "fpr"))
abline(a=0, b=1, lty=2, col="black")
performance(pred.bg.roc, "auc")@y.values
```

- prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 @y.values값으로 확인한 결과 0.6875로 나타났다.


#### 부스팅 (Boosting)
##### 개념

- 예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법으로 Adaboost는 이진분류 문제에서 랜덤 분류기보다 조금 더 좋은 분류기 n개에 각각 가중치를 설정하고 n개의 분류기를 결합하여 최종 분류기를 만드는 방법을 제안하였다. 
- 훈련오차를 빨리, 쉽게 줄일 수 있고 배깅에 비해 많은 경우 예측오차가 향상되어 Adaboost의 성능이 배깅보다 뛰어난 경우가 많다. 

##### R을 이용한 Boosting 분석

<b>[함수사용법]</b>
```{}
boosting(formula, data, boos=TRUE/FALSE, control=, ...)
```

__Q. 앞서 분할한 credit 데이터의 train 데이터로 Boosting 모델을 만들어 보자.__
```{r}
library(adabag)
boost<-boosting(credit.rating ~ ., data=train, boos=TRUE, mfinal=80)
names(boost)
```

- names 함수를 통해 boosting 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다. 
  + trees: boosting을 통해 생성된 의사결정나무들을 확인할 수 있다. (80개)
  + weitgts: 각 의사결정나무에 부여된 가중치값을 확인할 수 있다. 
  + votes: 각 의사결정나무들이 1행 데이터에 대해 1 또는 2열의 분류를 가진다는 것에 대한 투표를 진행한 것이다.
  + prob: 각 행에 대해 1 또는 2열의 특징으로 분류되는 확률을 나타내는 것이다. 
  + class: boosting 기법을 활용해 각 행의 분류를 예측한 것이다. 
  + importance: 변수의 상대적인 중요도를 나타내며, 지니지수의 gain을 고려한 측도이다. 

```{r}
boost$importance
```

- importance 인자에서 변수의 상대적 중요도를 봤을 때, credit.amount, age, credit.duration.months 순서로 변수 중요도가 크다는 것을 파악할 수 있다. 

```{r}
library(caret)
pred.boos<-predict(boost, test, type="class")
confusionMatrix(data=as.factor(pred.boos$class), reference=test$credit.rating, positive='1')
```

- 로지스틱 회귀모형, 의사결정나무 모형과 동일한 형태로 정분류율을 확인할 수 있으며, 분석 결과에서 예측한 값의 class가 numeric형이므로 as.factor 함수를 이용하여 factor로 변형을 해야 한다. 
- 정분류율은 0.7133이며, 민감도는 0.8098로 높게 나타났다. 또, 특이도는 0.5053이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다. 

```{r}
library(ROCR)
pred.boos.roc<-prediction(as.numeric(pred.boos$class), as.numeric(test[,1]))
plot(performance(pred.boos.roc, "tpr", "fpr"))
abline(a=0, b=1, lty=2, col="black")
performance(pred.boos.roc,"auc")@y.values
```

- prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 @y.values값으로 확인한 결과 0.6575로 나타났다. 



#### 랜덤포레스트 (Random Forest)
##### 개념
- 의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법이다. 
- R프로그램에서는 randomForest 패키지로 구현이 가능하다. randomForest 함수를 사용하고 random input에 따른 forest of tree를 생성하여 이를 이용한 분류를 한다. 
- 수천개의 변수를 통해 변수 제거없이 실행되므로 정확도 측면에서 좋은 성과를 보인다. 
- 이론적 설명이나 최종 결과에 대한 해석이 어렵다는 단점이 있지만 예측력이 매우 높은 것으로 알려져 있다. 특히 입력변수가 많은 경우, 배깅/부스팅과 비슷하거나 좋은 예측력을 보인다. 

##### R을 이용한 RandomForest 분석
- R에서 RandomForest 분석을 수행할 수 있는 함수는 randomForest 패키지의 randomForest 함수이며, 이를 이용하여 분류분석을 실시한다. 

<b>[함수사용법]</b>
```{}
randomForest(formula, data, ntree, mtry, ...)
```

|인자|설명|
|----|----|
|formula|수식(종속변수 ~ 독립변수)|
|data|분석하고자 하는 데이터|
|ntree|사용할 트리의 수, 너무 작은 숫자를 입력하면 예측 불가|
|mtry|각 분할에서 랜덤으로 뽑힌 변수의 개수<br/>보통 classification은 sqrt(변수 개수), regression은 (변수 개수/3)|

__Q. 앞서 분할한 credit 데이터의 train 데이터로 randomforest 모델을 만들어 보자.__
```{r}
library(randomForest)
(rf.model<-randomForest(credit.rating ~ ., 
                       data=train, 
                       ntree=50, # 나무 50개 사용
                       mtry=sqrt(20), # 사용할 변수의 개수 (classification이므로 sqrt(20)개)
                       importance=TRUE) # 변수중요도를 결과를 확인
)
```

- 랜덤포레스트 분석 결과에서 "OOB estimate of error rate"의 값은 에러 추정치로서 값이 낮을수록 분류모델의 성능이 좋다고 판단할 수 있다. Confusion matrix의 결과에서 class.error값으로 분류 에러를 통해 모델 성능을 확인할 수 있다. 
```{r}
names(rf.model)
```

- names 함수를 통해 randomForest 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다. 
  + predicted: Out-of-bag samples에 기초한 예측값을 확인할 수 있다. 
  + err.rate: 입력데이터 각각에 대한 예측 오류율을 확인할 수 있다. 
  + importance: 변수 중요도를 나타내며 Gini값을 기준으로 한다. MeanDecreaseAccuracy와 MeanDecreaseGini 모두 값이 클수록 중요도가 높다고 해석할 수 있다. 
  
```{r}
varImpPlot(rf.model)
```

- varImpPlot 함수로 importance 인자 결과를 시각화할 수 있다. 변수의 상대적 중요도를 Mean DecreaseGini를 기준으로 봤을 때, credit.amout, age, account.balance 순서로 변수 중요도가 크다는 것을 파악할 수 있다. 

```{r}
library(caret)
pred.rf<-predict(rf.model, test[,-1], type="class")
confusionMatrix(data=pred.rf, reference=test[,1], positive='1')
```

- 정분류율은 0.76이며, 민감도는 0.8976으로 높게 나타났다. 또 특이도는 0.4632이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다. 

```{r}
library(ROCR)
pred.rf.roc<-prediction(as.numeric(pred.rf), as.numeric(test[,1]))
plot(performance(pred.rf.roc,"tpr","fpr"))
abline(a=0,b=1,lty=2,col="black")

performance(pred.rf.roc, "auc")@y.values[[1]]
```

- prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 @y.values값으로 확인한 결과 0.6804로 나타났다. 

__Q. 앞서 분리한 iris 데이터의 Species를 분류하는 랜덤포레스트분석을 실시하고 오분류표를 만들어 보자.__
```{r}
library(randomForest)
(rf.model2<-randomForest(Species ~ ., data=train.iris, ntree=50, mtry=sqrt(4), importance=TRUE))

pred.rf2<-predict(rf.model2, test.iris[,-5], type="class")
confusionMatrix(data=pred.rf2, reference=test.iris[,5], positive='1')
```

### SVM (Support Vector Machine)
- 서포트 벡터 머신은 기계학습 분야 중 하나로 패턴인식, 자료 분석 등을 위한 지도학습 모델이며 주로 회귀와 분류 문제 해결에 사용된다. 
- 서포트 벡터 머신 알고리즘은 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어떤 범주에 속할 것인지를 판단하는 <b>비확률적 이진 선형 분류 모델을 생성</b>한다. 

#### 작동 원리

- 데이터의 각 그룹을 구분하는 분류자를 <b>결정 초평면</b>, 각 그룹에 속한 데이터들 중에서도 초평면에 가장 가까이에 붙어 있는 최정방 데이터들을 <b>서포트 벡터</b>, 서포트 벡터와 초평면 사이의 수직거리를 <b>마진</b>이라고 한다. 
- SVM은 고차원 혹은 무한 차원의 공간에서 <b>마진을 최대화하는 초평면 (MMH, Maximum Margin Hyperplane: 최대마진 초평면) 을 찾아 분류와 회귀를 수행</b>한다. 
- SVM 모형은 선형 분류뿐만 아니라 <b>비선형 분류</b>에서도 사용되는데, 비선형 분류에서는 입력자료를 다차원 공간상으로 매핑할 때 <b>커널 트릭</b>을 사용하기도 한다. 

#### R을 이용한 SVM 분석
<b>[함수사용법]</b>
```{}
svm(formula, data, kernel, gamma, cost, ...)
```

|인자|설명|
|----|----|
|formula|수식(종속변수 ~ 독립변수)|
|data|분석하고자 하는 데이터|
|kernel|훈련과 예측에 사용되는 커널<br/>"radial","linear","polynomial","sigmoid"가 있음.<br/>실제 문제에서 커널의 선택이 결과의 정확도에 큰 영향을 주지 않음.|
|gamma|초평면의 기울기, default=1/(데이터차원)|
|cost|과적합을 막는 정도, default=1|

```{}
tune.svm(formula, data, kernel, gamma, cost, ...)
```

|인자|설명|
|----|----|
|formula|수식(종속변수 ~ 독립변수)|
|data|분석하고자 하는 데이터|
|gamma|초평면의 기울기|
|cost|과적합을 막는 정도|

__Q. 앞서 분할한 credit 데이터의 train 데이터를 이용하여 tune.svm 함수로 최적의 파라미터를 찾고 SVM 모델을 만들어 보자.__
```{r}
install.packages(setdiff("e1071", rownames(installed.packages())))
library(e1071)
tune.svm(credit.rating ~ ., data=credit, gamma = 10^(-6:-1), cost = 10^(1:2))
```

- tune.svm 함수에서 gamma와 cost의 주어진 범위 내에서 최적값을 찾아준다. 여기서는 gamma 6개, cost 2개, 즉 6 * 12개의 조합에서 모수조율이 이루어진다. 분석결과에서 best parameters를 통해 gamma는 0.01, cost는 10이 최적의 파라미터임을 확인할 수 있다. 

```{r}
svm.model<-svm(credit.rating~., data=train, kernel="radial", gamma=0.01, cost=10)
summary(svm.model)
```

- svm 함수에서 gamma와 cost를 설정하고, kernel을 "radial"으로 지정한다. kernel은 radial (가우시안 RBF)이 default로 되어 있다. summary 함수로 svm 모델의 cost값과 Support Vectors의 수(train 데이터 수)를 확인할 수 있다. 

```{r}
# 예측을 통한 정분류를 확인
install.packages(setdiff("caret", rownames(installed.packages())))
library(caret)
pred.svm<-predict(svm.model, test, type="class")
confusionMatrix(data=pred.svm, reference=test[,1], positive='1')
```

- 정분류율을 0.7533이며, 민감도는 0.8488로 높게 나타났다. 또, 특이도는 0.5474이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다. 

```{r}
install.packages(setdiff("ROCR", rownames(installed.packages())))
library(ROCR)
pred.svm.roc<-prediction(as.numeric(pred.svm), as.numeric(test[,1]))
plot(performance(pred.svm.roc, "tpr", "fpr"))
abline(a=0, b=1, lty=2, col="black")
performance(pred.svm.roc, "auc")@y.values
```

- prediction 함수와 performance 함수로 값을 구하여 plot함수로 ROC 커브를 그렸으며, AUC값은 @y.values 값으로 확인한 결과 0.6981로 나타났다. 

__Q. 앞서 분리한 iris 데이터의 Species를 분류하는 SVM 분석을 실시하고 오분류표를 만들어 보자.__
```{r}
install.packages(setdiff("e1071", rownames(installed.packages())))
library(e1071)
tune.svm(Species ~ ., data=iris, gamma=2^(-1:1), cost=2^(2:4))
svm.model2<-svm(Species~., data=train.iris, kernel="radial", gamma=0.5, cost=16)
pred.svm2<-predict(svm.model2, test.iris, type="class")
confusionMatrix(data=pred.svm2, reference=test.iris[,5], positive='1')
```



### 나이브 베이즈 분류
- 나이브 베이즈 분류는 데이터에서 변수들에 대한 조건부 독립을 가정하는 알고리즘으로 클래스에 대한 사전 정보와 데이터로부터 추출된 정보를 결합하고, 베이즈 정리를 이용하여 특정 데이터가 어떤 클래스에 속하는지를 분류하는 알고리즘이다. 
- 텍스트 분류에서 문서를 여러 범주중 하나로 판단하는 문제에 대한 솔루션으로 사용될 수 있다. 

