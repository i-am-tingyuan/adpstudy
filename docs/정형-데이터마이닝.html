<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 정형 데이터마이닝 | ADPStudy</title>
  <meta name="description" content="4 정형 데이터마이닝 | ADPStudy" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4 정형 데이터마이닝 | ADPStudy" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 정형 데이터마이닝 | ADPStudy" />
  
  
  

<meta name="author" content="tingyuan" />


<meta name="date" content="2021-09-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="통계분석.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> R기초</a></li>
<li class="chapter" data-level="2" data-path="데이터-전처리.html"><a href="데이터-전처리.html"><i class="fa fa-check"></i><b>2</b> 데이터 전처리</a>
<ul>
<li class="chapter" data-level="2.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#제어문"><i class="fa fa-check"></i><b>2.1</b> 제어문</a></li>
<li class="chapter" data-level="2.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#데이터-변환"><i class="fa fa-check"></i><b>2.2</b> 데이터 변환</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#파생변수-생성"><i class="fa fa-check"></i><b>2.2.1</b> 파생변수 생성</a></li>
<li class="chapter" data-level="2.2.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#변수-축소"><i class="fa fa-check"></i><b>2.2.2</b> 변수 축소</a></li>
<li class="chapter" data-level="2.2.3" data-path="데이터-전처리.html"><a href="데이터-전처리.html#표준화와-정규화"><i class="fa fa-check"></i><b>2.2.3</b> 표준화와 정규화</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="데이터-전처리.html"><a href="데이터-전처리.html#데이터-결합-및-요약"><i class="fa fa-check"></i><b>2.3</b> 데이터 결합 및 요약</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#데이터-결합"><i class="fa fa-check"></i><b>2.3.1</b> 데이터 결합</a></li>
<li class="chapter" data-level="2.3.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#데이터-요약"><i class="fa fa-check"></i><b>2.3.2</b> 데이터 요약</a></li>
<li class="chapter" data-level="2.3.3" data-path="데이터-전처리.html"><a href="데이터-전처리.html#apply-계열-함수"><i class="fa fa-check"></i><b>2.3.3</b> apply 계열 함수</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="데이터-전처리.html"><a href="데이터-전처리.html#패키지를-활용한-데이터-전처리"><i class="fa fa-check"></i><b>2.4</b> 패키지를 활용한 데이터 전처리</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#plyr"><i class="fa fa-check"></i><b>2.4.1</b> plyr</a></li>
<li class="chapter" data-level="2.4.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#dplyr"><i class="fa fa-check"></i><b>2.4.2</b> dplyr</a></li>
<li class="chapter" data-level="2.4.3" data-path="데이터-전처리.html"><a href="데이터-전처리.html#reshape2"><i class="fa fa-check"></i><b>2.4.3</b> reshape2</a></li>
<li class="chapter" data-level="2.4.4" data-path="데이터-전처리.html"><a href="데이터-전처리.html#data.table"><i class="fa fa-check"></i><b>2.4.4</b> data.table</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="데이터-전처리.html"><a href="데이터-전처리.html#결측치"><i class="fa fa-check"></i><b>2.5</b> 결측치</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#결측치-인식"><i class="fa fa-check"></i><b>2.5.1</b> 결측치 인식</a></li>
<li class="chapter" data-level="2.5.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#결측치-처리"><i class="fa fa-check"></i><b>2.5.2</b> 결측치 처리</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="데이터-전처리.html"><a href="데이터-전처리.html#이상치-인식"><i class="fa fa-check"></i><b>2.6</b> 이상치 인식</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#이상치란"><i class="fa fa-check"></i><b>2.6.1</b> 이상치란?</a></li>
<li class="chapter" data-level="2.6.2" data-path="데이터-전처리.html"><a href="데이터-전처리.html#사분위수"><i class="fa fa-check"></i><b>2.6.2</b> 사분위수</a></li>
<li class="chapter" data-level="2.6.3" data-path="데이터-전처리.html"><a href="데이터-전처리.html#boxplot을-활용한-이상치-판별"><i class="fa fa-check"></i><b>2.6.3</b> boxplot을 활용한 이상치 판별</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="데이터-전처리.html"><a href="데이터-전처리.html#날짜-데이터-전처리"><i class="fa fa-check"></i><b>2.7</b> 날짜 데이터 전처리</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="데이터-전처리.html"><a href="데이터-전처리.html#날짜-데이터-다루기"><i class="fa fa-check"></i><b>2.7.1</b> 날짜 데이터 다루기</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="통계분석.html"><a href="통계분석.html"><i class="fa fa-check"></i><b>3</b> 통계분석</a>
<ul>
<li class="chapter" data-level="3.1" data-path="통계분석.html"><a href="통계분석.html#통계-자료의-획득방법"><i class="fa fa-check"></i><b>3.1</b> 통계 자료의 획득방법</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="통계분석.html"><a href="통계분석.html#총조사전수-조사census"><i class="fa fa-check"></i><b>3.1.1</b> 총조사/전수 조사(census)</a></li>
<li class="chapter" data-level="3.1.2" data-path="통계분석.html"><a href="통계분석.html#표본조사"><i class="fa fa-check"></i><b>3.1.2</b> 표본조사</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="통계분석.html"><a href="통계분석.html#t-검정-t-test"><i class="fa fa-check"></i><b>3.2</b> T-검정 (T-Test)</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="통계분석.html"><a href="통계분석.html#일표본-t-검정-one-sample-t-test"><i class="fa fa-check"></i><b>3.2.1</b> 일표본 T-검정 (One Sample T-Test)</a></li>
<li class="chapter" data-level="3.2.2" data-path="통계분석.html"><a href="통계분석.html#대응표본-t-검정-paired-sample-t-test"><i class="fa fa-check"></i><b>3.2.2</b> 대응표본 T-검정 (Paired Sample T-Test)</a></li>
<li class="chapter" data-level="3.2.3" data-path="통계분석.html"><a href="통계분석.html#독립표본-t-검정-independent-sample-t-test"><i class="fa fa-check"></i><b>3.2.3</b> 독립표본 T-검정 (Independent Sample T-Test)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="통계분석.html"><a href="통계분석.html#교차분석"><i class="fa fa-check"></i><b>3.3</b> 교차분석</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="통계분석.html"><a href="통계분석.html#교차분석-개념"><i class="fa fa-check"></i><b>3.3.1</b> 교차분석 개념</a></li>
<li class="chapter" data-level="3.3.2" data-path="통계분석.html"><a href="통계분석.html#적합성-검정"><i class="fa fa-check"></i><b>3.3.2</b> 적합성 검정</a></li>
<li class="chapter" data-level="3.3.3" data-path="통계분석.html"><a href="통계분석.html#독립성-검정"><i class="fa fa-check"></i><b>3.3.3</b> 독립성 검정</a></li>
<li class="chapter" data-level="3.3.4" data-path="통계분석.html"><a href="통계분석.html#동질성-검정"><i class="fa fa-check"></i><b>3.3.4</b> 동질성 검정</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="통계분석.html"><a href="통계분석.html#분산분석-anova"><i class="fa fa-check"></i><b>3.4</b> 분산분석 (ANOVA)</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="통계분석.html"><a href="통계분석.html#분산분석의-개념"><i class="fa fa-check"></i><b>3.4.1</b> 분산분석의 개념</a></li>
<li class="chapter" data-level="3.4.2" data-path="통계분석.html"><a href="통계분석.html#일원배치-분산분석-one-way-anova"><i class="fa fa-check"></i><b>3.4.2</b> 일원배치 분산분석 (One-way ANOVA)</a></li>
<li class="chapter" data-level="3.4.3" data-path="통계분석.html"><a href="통계분석.html#이원배치-분산분석-two-way-anova"><i class="fa fa-check"></i><b>3.4.3</b> 이원배치 분산분석 (Two-way ANOVA)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="통계분석.html"><a href="통계분석.html#상관분석"><i class="fa fa-check"></i><b>3.5</b> 상관분석</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="통계분석.html"><a href="통계분석.html#상관분석-개념"><i class="fa fa-check"></i><b>3.5.1</b> 상관분석 개념</a></li>
<li class="chapter" data-level="3.5.2" data-path="통계분석.html"><a href="통계분석.html#상관분석의-유형"><i class="fa fa-check"></i><b>3.5.2</b> 상관분석의 유형</a></li>
<li class="chapter" data-level="3.5.3" data-path="통계분석.html"><a href="통계분석.html#상관계수-검정"><i class="fa fa-check"></i><b>3.5.3</b> 상관계수 검정</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="통계분석.html"><a href="통계분석.html#회귀분석"><i class="fa fa-check"></i><b>3.6</b> 회귀분석</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="통계분석.html"><a href="통계분석.html#회귀분석의-개념"><i class="fa fa-check"></i><b>3.6.1</b> 회귀분석의 개념</a></li>
<li class="chapter" data-level="3.6.2" data-path="통계분석.html"><a href="통계분석.html#단순선형회귀분석"><i class="fa fa-check"></i><b>3.6.2</b> 단순선형회귀분석</a></li>
<li class="chapter" data-level="3.6.3" data-path="통계분석.html"><a href="통계분석.html#다중선형회귀분석-다변량-회귀분석"><i class="fa fa-check"></i><b>3.6.3</b> 다중선형회귀분석 (다변량 회귀분석)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html"><i class="fa fa-check"></i><b>4</b> 정형 데이터마이닝</a>
<ul>
<li class="chapter" data-level="4.1" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#데이터-분할과-성과분석"><i class="fa fa-check"></i><b>4.1</b> 데이터 분할과 성과분석</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#데이터-분할"><i class="fa fa-check"></i><b>4.1.1</b> 데이터 분할</a></li>
<li class="chapter" data-level="4.1.2" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#성과분석"><i class="fa fa-check"></i><b>4.1.2</b> 성과분석</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#분류-분석"><i class="fa fa-check"></i><b>4.2</b> 분류 분석</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#로지스틱-회귀분석"><i class="fa fa-check"></i><b>4.2.1</b> 로지스틱 회귀분석</a></li>
<li class="chapter" data-level="4.2.2" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#의사결정나무"><i class="fa fa-check"></i><b>4.2.2</b> 의사결정나무</a></li>
<li class="chapter" data-level="4.2.3" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#앙상블-기법"><i class="fa fa-check"></i><b>4.2.3</b> 앙상블 기법</a></li>
<li class="chapter" data-level="4.2.4" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#svm-support-vector-machine"><i class="fa fa-check"></i><b>4.2.4</b> SVM (Support Vector Machine)</a></li>
<li class="chapter" data-level="4.2.5" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#나이브-베이즈-분류"><i class="fa fa-check"></i><b>4.2.5</b> 나이브 베이즈 분류</a></li>
<li class="chapter" data-level="4.2.6" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#k-nn-k-nearest-neighbor"><i class="fa fa-check"></i><b>4.2.6</b> K-NN (K-Nearest Neighbor)</a></li>
<li class="chapter" data-level="4.2.7" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#인공신경망-모형-artificial-neural-network"><i class="fa fa-check"></i><b>4.2.7</b> 인공신경망 모형 (Artificial Neural Network)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#군집분석"><i class="fa fa-check"></i><b>4.3</b> 군집분석</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#군집분석-1"><i class="fa fa-check"></i><b>4.3.1</b> 군집분석</a></li>
<li class="chapter" data-level="4.3.2" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#계층적-군집분석"><i class="fa fa-check"></i><b>4.3.2</b> 계층적 군집분석</a></li>
<li class="chapter" data-level="4.3.3" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#비계층적-군집분석"><i class="fa fa-check"></i><b>4.3.3</b> 비계층적 군집분석</a></li>
<li class="chapter" data-level="4.3.4" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#혼합-분포-군집"><i class="fa fa-check"></i><b>4.3.4</b> 혼합 분포 군집</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#연관분석"><i class="fa fa-check"></i><b>4.4</b> 연관분석</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="정형-데이터마이닝.html"><a href="정형-데이터마이닝.html#연관규칙"><i class="fa fa-check"></i><b>4.4.1</b> 연관규칙</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ADPStudy</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="정형-데이터마이닝" class="section level1" number="4">
<h1><span class="header-section-number">4</span> 정형 데이터마이닝</h1>
<div id="데이터-분할과-성과분석" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> 데이터 분할과 성과분석</h2>
<div id="데이터-분할" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> 데이터 분할</h3>
<div id="sample" class="section level4" number="4.1.1.1">
<h4><span class="header-section-number">4.1.1.1</span> sample</h4>
<p><b>[함수사용법]</b></p>
<pre><code>sample(x, size, replace=FALSE, prob...)</code></pre>
<p><strong>Q. credit 데이터를 train, validation, test로 분할해보자.</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="정형-데이터마이닝.html#cb2-1" aria-hidden="true" tabindex="-1"></a>credit.df<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;./data/german_credit_dataset.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>)</span>
<span id="cb2-2"><a href="정형-데이터마이닝.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(credit.df)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1000 obs. of  21 variables:
##  $ credit.rating                 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ account.balance               : int  1 1 2 1 1 1 1 1 4 2 ...
##  $ credit.duration.months        : int  18 9 12 12 12 10 8 6 18 24 ...
##  $ previous.credit.payment.status: int  4 4 2 4 4 4 4 4 4 2 ...
##  $ credit.purpose                : int  2 0 9 0 0 0 0 0 3 3 ...
##  $ credit.amount                 : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...
##  $ savings                       : int  1 1 2 1 1 1 1 1 1 3 ...
##  $ employment.duration           : int  2 3 4 3 3 2 4 2 1 1 ...
##  $ installment.rate              : int  4 2 2 3 4 1 1 2 4 1 ...
##  $ marital.status                : int  2 3 2 3 3 3 3 3 2 2 ...
##  $ guarantor                     : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ residence.duration            : int  4 2 4 2 4 3 4 4 4 4 ...
##  $ current.assets                : int  2 1 1 1 2 1 1 1 3 4 ...
##  $ age                           : int  21 36 23 39 38 48 39 40 65 23 ...
##  $ other.credits                 : int  3 3 3 3 1 3 3 3 3 3 ...
##  $ apartment.type                : int  1 1 1 1 2 1 2 2 2 1 ...
##  $ bank.credits                  : int  1 2 1 2 2 2 2 1 2 1 ...
##  $ occupation                    : int  3 3 2 2 2 2 2 2 1 1 ...
##  $ dependents                    : int  1 2 1 2 1 2 1 2 1 1 ...
##  $ telephone                     : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ foreign.worker                : int  1 1 1 2 2 2 2 2 1 1 ...</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="정형-데이터마이닝.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1111</span>)</span>
<span id="cb4-2"><a href="정형-데이터마이닝.html#cb4-2" aria-hidden="true" tabindex="-1"></a>idx<span class="ot">&lt;-</span><span class="fu">sample</span>(<span class="dv">3</span>, <span class="fu">nrow</span>(credit.df), <span class="at">replace=</span><span class="cn">TRUE</span>, <span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>))</span>
<span id="cb4-3"><a href="정형-데이터마이닝.html#cb4-3" aria-hidden="true" tabindex="-1"></a>train<span class="ot">&lt;-</span>credit.df[idx<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb4-4"><a href="정형-데이터마이닝.html#cb4-4" aria-hidden="true" tabindex="-1"></a>validation<span class="ot">&lt;-</span>credit.df[idx<span class="sc">==</span><span class="dv">2</span>,]</span>
<span id="cb4-5"><a href="정형-데이터마이닝.html#cb4-5" aria-hidden="true" tabindex="-1"></a>test<span class="ot">&lt;-</span>credit.df[idx<span class="sc">==</span><span class="dv">3</span>,]</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="정형-데이터마이닝.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(train)</span></code></pre></div>
<pre><code>## [1] 483</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="정형-데이터마이닝.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(validation)</span></code></pre></div>
<pre><code>## [1] 293</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="정형-데이터마이닝.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(test)</span></code></pre></div>
<pre><code>## [1] 224</code></pre>
</div>
<div id="createdatapartition" class="section level4" number="4.1.1.2">
<h4><span class="header-section-number">4.1.1.2</span> createDataPartition</h4>
<ul>
<li>caret 패키지에서 목적변수를 고려한 데이터 분리를 지원하며, 함수를 사용해 분리한 데이터는 변수값의 비율이 원본 데이터와 같게 유지된다.</li>
<li><b>[함수사용법]</b></li>
</ul>
<pre><code>createDataPartition(y, times, p, list=TRUE, ...)</code></pre>
<p><strong>Q. credit 데이터를 train, test로 분할해 보자.</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="정형-데이터마이닝.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;caret&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb12-2"><a href="정형-데이터마이닝.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="정형-데이터마이닝.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 목적변수로 credit.rating을 지정, 생성할 데이터 분할은 1개로 지정, 훈련데이터는 70%로 설정</span></span>
<span id="cb15-2"><a href="정형-데이터마이닝.html#cb15-2" aria-hidden="true" tabindex="-1"></a>part<span class="ot">&lt;-</span><span class="fu">createDataPartition</span>(credit.df<span class="sc">$</span>credit.rating, <span class="at">times=</span><span class="dv">1</span>, <span class="at">p=</span><span class="fl">0.7</span>)</span>
<span id="cb15-3"><a href="정형-데이터마이닝.html#cb15-3" aria-hidden="true" tabindex="-1"></a>parts<span class="ot">&lt;-</span><span class="fu">as.vector</span>(part<span class="sc">$</span>Resample1)</span>
<span id="cb15-4"><a href="정형-데이터마이닝.html#cb15-4" aria-hidden="true" tabindex="-1"></a>train<span class="ot">&lt;-</span>credit.df[parts,]</span>
<span id="cb15-5"><a href="정형-데이터마이닝.html#cb15-5" aria-hidden="true" tabindex="-1"></a>test<span class="ot">&lt;-</span>credit.df[<span class="sc">-</span>parts,]</span></code></pre></div>
</div>
</div>
<div id="성과분석" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> 성과분석</h3>
<div id="오분류표-confusion-matrix" class="section level4" number="4.1.2.1">
<h4><span class="header-section-number">4.1.2.1</span> 오분류표 (Confusion Matrix)</h4>
<div id="개념-2" class="section level5" number="4.1.2.1.1">
<h5><span class="header-section-number">4.1.2.1.1</span> 개념</h5>
<ul>
<li>목표 변수의 <b>실제 범주</b>와 <b>모형에 의해 예측된 분류 범주</b> 사이의 관계를 나타내는 표</li>
<li>TP (True Positive)<br/>
TN (True Negative)<br/>
FP (False Positive)<br/>
FN (False Negative)</li>
</ul>
</div>
<div id="분석-지표" class="section level5" number="4.1.2.1.2">
<h5><span class="header-section-number">4.1.2.1.2</span> 분석 지표</h5>
<ul>
<li><p>정분류율 : 전체 관측치 중 실제값과 예측치가 일치한 정도<br/>
<span class="math inline">\(Accuracy=\frac{TN+TP}{TN+TP+FN+FP}\)</span></p></li>
<li><p>오분류율 : 전체 관측치 중 실제값과 예측치가 다른 정도<br/>
<span class="math inline">\(1 - Accuracy\)</span></p></li>
<li><p>민감도 (Sensitivity (TPR: True Positive Rate)) : 실제값이 True인 관측치 중 예측치가 적중한 정도<br/>
<span class="math inline">\(Sensitivity=\frac{TP}{TP+FN}\)</span></p></li>
<li><p>특이도 (Specificity (TNR: True Negative Rate)) : 실제값이 False인 관측치 중 예측치가 적중한 정도<br/>
<span class="math inline">\(Specificity=\frac{TN}{TN+FP}\)</span></p></li>
<li><p>정확도 (Precision) : True로 예측된 것 중 실제로 True인 것들의 비율<br/>
<span class="math inline">\(Precision=\frac{TP}{TP+FP}\)</span></p></li>
<li><p>재현율 (Recall) : 실제 True인 값 중 True를 얼마나 찾았는지에 대한 비율<br/>
<span class="math inline">\(Recall=\frac{TP}{TP+FN} (=Sensitivity)\)</span></p></li>
<li><p>F1-score : 정확도와 재현율을 보정하여 하나의 지표로 나타낸 값<br/>
<span class="math inline">\(F_{1}=2\times \frac{Precision \times Recall}{Precision+Recall}\)</span></p></li>
<li><p><b>[함수사용법]</b></p></li>
</ul>
<pre><code>confusionMatrix(data, reference)</code></pre>
<p><strong>Q. 임의의 값을 활용하여 Confusion Matrix를 그려보자.</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="정형-데이터마이닝.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;caret&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb17-2"><a href="정형-데이터마이닝.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-3"><a href="정형-데이터마이닝.html#cb17-3" aria-hidden="true" tabindex="-1"></a>predicted<span class="ot">&lt;-</span><span class="fu">factor</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb17-4"><a href="정형-데이터마이닝.html#cb17-4" aria-hidden="true" tabindex="-1"></a>actual<span class="ot">&lt;-</span><span class="fu">factor</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb17-5"><a href="정형-데이터마이닝.html#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span>predicted <span class="sc">+</span> actual)</span></code></pre></div>
<pre><code>##          actual
## predicted 0 1
##         0 3 2
##         1 1 6</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="정형-데이터마이닝.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(predicted<span class="sc">==</span>actual)<span class="sc">/</span><span class="fu">NROW</span>(actual) <span class="co"># 정분류율을 직접 식으로 계산</span></span></code></pre></div>
<pre><code>## [1] 0.75</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="정형-데이터마이닝.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(predicted, actual)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction 0 1
##          0 3 2
##          1 1 6
##                                           
##                Accuracy : 0.75            
##                  95% CI : (0.4281, 0.9451)
##     No Information Rate : 0.6667          
##     P-Value [Acc &gt; NIR] : 0.3931          
##                                           
##                   Kappa : 0.4706          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.0000          
##                                           
##             Sensitivity : 0.7500          
##             Specificity : 0.7500          
##          Pos Pred Value : 0.6000          
##          Neg Pred Value : 0.8571          
##              Prevalence : 0.3333          
##          Detection Rate : 0.2500          
##    Detection Prevalence : 0.4167          
##       Balanced Accuracy : 0.7500          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
</div>
</div>
<div id="roc-그래프" class="section level4" number="4.1.2.2">
<h4><span class="header-section-number">4.1.2.2</span> ROC 그래프</h4>
<ul>
<li>ROC 그래프의 x축에는 FP Ratio(1-특이도)를 나타내며, y축에는 민감도를 나타내 이 두 평가값의 관계로 모형을 평가한다.</li>
<li>모형의 성과를 평가하는 기준은 ROC 그래프의 밑부분 면적이며, 면적이 넓을수록 좋은 모형으로 평가한다.</li>
<li><b>[함수사용법]</b></li>
</ul>
<pre><code>prediction(predictions, labels)</code></pre>
<pre><code>performance(prediction.object, acc(accuracy), fpr(FP Rate), tpr(TP Rate), ...)</code></pre>
<p><strong>Q. 임의의 값으로 ROC Curve를 그려보자.</strong></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="정형-데이터마이닝.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb25-2"><a href="정형-데이터마이닝.html#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb25-3"><a href="정형-데이터마이닝.html#cb25-3" aria-hidden="true" tabindex="-1"></a>probability<span class="ot">&lt;-</span><span class="fu">runif</span>(<span class="dv">100</span>)</span>
<span id="cb25-4"><a href="정형-데이터마이닝.html#cb25-4" aria-hidden="true" tabindex="-1"></a>(labels<span class="ot">&lt;-</span><span class="fu">ifelse</span>(probability<span class="sc">&gt;</span><span class="fl">0.5</span><span class="sc">&amp;</span><span class="fu">runif</span>(<span class="dv">100</span>)<span class="sc">&lt;</span><span class="fl">0.4</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>##   [1] 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 1 2 2 2 2 2 2
##  [38] 1 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2
##  [75] 2 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 2 2 1 2 1 1 2 2 2</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="정형-데이터마이닝.html#cb27-1" aria-hidden="true" tabindex="-1"></a>pred<span class="ot">&lt;-</span><span class="fu">prediction</span>(probability, labels)</span>
<span id="cb27-2"><a href="정형-데이터마이닝.html#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="정형-데이터마이닝.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values <span class="co"># AUROC</span></span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.1735986</code></pre>
</div>
</div>
</div>
<div id="분류-분석" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> 분류 분석</h2>
<p>분류 분석은 반응변수의 속성값에 대해 다양한 변수를 이용하여 모형을 구축하고 이를 사용해 새로운 자료에 대한 예측 및 분류를 수행하는 분석이다. 반응변수가 범주형인 경우의 예측 모형은 새로 입력되는 자료에 대한 분류가 주목적이며, 반응변수가 연속형인 경우에는 그 값을 예측하는 것이 주목적이다. 예측 민 분류 기법은 목표 마케팅, 성과예측, 의학진단, 사기검출, 제조 등 다양한 분야에 이용되고 있다.</p>
<div id="로지스틱-회귀분석" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> 로지스틱 회귀분석</h3>
<ul>
<li>로지스틱 회귀모형은 반응변수가 범주형인 경우에 적용되는 회귀분석 모형이다. 이 방법은 새로운 설명변수의 값이 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여, 추정 확률을 기준치에 따라분류하는 목적으로 활용된다. 이 때, 모형의 적합을 통해 추정된 확률을 사후확률 (Posterior Probability)라고 한다.</li>
<li>반응변수 y에 대한 다중 로지스틱 회귀모형은 다음과 같다.</li>
<li>로지스틱 회귀모형은 오즈(odds)의 관점에서 해석이 가능하다. exp(<span class="math inline">\(\beta_{1}\)</span>)의 의미는 나머지 변수(x<sub>1</sub>, …,x<sub>k</sub>)가 주어질 때, 한단위 증가할 때마다 성공(y=1)의 오즈가 몇 배 증가하는지를 나타내는 값이다.</li>
<li>오즈비(odds ratio) : 오즈는 성공할 확률이 실패할 확률의 몇배인지를 나타내는 확률이며, 오즈비는 오즈의 비율이다.</li>
</ul>
<div id="r을-이용한-이항-로지스틱-회귀분석" class="section level4" number="4.2.1.1">
<h4><span class="header-section-number">4.2.1.1</span> R을 이용한 이항 로지스틱 회귀분석</h4>
<p><b>[함수사용법]</b></p>
<pre><code>glm(formula, data, family=&quot;binomial&quot;...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수~독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>family</td>
<td>분석에 따른 link function 선택, binomial(이항), gaussian(가우시안), Gamma(감마), poisson(포아송) 등이 있음.</td>
</tr>
</tbody>
</table>
<pre><code>predict(model, newdata, type, ...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>model</td>
<td>개발한 모형</td>
</tr>
<tr class="even">
<td>newdata</td>
<td>예측을 수행할 test 데이터</td>
</tr>
<tr class="odd">
<td>type</td>
<td>예측 결과의 유형 지정, link(log-odds값), class(범주형(factor)값), response(0~1 확률값)</td>
</tr>
</tbody>
</table>
<p><strong>Q. credit 데이터를 분할하고, train 데이터로 로지스틱 회귀모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="정형-데이터마이닝.html#cb32-1" aria-hidden="true" tabindex="-1"></a>credit<span class="ot">&lt;-</span><span class="fu">read.csv</span>(<span class="st">&quot;./data/credit_final.csv&quot;</span>)</span>
<span id="cb32-2"><a href="정형-데이터마이닝.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(credit<span class="sc">$</span>credit.rating) <span class="co"># 종속변수 factor 변환</span></span></code></pre></div>
<pre><code>## [1] &quot;integer&quot;</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="정형-데이터마이닝.html#cb34-1" aria-hidden="true" tabindex="-1"></a>credit<span class="sc">$</span>credit.rating<span class="ot">&lt;-</span><span class="fu">factor</span>(credit<span class="sc">$</span>credit.rating)</span>
<span id="cb34-2"><a href="정형-데이터마이닝.html#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(credit)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1000 obs. of  21 variables:
##  $ credit.rating                 : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ...
##  $ account.balance               : int  1 1 2 1 1 1 1 1 3 2 ...
##  $ credit.duration.months        : int  18 9 12 12 12 10 8 6 18 24 ...
##  $ previous.credit.payment.status: int  3 3 2 3 3 3 3 3 3 2 ...
##  $ credit.purpose                : int  2 4 4 4 4 4 4 4 3 3 ...
##  $ credit.amount                 : int  1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...
##  $ savings                       : int  1 1 2 1 1 1 1 1 1 3 ...
##  $ employment.duration           : int  1 2 3 2 2 1 3 1 1 1 ...
##  $ installment.rate              : int  4 2 2 3 4 1 1 2 4 1 ...
##  $ marital.status                : int  1 3 1 3 3 3 3 3 1 1 ...
##  $ guarantor                     : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ residence.duration            : int  4 2 4 2 4 3 4 4 4 4 ...
##  $ current.assets                : int  2 1 1 1 2 1 1 1 3 4 ...
##  $ age                           : int  21 36 23 39 38 48 39 40 65 23 ...
##  $ other.credits                 : int  2 2 2 2 1 2 2 2 2 2 ...
##  $ apartment.type                : int  1 1 1 1 2 1 2 2 2 1 ...
##  $ bank.credits                  : int  1 2 1 2 2 2 2 1 2 1 ...
##  $ occupation                    : int  3 3 2 2 2 2 2 2 1 1 ...
##  $ dependents                    : int  1 2 1 2 1 2 1 2 1 1 ...
##  $ telephone                     : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ foreign.worker                : int  1 1 1 2 2 2 2 2 1 1 ...</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="정형-데이터마이닝.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb36-2"><a href="정형-데이터마이닝.html#cb36-2" aria-hidden="true" tabindex="-1"></a>idx<span class="ot">&lt;-</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(credit), <span class="fu">nrow</span>(credit)<span class="sc">*</span><span class="fl">0.7</span>, <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb36-3"><a href="정형-데이터마이닝.html#cb36-3" aria-hidden="true" tabindex="-1"></a>train<span class="ot">&lt;-</span>credit[idx,]</span>
<span id="cb36-4"><a href="정형-데이터마이닝.html#cb36-4" aria-hidden="true" tabindex="-1"></a>test<span class="ot">&lt;-</span>credit[<span class="sc">-</span>idx,]</span>
<span id="cb36-5"><a href="정형-데이터마이닝.html#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="정형-데이터마이닝.html#cb36-6" aria-hidden="true" tabindex="-1"></a>logistic<span class="ot">&lt;-</span><span class="fu">glm</span>(credit.rating<span class="sc">~</span>.,<span class="at">data=</span>train,<span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb36-7"><a href="정형-데이터마이닝.html#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logistic)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = credit.rating ~ ., family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4763  -0.7811   0.4133   0.7147   2.0078  
## 
## Coefficients:
##                                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                    -4.249e+00  1.419e+00  -2.994 0.002754 ** 
## account.balance                 8.687e-01  1.224e-01   7.096 1.28e-12 ***
## credit.duration.months         -2.145e-02  1.072e-02  -2.000 0.045501 *  
## previous.credit.payment.status  5.635e-01  1.897e-01   2.971 0.002973 ** 
## credit.purpose                 -4.133e-01  1.111e-01  -3.721 0.000198 ***
## credit.amount                  -7.722e-05  5.011e-05  -1.541 0.123341    
## savings                         3.531e-01  9.689e-02   3.645 0.000268 ***
## employment.duration             1.311e-01  1.003e-01   1.307 0.191067    
## installment.rate               -1.986e-01  1.002e-01  -1.983 0.047357 *  
## marital.status                  1.724e-01  9.722e-02   1.774 0.076139 .  
## guarantor                       6.995e-01  3.548e-01   1.971 0.048679 *  
## residence.duration             -2.940e-02  9.385e-02  -0.313 0.754063    
## current.assets                 -2.963e-01  1.075e-01  -2.757 0.005828 ** 
## age                             1.587e-02  1.009e-02   1.573 0.115623    
## other.credits                   4.845e-01  2.480e-01   1.953 0.050801 .  
## apartment.type                  4.437e-01  2.061e-01   2.152 0.031369 *  
## bank.credits                   -2.773e-01  2.391e-01  -1.160 0.246186    
## occupation                     -1.608e-01  1.672e-01  -0.962 0.335964    
## dependents                     -1.087e-01  2.831e-01  -0.384 0.700955    
## telephone                       4.068e-01  2.257e-01   1.803 0.071425 .  
## foreign.worker                  1.433e+00  8.141e-01   1.760 0.078390 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 846.57  on 699  degrees of freedom
## Residual deviance: 651.47  on 679  degrees of freedom
## AIC: 693.47
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<ul>
<li>회귀계수의 p-value가 유의수준 0.05보다 높게 나타나는 변수가 많으므로, step 함수에서 단계적 선택법을 이용하여 로지스틱 회귀분석을 다시 실시한다.</li>
</ul>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="정형-데이터마이닝.html#cb38-1" aria-hidden="true" tabindex="-1"></a>step.logistic<span class="ot">&lt;-</span><span class="fu">step</span>(<span class="fu">glm</span>(credit.rating<span class="sc">~</span><span class="dv">1</span>, <span class="at">data=</span>train, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>), </span>
<span id="cb38-2"><a href="정형-데이터마이닝.html#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">scope=</span><span class="fu">list</span>(lower<span class="sc">~</span><span class="dv">1</span>, <span class="at">upper=</span><span class="sc">~</span>account.balance<span class="sc">+</span>credit.duration.months<span class="sc">+</span>previous.credit.payment.status<span class="sc">+</span>credit.purpose<span class="sc">+</span>credit.amount<span class="sc">+</span>savings<span class="sc">+</span>employment.duration<span class="sc">+</span>installment.rate<span class="sc">+</span>marital.status<span class="sc">+</span>guarantor<span class="sc">+</span>residence.duration<span class="sc">+</span>current.assets<span class="sc">+</span>age<span class="sc">+</span>other.credits<span class="sc">+</span>apartment.type<span class="sc">+</span>bank.credits<span class="sc">+</span>occupation<span class="sc">+</span>dependents<span class="sc">+</span>telephone<span class="sc">+</span>foreign.worker), <span class="at">direction=</span><span class="st">&quot;both&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=848.57
## credit.rating ~ 1
## 
##                                  Df Deviance    AIC
## + account.balance                 1   761.97 765.97
## + savings                         1   817.12 821.12
## + credit.duration.months          1   818.40 822.40
## + previous.credit.payment.status  1   821.29 825.29
## + current.assets                  1   832.86 836.86
## + credit.amount                   1   835.30 839.30
## + age                             1   835.37 839.37
## + credit.purpose                  1   837.72 841.72
## + employment.duration             1   837.80 841.80
## + other.credits                   1   839.28 843.28
## + foreign.worker                  1   839.45 843.45
## + installment.rate                1   842.94 846.94
## + marital.status                  1   843.24 847.24
## + telephone                       1   843.75 847.75
## + apartment.type                  1   844.24 848.24
## &lt;none&gt;                                846.57 848.57
## + occupation                      1   845.33 849.33
## + guarantor                       1   845.60 849.60
## + bank.credits                    1   845.79 849.79
## + dependents                      1   846.34 850.34
## + residence.duration              1   846.39 850.39
## 
## Step:  AIC=765.97
## credit.rating ~ account.balance
## 
##                                  Df Deviance    AIC
## + credit.duration.months          1   738.84 744.84
## + previous.credit.payment.status  1   747.38 753.38
## + current.assets                  1   748.44 754.44
## + savings                         1   749.48 755.48
## + foreign.worker                  1   751.18 757.18
## + credit.purpose                  1   751.40 757.40
## + age                             1   752.09 758.09
## + credit.amount                   1   752.24 758.24
## + other.credits                   1   754.34 760.34
## + employment.duration             1   756.99 762.99
## + guarantor                       1   757.16 763.16
## + marital.status                  1   759.13 765.13
## + installment.rate                1   759.48 765.48
## &lt;none&gt;                                761.97 765.97
## + occupation                      1   760.38 766.38
## + apartment.type                  1   760.65 766.65
## + telephone                       1   760.86 766.86
## + residence.duration              1   760.91 766.91
## + dependents                      1   761.72 767.72
## + bank.credits                    1   761.95 767.95
## - account.balance                 1   846.57 848.57
## 
## Step:  AIC=744.84
## credit.rating ~ account.balance + credit.duration.months
## 
##                                  Df Deviance    AIC
## + previous.credit.payment.status  1   724.73 732.73
## + savings                         1   725.43 733.43
## + credit.purpose                  1   727.04 735.04
## + age                             1   730.32 738.32
## + foreign.worker                  1   731.34 739.34
## + employment.duration             1   732.40 740.40
## + current.assets                  1   733.16 741.16
## + other.credits                   1   733.23 741.23
## + guarantor                       1   733.69 741.69
## + marital.status                  1   734.34 742.34
## + apartment.type                  1   735.60 743.60
## + telephone                       1   735.74 743.74
## + installment.rate                1   736.81 744.81
## &lt;none&gt;                                738.84 744.84
## + residence.duration              1   737.75 745.75
## + occupation                      1   738.60 746.60
## + dependents                      1   738.69 746.69
## + bank.credits                    1   738.81 746.81
## + credit.amount                   1   738.84 746.84
## - credit.duration.months          1   761.97 765.97
## - account.balance                 1   818.40 822.40
## 
## Step:  AIC=732.73
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status
## 
##                                  Df Deviance    AIC
## + savings                         1   709.53 719.53
## + credit.purpose                  1   713.08 723.08
## + foreign.worker                  1   717.65 727.65
## + guarantor                       1   718.72 728.72
## + age                             1   719.12 729.12
## + current.assets                  1   719.90 729.90
## + employment.duration             1   720.59 730.59
## + other.credits                   1   720.85 730.85
## + bank.credits                    1   721.21 731.21
## + marital.status                  1   721.60 731.60
## + apartment.type                  1   722.13 732.13
## + telephone                       1   722.61 732.61
## + installment.rate                1   722.70 732.70
## &lt;none&gt;                                724.73 732.73
## + residence.duration              1   724.10 734.10
## + occupation                      1   724.21 734.21
## + dependents                      1   724.63 734.63
## + credit.amount                   1   724.70 734.70
## - previous.credit.payment.status  1   738.84 744.84
## - credit.duration.months          1   747.38 753.38
## - account.balance                 1   793.25 799.25
## 
## Step:  AIC=719.53
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings
## 
##                                  Df Deviance    AIC
## + credit.purpose                  1   697.86 709.86
## + guarantor                       1   701.87 713.87
## + foreign.worker                  1   703.31 715.31
## + current.assets                  1   704.12 716.12
## + age                             1   704.83 716.83
## + other.credits                   1   705.56 717.56
## + marital.status                  1   705.89 717.89
## + employment.duration             1   706.35 718.35
## + apartment.type                  1   706.49 718.49
## + bank.credits                    1   706.94 718.94
## + installment.rate                1   707.42 719.42
## &lt;none&gt;                                709.53 719.53
## + telephone                       1   708.50 720.50
## + occupation                      1   709.13 721.13
## + residence.duration              1   709.29 721.29
## + dependents                      1   709.40 721.40
## + credit.amount                   1   709.43 721.43
## - savings                         1   724.73 732.73
## - previous.credit.payment.status  1   725.43 733.43
## - credit.duration.months          1   733.39 741.39
## - account.balance                 1   760.85 768.85
## 
## Step:  AIC=709.86
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose
## 
##                                  Df Deviance    AIC
## + current.assets                  1   690.41 704.41
## + foreign.worker                  1   690.93 704.93
## + guarantor                       1   690.96 704.96
## + age                             1   692.75 706.75
## + marital.status                  1   692.89 706.89
## + employment.duration             1   694.44 708.44
## + apartment.type                  1   694.56 708.56
## + other.credits                   1   694.89 708.89
## &lt;none&gt;                                697.86 709.86
## + bank.credits                    1   696.00 710.00
## + installment.rate                1   696.12 710.12
## + occupation                      1   696.52 710.52
## + telephone                       1   696.92 710.92
## + credit.amount                   1   697.40 711.40
## + dependents                      1   697.63 711.63
## + residence.duration              1   697.77 711.77
## - credit.purpose                  1   709.53 719.53
## - savings                         1   713.08 723.08
## - previous.credit.payment.status  1   713.72 723.72
## - credit.duration.months          1   722.75 732.75
## - account.balance                 1   751.20 761.20
## 
## Step:  AIC=704.41
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets
## 
##                                  Df Deviance    AIC
## + apartment.type                  1   682.70 698.70
## + age                             1   683.31 699.31
## + foreign.worker                  1   684.57 700.57
## + guarantor                       1   684.94 700.94
## + marital.status                  1   685.00 701.00
## + employment.duration             1   686.34 702.34
## + other.credits                   1   688.09 704.09
## + telephone                       1   688.35 704.35
## &lt;none&gt;                                690.41 704.41
## + bank.credits                    1   688.64 704.64
## + installment.rate                1   689.04 705.04
## + occupation                      1   690.02 706.02
## + residence.duration              1   690.11 706.11
## + dependents                      1   690.13 706.13
## + credit.amount                   1   690.34 706.34
## - current.assets                  1   697.86 709.86
## - credit.purpose                  1   704.12 716.12
## - previous.credit.payment.status  1   705.30 717.30
## - savings                         1   706.36 718.36
## - credit.duration.months          1   706.49 718.49
## - account.balance                 1   744.08 756.08
## 
## Step:  AIC=698.7
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type
## 
##                                  Df Deviance    AIC
## + foreign.worker                  1   676.21 694.21
## + guarantor                       1   677.12 695.12
## + age                             1   678.76 696.76
## + marital.status                  1   679.37 697.37
## + employment.duration             1   679.61 697.61
## + other.credits                   1   679.81 697.81
## + installment.rate                1   680.47 698.47
## + telephone                       1   680.58 698.58
## &lt;none&gt;                                682.70 698.70
## + bank.credits                    1   681.07 699.07
## + occupation                      1   682.35 700.35
## + residence.duration              1   682.39 700.39
## + dependents                      1   682.63 700.63
## + credit.amount                   1   682.63 700.63
## - apartment.type                  1   690.41 704.41
## - current.assets                  1   694.56 708.56
## - previous.credit.payment.status  1   696.22 710.22
## - credit.purpose                  1   697.55 711.55
## - savings                         1   699.58 713.58
## - credit.duration.months          1   700.14 714.14
## - account.balance                 1   735.18 749.18
## 
## Step:  AIC=694.21
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker
## 
##                                  Df Deviance    AIC
## + guarantor                       1   672.46 692.46
## + age                             1   672.50 692.50
## + other.credits                   1   673.01 693.01
## + employment.duration             1   673.02 693.02
## + marital.status                  1   673.43 693.43
## + telephone                       1   673.89 693.89
## &lt;none&gt;                                676.21 694.21
## + installment.rate                1   674.68 694.68
## + bank.credits                    1   674.79 694.79
## + residence.duration              1   675.92 695.92
## + occupation                      1   675.94 695.94
## + credit.amount                   1   675.98 695.98
## + dependents                      1   676.17 696.17
## - foreign.worker                  1   682.70 698.70
## - apartment.type                  1   684.57 700.57
## - current.assets                  1   687.01 703.01
## - previous.credit.payment.status  1   689.51 705.51
## - credit.duration.months          1   691.63 707.63
## - credit.purpose                  1   691.85 707.85
## - savings                         1   692.44 708.44
## - account.balance                 1   730.93 746.93
## 
## Step:  AIC=692.46
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker + guarantor
## 
##                                  Df Deviance    AIC
## + age                             1   668.86 690.86
## + other.credits                   1   669.00 691.00
## + employment.duration             1   669.15 691.15
## + marital.status                  1   669.93 691.93
## + telephone                       1   670.01 692.01
## &lt;none&gt;                                672.46 692.46
## + bank.credits                    1   670.79 692.79
## + installment.rate                1   671.11 693.11
## + credit.amount                   1   672.07 694.07
## + occupation                      1   672.19 694.19
## + residence.duration              1   672.20 694.20
## - guarantor                       1   676.21 694.21
## + dependents                      1   672.43 694.43
## - foreign.worker                  1   677.12 695.12
## - apartment.type                  1   680.81 698.81
## - current.assets                  1   682.08 700.08
## - previous.credit.payment.status  1   686.53 704.53
## - credit.purpose                  1   687.00 705.00
## - credit.duration.months          1   688.83 706.83
## - savings                         1   689.97 707.97
## - account.balance                 1   729.18 747.18
## 
## Step:  AIC=690.86
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker + guarantor + age
## 
##                                  Df Deviance    AIC
## + other.credits                   1   665.40 689.40
## + marital.status                  1   666.21 690.21
## + bank.credits                    1   666.82 690.82
## &lt;none&gt;                                668.86 690.86
## + telephone                       1   666.95 690.95
## + employment.duration             1   667.09 691.09
## + installment.rate                1   667.18 691.18
## - age                             1   672.46 692.46
## + credit.amount                   1   668.46 692.46
## - guarantor                       1   672.50 692.50
## + occupation                      1   668.56 692.56
## + dependents                      1   668.86 692.86
## + residence.duration              1   668.86 692.86
## - foreign.worker                  1   673.34 693.34
## - apartment.type                  1   673.96 693.96
## - current.assets                  1   678.94 698.94
## - previous.credit.payment.status  1   680.46 700.46
## - credit.duration.months          1   683.44 703.44
## - credit.purpose                  1   683.80 703.80
## - savings                         1   685.13 705.13
## - account.balance                 1   726.24 746.24
## 
## Step:  AIC=689.4
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker + guarantor + age + other.credits
## 
##                                  Df Deviance    AIC
## + marital.status                  1   662.52 688.52
## &lt;none&gt;                                665.40 689.40
## + telephone                       1   663.54 689.54
## + employment.duration             1   663.56 689.56
## + installment.rate                1   663.60 689.60
## + bank.credits                    1   663.93 689.93
## + credit.amount                   1   664.86 690.86
## - other.credits                   1   668.86 690.86
## + occupation                      1   664.96 690.96
## - age                             1   669.00 691.00
## - guarantor                       1   669.27 691.27
## + dependents                      1   665.39 691.39
## + residence.duration              1   665.39 691.39
## - foreign.worker                  1   670.15 692.15
## - apartment.type                  1   671.10 693.10
## - current.assets                  1   674.92 696.92
## - previous.credit.payment.status  1   675.51 697.51
## - credit.purpose                  1   678.94 700.94
## - credit.duration.months          1   679.13 701.13
## - savings                         1   681.77 703.77
## - account.balance                 1   723.42 745.42
## 
## Step:  AIC=688.52
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker + guarantor + age + other.credits + marital.status
## 
##                                  Df Deviance    AIC
## + installment.rate                1   659.86 687.86
## &lt;none&gt;                                662.52 688.52
## + telephone                       1   660.70 688.70
## + bank.credits                    1   661.03 689.03
## + employment.duration             1   661.22 689.22
## - marital.status                  1   665.40 689.40
## + credit.amount                   1   662.07 690.07
## - guarantor                       1   666.10 690.10
## + occupation                      1   662.11 690.11
## - other.credits                   1   666.21 690.21
## - age                             1   666.25 690.25
## + dependents                      1   662.49 690.49
## - apartment.type                  1   666.51 690.51
## + residence.duration              1   662.52 690.52
## - foreign.worker                  1   666.90 690.90
## - current.assets                  1   671.86 695.86
## - previous.credit.payment.status  1   671.87 695.87
## - credit.purpose                  1   676.96 700.96
## - credit.duration.months          1   677.03 701.03
## - savings                         1   679.14 703.14
## - account.balance                 1   720.47 744.47
## 
## Step:  AIC=687.86
## credit.rating ~ account.balance + credit.duration.months + previous.credit.payment.status + 
##     savings + credit.purpose + current.assets + apartment.type + 
##     foreign.worker + guarantor + age + other.credits + marital.status + 
##     installment.rate
## 
##                                  Df Deviance    AIC
## &lt;none&gt;                                659.86 687.86
## + credit.amount                   1   657.88 687.88
## + telephone                       1   658.20 688.20
## + bank.credits                    1   658.44 688.44
## + employment.duration             1   658.44 688.44
## - installment.rate                1   662.52 688.52
## - guarantor                       1   663.09 689.09
## - foreign.worker                  1   663.52 689.52
## + occupation                      1   659.54 689.54
## - marital.status                  1   663.60 689.60
## - other.credits                   1   663.74 689.74
## + dependents                      1   659.77 689.77
## + residence.duration              1   659.85 689.85
## - age                             1   664.07 690.07
## - apartment.type                  1   664.22 690.22
## - previous.credit.payment.status  1   668.62 694.62
## - current.assets                  1   669.29 695.29
## - credit.purpose                  1   673.93 699.93
## - credit.duration.months          1   674.24 700.24
## - savings                         1   676.80 702.80
## - account.balance                 1   716.56 742.56</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="정형-데이터마이닝.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(step.logistic)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = credit.rating ~ account.balance + credit.duration.months + 
##     previous.credit.payment.status + savings + credit.purpose + 
##     current.assets + apartment.type + foreign.worker + guarantor + 
##     age + other.credits + marital.status + installment.rate, 
##     family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4734  -0.8128   0.4436   0.7404   1.8425  
## 
## Coefficients:
##                                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                    -4.453085   1.295853  -3.436 0.000589 ***
## account.balance                 0.877274   0.120850   7.259 3.89e-13 ***
## credit.duration.months         -0.030855   0.008188  -3.768 0.000164 ***
## previous.credit.payment.status  0.484631   0.165356   2.931 0.003381 ** 
## savings                         0.377087   0.095484   3.949 7.84e-05 ***
## credit.purpose                 -0.395226   0.108290  -3.650 0.000263 ***
## current.assets                 -0.314207   0.103329  -3.041 0.002359 ** 
## apartment.type                  0.423587   0.202868   2.088 0.036798 *  
## foreign.worker                  1.371175   0.809628   1.694 0.090344 .  
## guarantor                       0.608202   0.347239   1.752 0.079853 .  
## age                             0.019056   0.009441   2.018 0.043540 *  
## other.credits                   0.483427   0.243663   1.984 0.047256 *  
## marital.status                  0.181255   0.093959   1.929 0.053720 .  
## installment.rate               -0.146927   0.090550  -1.623 0.104674    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 846.57  on 699  degrees of freedom
## Residual deviance: 659.86  on 686  degrees of freedom
## AIC: 687.86
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<ul>
<li>총 20개의 독립변수 중 13개의 독립변수가 선택되었으며, *과 .은 각 유의확률에서 채택이 되는지를 알 수 있다. 로지스틱 회귀식은 아래와 같이 나타난다. <br/>
<span class="math inline">\(P(credit.rating)=\frac{1}{1+exp[-(-1.45+0.88account.balance+...-0.15installment.rate)]}\)</span></li>
<li>estimate가 양수이면 독립변수가 1단위 증가할 때 확률이 1에 가까워지고, estimate가 음수이면 독립변수가 1단위 증가할 때 확률이 0에 가까워진다.</li>
</ul>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="정형-데이터마이닝.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb42-2"><a href="정형-데이터마이닝.html#cb42-2" aria-hidden="true" tabindex="-1"></a>(pred<span class="ot">&lt;-</span><span class="fu">predict</span>(step.logistic, test[,<span class="sc">-</span><span class="dv">1</span>], <span class="at">type=</span><span class="st">&quot;response&quot;</span>)) <span class="co"># 예측값을 &quot;response&quot;로 지정하여 확률값을 출력</span></span></code></pre></div>
<pre><code>##         1         3         4         7         9        12        15        17 
## 0.4120408 0.6118378 0.8287752 0.9181769 0.8756254 0.6843918 0.6123956 0.7257466 
##        18        21        22        25        27        28        32        35 
## 0.8545862 0.6562587 0.8187122 0.9117270 0.3548313 0.8912199 0.6963481 0.5354274 
##        42        43        44        47        50        58        60        62 
## 0.5585623 0.8364706 0.7470300 0.7531220 0.5600975 0.8353797 0.8895306 0.7449967 
##        63        66        70        73        75        77        82        86 
## 0.9429548 0.9387643 0.8516873 0.8224228 0.9481515 0.9478558 0.9323424 0.6739541 
##        92        93        97        99       101       102       103       107 
## 0.7073080 0.2550983 0.8217615 0.6815670 0.9686422 0.2506009 0.7734371 0.9082236 
##       109       112       114       123       126       133       140       142 
## 0.5705113 0.5738746 0.8735354 0.6018558 0.9023466 0.9552089 0.9404364 0.9864618 
##       144       145       146       147       149       150       154       156 
## 0.9329562 0.7825584 0.9806404 0.7563203 0.7958647 0.7759120 0.5112201 0.8989627 
##       157       174       176       182       183       192       194       198 
## 0.2000154 0.6635239 0.8362179 0.7691743 0.2697873 0.7822958 0.9230847 0.7904401 
##       202       208       213       214       215       216       227       233 
## 0.9506486 0.8442133 0.4700817 0.9926162 0.8831600 0.9248918 0.4090421 0.8773947 
##       245       247       248       249       253       254       257       269 
## 0.9013957 0.8224225 0.9496794 0.7450681 0.8175941 0.6385456 0.6716667 0.8695574 
##       272       283       285       288       293       296       300       307 
## 0.9139702 0.9389755 0.3110148 0.9274089 0.9865352 0.7869555 0.9441139 0.7054924 
##       312       313       314       321       325       329       335       345 
## 0.9424433 0.9347673 0.4857308 0.9393010 0.9600646 0.9739688 0.9446268 0.8643433 
##       350       353       354       356       359       360       361       363 
## 0.8665074 0.7143366 0.6647453 0.9745540 0.6030884 0.9571675 0.9343947 0.9881441 
##       366       367       368       369       370       375       380       383 
## 0.8746333 0.8839657 0.6299201 0.1938767 0.4109438 0.9539802 0.9581369 0.8369876 
##       385       387       400       405       408       410       411       416 
## 0.9426122 0.7129784 0.6004036 0.7937358 0.6749529 0.8698886 0.9479245 0.7891121 
##       423       425       432       436       439       444       449       453 
## 0.8673777 0.8854057 0.9597774 0.9703585 0.2658115 0.9508754 0.8628265 0.6940124 
##       454       460       462       467       469       472       474       482 
## 0.6250801 0.9624819 0.7661106 0.9162244 0.3083106 0.8821974 0.9332950 0.7324789 
##       484       485       486       487       488       489       491       493 
## 0.9949158 0.9599063 0.8572638 0.8723732 0.9409401 0.8786549 0.8639081 0.1861704 
##       495       496       497       502       506       511       513       514 
## 0.8758798 0.8549234 0.8996813 0.8678649 0.9368716 0.9470541 0.5835893 0.7205346 
##       515       517       518       520       521       525       529       531 
## 0.7173306 0.5639953 0.5906169 0.7641548 0.6460617 0.8607718 0.7875209 0.9619511 
##       536       540       542       543       546       550       551       556 
## 0.3886664 0.4620445 0.6683025 0.7880538 0.7462993 0.9224374 0.5281521 0.6557149 
##       563       565       568       569       572       576       579       580 
## 0.2330092 0.8570038 0.8865552 0.9570444 0.9035184 0.4413908 0.6281038 0.3626785 
##       582       583       584       586       587       592       594       599 
## 0.6094103 0.8412318 0.4426206 0.6207627 0.5037450 0.4947543 0.1509256 0.6393267 
##       607       611       616       622       628       631       635       641 
## 0.9444137 0.4469861 0.4350562 0.6942851 0.9373949 0.4534486 0.1898027 0.6636863 
##       642       643       652       653       654       656       664       669 
## 0.4613032 0.6911431 0.9049479 0.8419885 0.9659676 0.8858289 0.6496323 0.8331154 
##       674       675       683       684       689       690       693       695 
## 0.8500149 0.7906134 0.9087419 0.9736985 0.8522894 0.3264172 0.7586834 0.8787157 
##       699       701       708       713       715       728       730       731 
## 0.7674790 0.7948799 0.8674318 0.9289444 0.8646000 0.7547228 0.7213844 0.5971793 
##       735       736       737       740       743       748       749       756 
## 0.5683151 0.9734926 0.6673813 0.6835835 0.7376732 0.8792291 0.7720190 0.1485896 
##       758       759       763       772       773       776       786       787 
## 0.1935449 0.2411321 0.7705442 0.3751020 0.6321914 0.1383704 0.8161353 0.5249610 
##       790       791       793       795       796       797       799       801 
## 0.5824022 0.3912481 0.3479640 0.8999023 0.3893990 0.9279937 0.2878022 0.5014722 
##       806       808       825       826       827       828       829       830 
## 0.1469686 0.2080182 0.2501811 0.7994888 0.2773739 0.6401503 0.6154802 0.4419988 
##       833       839       848       849       850       855       856       866 
## 0.7936517 0.4876081 0.1777989 0.6991339 0.7273259 0.9482981 0.1826371 0.9643884 
##       868       874       875       879       884       887       892       896 
## 0.6638910 0.6762806 0.2602226 0.3118001 0.5363162 0.2179213 0.5033415 0.7543552 
##       897       898       901       907       909       912       914       919 
## 0.9062067 0.5762438 0.5157371 0.2894535 0.6484000 0.5229902 0.1543145 0.2554326 
##       921       924       929       936       939       945       946       948 
## 0.2209400 0.3185682 0.3902414 0.7428232 0.4296006 0.6761346 0.5554851 0.9205723 
##       950       952       956       963       964       967       970       971 
## 0.9513133 0.9508658 0.6010311 0.1464600 0.3378311 0.6942551 0.3984775 0.4066565 
##       972       973       977       978       983       984       985       989 
## 0.2523158 0.9263933 0.4497004 0.4379014 0.5426059 0.1238137 0.6028227 0.2606977 
##       993       995       997       998 
## 0.9482636 0.2613449 0.5866442 0.9168300</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="정형-데이터마이닝.html#cb44-1" aria-hidden="true" tabindex="-1"></a>pred1<span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(pred)</span>
<span id="cb44-2"><a href="정형-데이터마이닝.html#cb44-2" aria-hidden="true" tabindex="-1"></a>pred1<span class="sc">$</span>grade<span class="ot">&lt;-</span><span class="fu">ifelse</span>(pred1<span class="sc">$</span>pred<span class="sc">&lt;</span><span class="fl">0.5</span>, pred1<span class="sc">$</span>grade<span class="ot">&lt;-</span><span class="dv">0</span>, pred1<span class="sc">$</span>grade<span class="ot">&lt;-</span><span class="dv">1</span>)</span>
<span id="cb44-3"><a href="정형-데이터마이닝.html#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(pred1<span class="sc">$</span>grade), <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  43  23
##          1  52 182
##                                         
##                Accuracy : 0.75          
##                  95% CI : (0.697, 0.798)
##     No Information Rate : 0.6833        
##     P-Value [Acc &gt; NIR] : 0.006892      
##                                         
##                   Kappa : 0.3708        
##                                         
##  Mcnemar&#39;s Test P-Value : 0.001224      
##                                         
##             Sensitivity : 0.8878        
##             Specificity : 0.4526        
##          Pos Pred Value : 0.7778        
##          Neg Pred Value : 0.6515        
##              Prevalence : 0.6833        
##          Detection Rate : 0.6067        
##    Detection Prevalence : 0.7800        
##       Balanced Accuracy : 0.6702        
##                                         
##        &#39;Positive&#39; Class : 1             
## </code></pre>
<ul>
<li>구축된 로지스틱 회귀모형으로 test 데이터의 기존 credit.rating 열을 제외한 데이터로 예측을 한다. 정분류율을 확인하기 전에 예측값이 확률로 나타나기 때문에 기준이 되는 확률보다 크면 1, 작으면 0으로 범주를 추가한다.</li>
<li>정분류율(Accuracy)은 0.75이며, 민감도는 0.8878로 높게 나타났다. 또 특이도는 0.4526이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="정형-데이터마이닝.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;ROCR&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb46-2"><a href="정형-데이터마이닝.html#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb46-3"><a href="정형-데이터마이닝.html#cb46-3" aria-hidden="true" tabindex="-1"></a>pred.logistic.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred1<span class="sc">$</span>grade), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb46-4"><a href="정형-데이터마이닝.html#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.logistic.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb46-5"><a href="정형-데이터마이닝.html#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="정형-데이터마이닝.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.logistic.roc,<span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6702182</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인할 결과 0.67로 나타났다.</li>
</ul>
</div>
<div id="r을-이용한-다항-로지스틱-회귀분석" class="section level4" number="4.2.1.2">
<h4><span class="header-section-number">4.2.1.2</span> R을 이용한 다항 로지스틱 회귀분석</h4>
<ul>
<li>예측하고자 하는 분류가 3개 이상이 된다면 다항 로지스틱 회귀분석을 사용한다. R에서는 <b>nnet 패키지의 multinom</b> 등의 함수로 분석을 한다.</li>
</ul>
<pre><code>multinom(formula, data)</code></pre>
<p><strong>Q. iris 데이터의 Species를 분류하는 다항 로지스틱 회귀분석을 실시하고 오분류표를 만들어 보자.</strong></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="정형-데이터마이닝.html#cb50-1" aria-hidden="true" tabindex="-1"></a>idx<span class="ot">&lt;-</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(iris), <span class="fu">nrow</span>(iris)<span class="sc">*</span><span class="fl">0.7</span>, <span class="at">replace=</span><span class="cn">FALSE</span>)</span>
<span id="cb50-2"><a href="정형-데이터마이닝.html#cb50-2" aria-hidden="true" tabindex="-1"></a>train.iris<span class="ot">&lt;-</span>iris[idx,]</span>
<span id="cb50-3"><a href="정형-데이터마이닝.html#cb50-3" aria-hidden="true" tabindex="-1"></a>test.iris<span class="ot">&lt;-</span>iris[<span class="sc">-</span>idx,]</span>
<span id="cb50-4"><a href="정형-데이터마이닝.html#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="정형-데이터마이닝.html#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb50-6"><a href="정형-데이터마이닝.html#cb50-6" aria-hidden="true" tabindex="-1"></a>mul.iris<span class="ot">&lt;-</span><span class="fu">multinom</span>(Species<span class="sc">~</span>., train.iris)</span></code></pre></div>
<pre><code>## # weights:  18 (10 variable)
## initial  value 115.354290 
## iter  10 value 11.814376
## iter  20 value 5.835729
## iter  30 value 5.729057
## iter  40 value 5.720449
## iter  50 value 5.715789
## iter  60 value 5.711880
## iter  70 value 5.708283
## iter  80 value 5.708073
## iter  90 value 5.707557
## iter 100 value 5.707382
## final  value 5.707382 
## stopped after 100 iterations</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="정형-데이터마이닝.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측을 통한 정분류율 확인</span></span>
<span id="cb52-2"><a href="정형-데이터마이닝.html#cb52-2" aria-hidden="true" tabindex="-1"></a>pred.mul<span class="ot">&lt;-</span><span class="fu">predict</span>(mul.iris, test.iris[,<span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb52-3"><a href="정형-데이터마이닝.html#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(pred.mul, test.iris[,<span class="dv">5</span>])</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         10         0
##   virginica       0          0        20
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9213, 1)
##     No Information Rate : 0.4444     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           1.0000
## Specificity                 1.0000            1.0000           1.0000
## Pos Pred Value              1.0000            1.0000           1.0000
## Neg Pred Value              1.0000            1.0000           1.0000
## Prevalence                  0.3333            0.2222           0.4444
## Detection Rate              0.3333            0.2222           0.4444
## Detection Prevalence        0.3333            0.2222           0.4444
## Balanced Accuracy           1.0000            1.0000           1.0000</code></pre>
</div>
</div>
<div id="의사결정나무" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> 의사결정나무</h3>
<ul>
<li>의사결정나무는 분류함수를 의사결정 규칙으로 이뤄진 나무 모양으로 그리는 방법이다. 계산 결과가 의사결정나무에 직접 나타나기 때문에 해석이 간편하다.</li>
<li>의사결정나무는 주어진 입력값에 대하여 출력값을 예측하는 모형으로 분류나무와 회귀나무 모형이 있다.</li>
</ul>
<div id="의사결정나무의-분석-과정" class="section level4" number="4.2.2.1">
<h4><span class="header-section-number">4.2.2.1</span> 의사결정나무의 분석 과정</h4>
<ul>
<li>의사결정나무의 형성과정은 크게 성장, 가지치기, 타당성 평가, 해석 및 예측으로 이루어진다.</li>
</ul>
<div id="성장단계" class="section level5" number="4.2.2.1.1">
<h5><span class="header-section-number">4.2.2.1.1</span> 성장단계</h5>
<ul>
<li><p>각 마디에서 적절한 최적의 분류규칙을 찾아서 나무를 성장시키는 과정으로 적절한 정지규칙을 만족하면 중단한다.</p></li>
<li><p>분리 규칙을 설정하는 분리 기준은 이산형 목표변수, 연속형 목표변수에 따라 나뉘며 아래와 같은 기준값을 사용한다.</p></li>
<li><p>이산형 목표변수</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th>기준값</th>
<th>분리기준</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>카이제곱 통계량 p값</td>
<td>p값이 가장 작은 예측변수와 그때의 최적분리에 의해서 자식마디를 형성</td>
</tr>
<tr class="even">
<td>지니 지수</td>
<td>지니 지수를 감소시켜주는 예측변수와 그 때의 최적 분리에 의해서 자식 마디를 형성</td>
</tr>
<tr class="odd">
<td>엔트로피 지수</td>
<td>엔트로피 지수가 가장 작은 예측 변수와 이 때의 최적분리에 의해 자식 마디를 형성</td>
</tr>
</tbody>
</table>
<ul>
<li>연속형 목표변수</li>
</ul>
<table>
<thead>
<tr class="header">
<th>기준값</th>
<th>분리기준</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>분산분석에서 F통계량</td>
<td>p값이 가장 작은 예측변수와 그때의 최적분리에 의해서 자식마디를 형성</td>
</tr>
<tr class="even">
<td>분산의 감소량</td>
<td>분산의 감소량을 최대화 하는 기준의 최적분리에 의해서 자식마디를 형성</td>
</tr>
</tbody>
</table>
<ul>
<li>정지규칙은 더 이상 분리가 일어나지 않고, 현재의 마디가 끝마디가 되도록 하는 규칙이며, 의사결정나무의 깊이를 지정하거나 끝마디의 레코드 수의 최소 개수를 지정한다.</li>
</ul>
</div>
<div id="가지치기-단계" class="section level5" number="4.2.2.1.2">
<h5><span class="header-section-number">4.2.2.1.2</span> 가지치기 단계</h5>
<ul>
<li>오차를 크게 할 위험이 높거나 부적절한 추론 규칙을 가지고 있는 가지 또는 불필요한 가지를 제거하는 단계이다.</li>
<li>나무의 크기를 모형의 복잡도로 볼 수 있으며, 최적의 나무 크기는 자료로부터 추정하게 된다. 일반적으로 사용되는 방법은 마디에 속하는 자료가 일정수 이하일 때 분할을 정지하고 비용-복잡도 가지치기를 이용하여 성장시킨 나무를 가지치기하게 된다.</li>
</ul>
</div>
<div id="타당성-평가-단계" class="section level5" number="4.2.2.1.3">
<h5><span class="header-section-number">4.2.2.1.3</span> 타당성 평가 단계</h5>
<ul>
<li>이익도표, 위험도표 혹은 시험자료를 이용하여 의사결정나무를 평가하는 단계이다.</li>
</ul>
</div>
<div id="해설-및-예측-단계" class="section level5" number="4.2.2.1.4">
<h5><span class="header-section-number">4.2.2.1.4</span> 해설 및 예측 단계</h5>
<ul>
<li>구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용하는 단계이다.</li>
</ul>
</div>
</div>
<div id="의사결정나무-알고리즘" class="section level4" number="4.2.2.2">
<h4><span class="header-section-number">4.2.2.2</span> 의사결정나무 알고리즘</h4>
<div id="cart-classification-and-regression-tree" class="section level5" number="4.2.2.2.1">
<h5><span class="header-section-number">4.2.2.2.1</span> CART (Classification and Regression Tree)</h5>
</div>
<div id="c4.5와-c5.0" class="section level5" number="4.2.2.2.2">
<h5><span class="header-section-number">4.2.2.2.2</span> C4.5와 C5.0</h5>
</div>
<div id="chaid-shi-squared-automatic-interaction-detection" class="section level5" number="4.2.2.2.3">
<h5><span class="header-section-number">4.2.2.2.3</span> CHAID (SHi-squared Automatic Interaction Detection)</h5>
</div>
</div>
<div id="r을-이용한-의사결정나무-분석" class="section level4" number="4.2.2.3">
<h4><span class="header-section-number">4.2.2.3</span> R을 이용한 의사결정나무 분석</h4>
<p><b>[함수사용법]</b></p>
<pre><code>rpart(formula, data, method, control=rpart.control(), ...)</code></pre>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 의사결정나무 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="정형-데이터마이닝.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb55-2"><a href="정형-데이터마이닝.html#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb55-3"><a href="정형-데이터마이닝.html#cb55-3" aria-hidden="true" tabindex="-1"></a>dt.model<span class="ot">&lt;-</span><span class="fu">rpart</span>(credit.rating<span class="sc">~</span>., <span class="at">method=</span><span class="st">&quot;class&quot;</span>, <span class="at">data=</span>train, <span class="at">control=</span><span class="fu">rpart.control</span>(<span class="at">maxdepth=</span><span class="dv">5</span>, <span class="at">minsplit=</span><span class="dv">15</span>))</span>
<span id="cb55-4"><a href="정형-데이터마이닝.html#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">prp</span>(dt.model, <span class="at">type=</span><span class="dv">4</span>, <span class="at">extra=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<ul>
<li>총 700개의 관측치 중 495개의 관측치를 1로 분류했으며, account.balance &gt;= 3인 325개의 노드 중 288이 1로 분류되었음을 의미한다. prp 함수는 rpart.plot 패키지에 속한 함수이며, type, extra 등의 인자를 사용하여 그래프의 모양을 바꿀 수 있다.</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="정형-데이터마이닝.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># rpart 함수를 활용하여 의사결정나무분석 실시 (최적 나무 선정)</span></span>
<span id="cb56-2"><a href="정형-데이터마이닝.html#cb56-2" aria-hidden="true" tabindex="-1"></a>dt.model<span class="sc">$</span>cptable</span></code></pre></div>
<pre><code>##           CP nsplit rel error    xerror       xstd
## 1 0.05365854      0 1.0000000 1.0000000 0.05873225
## 2 0.04390244      3 0.8341463 0.9853659 0.05847732
## 3 0.03414634      4 0.7902439 0.9804878 0.05839093
## 4 0.01000000      5 0.7560976 0.9756098 0.05830383</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="정형-데이터마이닝.html#cb58-1" aria-hidden="true" tabindex="-1"></a>(opt<span class="ot">&lt;-</span><span class="fu">which.min</span>(dt.model<span class="sc">$</span>cptable[,<span class="st">&quot;xerror&quot;</span>]))</span></code></pre></div>
<pre><code>## 4 
## 4</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="정형-데이터마이닝.html#cb60-1" aria-hidden="true" tabindex="-1"></a>(cp<span class="ot">&lt;-</span>dt.model<span class="sc">$</span>cptable[opt, <span class="st">&quot;CP&quot;</span>])</span></code></pre></div>
<pre><code>## [1] 0.01</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="정형-데이터마이닝.html#cb62-1" aria-hidden="true" tabindex="-1"></a>(prune.c<span class="ot">&lt;-</span><span class="fu">prune</span>(dt.model, <span class="at">cp=</span>cp))</span></code></pre></div>
<pre><code>## n= 700 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 700 205 1 (0.2928571 0.7071429)  
##    2) account.balance&lt; 2.5 375 168 1 (0.4480000 0.5520000)  
##      4) credit.duration.months&gt;=22.5 160  69 0 (0.5687500 0.4312500)  
##        8) savings&lt; 2.5 128  47 0 (0.6328125 0.3671875)  
##         16) credit.purpose&gt;=1.5 111  35 0 (0.6846847 0.3153153) *
##         17) credit.purpose&lt; 1.5 17   5 1 (0.2941176 0.7058824) *
##        9) savings&gt;=2.5 32  10 1 (0.3125000 0.6875000) *
##      5) credit.duration.months&lt; 22.5 215  77 1 (0.3581395 0.6418605)  
##       10) previous.credit.payment.status&lt; 1.5 15   3 0 (0.8000000 0.2000000) *
##       11) previous.credit.payment.status&gt;=1.5 200  65 1 (0.3250000 0.6750000) *
##    3) account.balance&gt;=2.5 325  37 1 (0.1138462 0.8861538) *</code></pre>
<ul>
<li><p>cptable 인자를 통해서 교차타당성 오차를 제공하여 의사결정나무 모델의 가지치기, 트리의 최대 크기조절에 사용한다. nsplit은 분할횟수, xerror는 해당 CP에서 cross validation 했을 때 오류율, xstd는 해당 CP에서 cross validation 했을 때 편차를 나타낸다. cptable에서 xerror가 가장 낮은 split 개수를 선택한다.</p></li>
<li><p>위 결과를 확인했을 때, xerror가 가장 낮을 때 nsplit은 5이며, 앞선 모형의 그래프를 봤을 때 의사 결정나무 모델이 분할을 5번까지 한다고 할 수 있다.</p></li>
</ul>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="정형-데이터마이닝.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(dt.model)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<ul>
<li>plotcp의 결과에서도 xerror가 가장 낮을 때 결과에 따라 교차타당성오차를 최소로 하는 트리를 형성한다. 결과적으로 나무의 크기가 6일 때 최적의 나무라고 할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="정형-데이터마이닝.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;caret&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb65-2"><a href="정형-데이터마이닝.html#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb65-3"><a href="정형-데이터마이닝.html#cb65-3" aria-hidden="true" tabindex="-1"></a>pred.dt<span class="ot">&lt;-</span><span class="fu">predict</span>(dt.model, test[,<span class="sc">-</span><span class="dv">1</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb65-4"><a href="정형-데이터마이닝.html#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.dt, <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  42  21
##          1  53 184
##                                           
##                Accuracy : 0.7533          
##                  95% CI : (0.7005, 0.8011)
##     No Information Rate : 0.6833          
##     P-Value [Acc &gt; NIR] : 0.0047614       
##                                           
##                   Kappa : 0.3734          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.0003137       
##                                           
##             Sensitivity : 0.8976          
##             Specificity : 0.4421          
##          Pos Pred Value : 0.7764          
##          Neg Pred Value : 0.6667          
##              Prevalence : 0.6833          
##          Detection Rate : 0.6133          
##    Detection Prevalence : 0.7900          
##       Balanced Accuracy : 0.6698          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>정분류율(Accuracy)은 0.7533며, 민감도는 0.8976로 높게 나타났다. 또, 특이도는 0.4421이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="정형-데이터마이닝.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC 커브 그리기 및 AUC 산출</span></span>
<span id="cb67-2"><a href="정형-데이터마이닝.html#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;ROCR&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb67-3"><a href="정형-데이터마이닝.html#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb67-4"><a href="정형-데이터마이닝.html#cb67-4" aria-hidden="true" tabindex="-1"></a>pred.dt.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.dt), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb67-5"><a href="정형-데이터마이닝.html#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.dt.roc,<span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb67-6"><a href="정형-데이터마이닝.html#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>,<span class="at">b=</span><span class="dv">1</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="정형-데이터마이닝.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.dt.roc,<span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6698331</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.6698로 나타났다.</li>
</ul>
<p><strong>Q. 앞서 분리한 iris 데이터의 Species를 분류하는 의사결정나무분석을 실시하고 오분류표를 만들어 보자.</strong></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="정형-데이터마이닝.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;rpart&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb70-2"><a href="정형-데이터마이닝.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb70-3"><a href="정형-데이터마이닝.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb70-4"><a href="정형-데이터마이닝.html#cb70-4" aria-hidden="true" tabindex="-1"></a>dt.model2<span class="ot">&lt;-</span><span class="fu">rpart</span>(Species<span class="sc">~</span>., <span class="at">data=</span>train.iris)</span>
<span id="cb70-5"><a href="정형-데이터마이닝.html#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="fu">prp</span>(dt.model2, <span class="at">type=</span><span class="dv">4</span>, <span class="at">extra=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="정형-데이터마이닝.html#cb71-1" aria-hidden="true" tabindex="-1"></a>pred.dt2<span class="ot">&lt;-</span><span class="fu">predict</span>(dt.model2, test.iris[,<span class="sc">-</span><span class="dv">5</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb71-2"><a href="정형-데이터마이닝.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.dt2, <span class="at">reference=</span>test.iris[,<span class="dv">5</span>])</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         10         1
##   virginica       0          0        19
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9778          
##                  95% CI : (0.8823, 0.9994)
##     No Information Rate : 0.4444          
##     P-Value [Acc &gt; NIR] : 8.12e-15        
##                                           
##                   Kappa : 0.9656          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.9500
## Specificity                 1.0000            0.9714           1.0000
## Pos Pred Value              1.0000            0.9091           1.0000
## Neg Pred Value              1.0000            1.0000           0.9615
## Prevalence                  0.3333            0.2222           0.4444
## Detection Rate              0.3333            0.2222           0.4222
## Detection Prevalence        0.3333            0.2444           0.4222
## Balanced Accuracy           1.0000            0.9857           0.9750</code></pre>
</div>
</div>
<div id="앙상블-기법" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> 앙상블 기법</h3>
<ul>
<li>앙상블 기법은 주어진 자료로부터 여러개의 예측모형들을 만든 후 예측모형들을 조합하여 하나의 최종 예측모형을 만드는 방법이다. 학습방법이 가장 불안전한 의사결정나무에 주로 사용한다.</li>
</ul>
<div id="배깅-bagging" class="section level4" number="4.2.3.1">
<h4><span class="header-section-number">4.2.3.1</span> 배깅 (Bagging)</h4>
<div id="개념-3" class="section level5" number="4.2.3.1.1">
<h5><span class="header-section-number">4.2.3.1.1</span> 개념</h5>
<ul>
<li>주어진 자료에서 여러개의 부트스트랩 자료를 생성하고 각 부트스트랩 자료에 예측모형을 만든후 결합하여 최종 예측모형을 만드는 방법이다.</li>
<li>보팅은 여러개의 모형으로부터 산출된 결과 중 다수결에 의해서 최종 결과를 선정하는 과정이다.</li>
<li>최적의 의사결정나무를 구축할 때 가장 어려운 부분이 가지치기이지만 배깅에서는 가지치기를 하지 않고 최대로 성정한 의사결정나무들을 활용한다.</li>
<li>훈련자료의 모집단의 분포를 모르기 때문에 실제 문제에서는 평균예측모형을 구할 수 없다. 배깅은 이러한 문제를 해결하기 위해 훈련자료를 모집단으로 생각하고 평균예측모형을 구하여 분산을 줄이고 예측력을 향상시킬 수 있다.</li>
</ul>
</div>
<div id="r을-이용한-bagging-분석" class="section level5" number="4.2.3.1.2">
<h5><span class="header-section-number">4.2.3.1.2</span> R을 이용한 Bagging 분석</h5>
<pre><code>bagging(formula, data, mfinal, control=, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자하는 데이터</td>
</tr>
<tr class="odd">
<td>mfinal</td>
<td>반복수 또는 사용할 트리의 수 (default=100)</td>
</tr>
<tr class="even">
<td>control</td>
<td>의사결정나무를 만들 때 사용할 option을 설정</td>
</tr>
</tbody>
</table>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 Bagging 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="정형-데이터마이닝.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;adabag&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb74-2"><a href="정형-데이터마이닝.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span></code></pre></div>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: doParallel</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="정형-데이터마이닝.html#cb79-1" aria-hidden="true" tabindex="-1"></a>bag<span class="ot">&lt;-</span><span class="fu">bagging</span>(credit.rating<span class="sc">~</span>., <span class="at">data=</span>train, <span class="at">mfinal=</span><span class="dv">15</span>)</span>
<span id="cb79-2"><a href="정형-데이터마이닝.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(bag)</span></code></pre></div>
<pre><code>## [1] &quot;formula&quot;    &quot;trees&quot;      &quot;votes&quot;      &quot;prob&quot;       &quot;class&quot;     
## [6] &quot;samples&quot;    &quot;importance&quot; &quot;terms&quot;      &quot;call&quot;</code></pre>
<ul>
<li>names 함수를 통해 bagging 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다.
<ul>
<li>trees: bagging을 통해 생성된 의사결정나무들을 확인할 수 있다.</li>
<li>votes: 각 의사결정나무들이 1행 데이터에 대해 1 또는 2열의 분류를 가진다는 것에 대한 투표를 진행한 것이다.</li>
<li>prob: 각 행에 대해 1 또는 2열의 특징으로 분류되는 확률을 나타내는 것이다.</li>
<li>class: bagging 기법을 활용해 각 행의 분류를 예측한 것이다.</li>
<li>samples: 각 의사결정나무에 사용된 부트스트랩 데이터의 레코드 번호를 나타낸다.</li>
<li>importance: 변수의 상대적인 중요도를 나타내며, 지니지수의 gain을 고려한 측도이다.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="정형-데이터마이닝.html#cb81-1" aria-hidden="true" tabindex="-1"></a>bag<span class="sc">$</span>importance</span></code></pre></div>
<pre><code>##                account.balance                            age 
##                     32.1612585                      9.6931394 
##                 apartment.type                   bank.credits 
##                      0.5240433                      0.7862148 
##                  credit.amount         credit.duration.months 
##                      9.5477783                      9.9671607 
##                 credit.purpose                 current.assets 
##                      4.7106811                      4.0205891 
##                     dependents            employment.duration 
##                      0.0000000                      2.6329518 
##                 foreign.worker                      guarantor 
##                      0.3666136                      3.3424176 
##               installment.rate                 marital.status 
##                      1.8668982                      1.7141508 
##                     occupation                  other.credits 
##                      1.5483235                      1.0551176 
## previous.credit.payment.status             residence.duration 
##                      6.2876622                      3.1676583 
##                        savings                      telephone 
##                      5.1833824                      1.4239586</code></pre>
<ul>
<li>importance 인자에서 변수의 상대적 중요도를 봤을 때, account.balance, credit.duration.months, age 순서로 변수 중요도가 크다는 것을 파악할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="정형-데이터마이닝.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb83-2"><a href="정형-데이터마이닝.html#cb83-2" aria-hidden="true" tabindex="-1"></a>pred.bg<span class="ot">&lt;-</span><span class="fu">predict</span>(bag, test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb83-3"><a href="정형-데이터마이닝.html#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(pred.bg<span class="sc">$</span>class), <span class="at">reference=</span>test<span class="sc">$</span>credit.rating, <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  50  31
##          1  45 174
##                                           
##                Accuracy : 0.7467          
##                  95% CI : (0.6935, 0.7949)
##     No Information Rate : 0.6833          
##     P-Value [Acc &gt; NIR] : 0.009816        
##                                           
##                   Kappa : 0.3905          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.135908        
##                                           
##             Sensitivity : 0.8488          
##             Specificity : 0.5263          
##          Pos Pred Value : 0.7945          
##          Neg Pred Value : 0.6173          
##              Prevalence : 0.6833          
##          Detection Rate : 0.5800          
##    Detection Prevalence : 0.7300          
##       Balanced Accuracy : 0.6875          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>로지스틱 회귀모형, 의사결정나무 모형과 동일한 형태로 정분류율을 확인할 수 있으며, 분석 결과에서 예측한 값의 class가 numeric형이므로 as.factor 함수를 이용하여 factor로 변형을 해야 한다.</li>
<li>정분류율은 0.7467이며, 민감도는 0.8488로 높게 나타났다. 또, 특이도는 0.5263이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="정형-데이터마이닝.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb85-2"><a href="정형-데이터마이닝.html#cb85-2" aria-hidden="true" tabindex="-1"></a>pred.bg.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.bg<span class="sc">$</span>class), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb85-3"><a href="정형-데이터마이닝.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.bg.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb85-4"><a href="정형-데이터마이닝.html#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="정형-데이터마이닝.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.bg.roc, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6875481</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.6875로 나타났다.</li>
</ul>
</div>
</div>
<div id="부스팅-boosting" class="section level4" number="4.2.3.2">
<h4><span class="header-section-number">4.2.3.2</span> 부스팅 (Boosting)</h4>
<div id="개념-4" class="section level5" number="4.2.3.2.1">
<h5><span class="header-section-number">4.2.3.2.1</span> 개념</h5>
<ul>
<li>예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법으로 Adaboost는 이진분류 문제에서 랜덤 분류기보다 조금 더 좋은 분류기 n개에 각각 가중치를 설정하고 n개의 분류기를 결합하여 최종 분류기를 만드는 방법을 제안하였다.</li>
<li>훈련오차를 빨리, 쉽게 줄일 수 있고 배깅에 비해 많은 경우 예측오차가 향상되어 Adaboost의 성능이 배깅보다 뛰어난 경우가 많다.</li>
</ul>
</div>
<div id="r을-이용한-boosting-분석" class="section level5" number="4.2.3.2.2">
<h5><span class="header-section-number">4.2.3.2.2</span> R을 이용한 Boosting 분석</h5>
<p><b>[함수사용법]</b></p>
<pre><code>boosting(formula, data, boos=TRUE/FALSE, control=, ...)</code></pre>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 Boosting 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="정형-데이터마이닝.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb89-2"><a href="정형-데이터마이닝.html#cb89-2" aria-hidden="true" tabindex="-1"></a>boost<span class="ot">&lt;-</span><span class="fu">boosting</span>(credit.rating <span class="sc">~</span> ., <span class="at">data=</span>train, <span class="at">boos=</span><span class="cn">TRUE</span>, <span class="at">mfinal=</span><span class="dv">80</span>)</span>
<span id="cb89-3"><a href="정형-데이터마이닝.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(boost)</span></code></pre></div>
<pre><code>## [1] &quot;formula&quot;    &quot;trees&quot;      &quot;weights&quot;    &quot;votes&quot;      &quot;prob&quot;      
## [6] &quot;class&quot;      &quot;importance&quot; &quot;terms&quot;      &quot;call&quot;</code></pre>
<ul>
<li>names 함수를 통해 boosting 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다.
<ul>
<li>trees: boosting을 통해 생성된 의사결정나무들을 확인할 수 있다. (80개)</li>
<li>weitgts: 각 의사결정나무에 부여된 가중치값을 확인할 수 있다.</li>
<li>votes: 각 의사결정나무들이 1행 데이터에 대해 1 또는 2열의 분류를 가진다는 것에 대한 투표를 진행한 것이다.</li>
<li>prob: 각 행에 대해 1 또는 2열의 특징으로 분류되는 확률을 나타내는 것이다.</li>
<li>class: boosting 기법을 활용해 각 행의 분류를 예측한 것이다.</li>
<li>importance: 변수의 상대적인 중요도를 나타내며, 지니지수의 gain을 고려한 측도이다.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="정형-데이터마이닝.html#cb91-1" aria-hidden="true" tabindex="-1"></a>boost<span class="sc">$</span>importance</span></code></pre></div>
<pre><code>##                account.balance                            age 
##                      5.0653036                     14.7869602 
##                 apartment.type                   bank.credits 
##                      1.8398062                      1.5915217 
##                  credit.amount         credit.duration.months 
##                     23.0980549                     10.0939561 
##                 credit.purpose                 current.assets 
##                      4.3067863                      4.6719210 
##                     dependents            employment.duration 
##                      1.3666935                      5.2701945 
##                 foreign.worker                      guarantor 
##                      0.3727978                      1.4688110 
##               installment.rate                 marital.status 
##                      3.6999734                      2.2674559 
##                     occupation                  other.credits 
##                      4.7645403                      1.6476463 
## previous.credit.payment.status             residence.duration 
##                      3.0414926                      4.7966697 
##                        savings                      telephone 
##                      4.2742639                      1.5751511</code></pre>
<ul>
<li>importance 인자에서 변수의 상대적 중요도를 봤을 때, credit.amount, age, credit.duration.months 순서로 변수 중요도가 크다는 것을 파악할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="정형-데이터마이닝.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb93-2"><a href="정형-데이터마이닝.html#cb93-2" aria-hidden="true" tabindex="-1"></a>pred.boos<span class="ot">&lt;-</span><span class="fu">predict</span>(boost, test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb93-3"><a href="정형-데이터마이닝.html#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(pred.boos<span class="sc">$</span>class), <span class="at">reference=</span>test<span class="sc">$</span>credit.rating, <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  48  39
##          1  47 166
##                                           
##                Accuracy : 0.7133          
##                  95% CI : (0.6586, 0.7638)
##     No Information Rate : 0.6833          
##     P-Value [Acc &gt; NIR] : 0.1455          
##                                           
##                   Kappa : 0.3223          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.4504          
##                                           
##             Sensitivity : 0.8098          
##             Specificity : 0.5053          
##          Pos Pred Value : 0.7793          
##          Neg Pred Value : 0.5517          
##              Prevalence : 0.6833          
##          Detection Rate : 0.5533          
##    Detection Prevalence : 0.7100          
##       Balanced Accuracy : 0.6575          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>로지스틱 회귀모형, 의사결정나무 모형과 동일한 형태로 정분류율을 확인할 수 있으며, 분석 결과에서 예측한 값의 class가 numeric형이므로 as.factor 함수를 이용하여 factor로 변형을 해야 한다.</li>
<li>정분류율은 0.7133이며, 민감도는 0.8098로 높게 나타났다. 또, 특이도는 0.5053이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="정형-데이터마이닝.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb95-2"><a href="정형-데이터마이닝.html#cb95-2" aria-hidden="true" tabindex="-1"></a>pred.boos.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.boos<span class="sc">$</span>class), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb95-3"><a href="정형-데이터마이닝.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.boos.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb95-4"><a href="정형-데이터마이닝.html#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="정형-데이터마이닝.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.boos.roc,<span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6575096</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.6575로 나타났다.</li>
</ul>
</div>
</div>
<div id="랜덤포레스트-random-forest" class="section level4" number="4.2.3.3">
<h4><span class="header-section-number">4.2.3.3</span> 랜덤포레스트 (Random Forest)</h4>
<div id="개념-5" class="section level5" number="4.2.3.3.1">
<h5><span class="header-section-number">4.2.3.3.1</span> 개념</h5>
<ul>
<li>의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법이다.</li>
<li>R프로그램에서는 randomForest 패키지로 구현이 가능하다. randomForest 함수를 사용하고 random input에 따른 forest of tree를 생성하여 이를 이용한 분류를 한다.</li>
<li>수천개의 변수를 통해 변수 제거없이 실행되므로 정확도 측면에서 좋은 성과를 보인다.</li>
<li>이론적 설명이나 최종 결과에 대한 해석이 어렵다는 단점이 있지만 예측력이 매우 높은 것으로 알려져 있다. 특히 입력변수가 많은 경우, 배깅/부스팅과 비슷하거나 좋은 예측력을 보인다.</li>
</ul>
</div>
<div id="r을-이용한-randomforest-분석" class="section level5" number="4.2.3.3.2">
<h5><span class="header-section-number">4.2.3.3.2</span> R을 이용한 RandomForest 분석</h5>
<ul>
<li>R에서 RandomForest 분석을 수행할 수 있는 함수는 randomForest 패키지의 randomForest 함수이며, 이를 이용하여 분류분석을 실시한다.</li>
</ul>
<p><b>[함수사용법]</b></p>
<pre><code>randomForest(formula, data, ntree, mtry, ...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수 ~ 독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>ntree</td>
<td>사용할 트리의 수, 너무 작은 숫자를 입력하면 예측 불가</td>
</tr>
<tr class="even">
<td>mtry</td>
<td>각 분할에서 랜덤으로 뽑힌 변수의 개수<br/>보통 classification은 sqrt(변수 개수), regression은 (변수 개수/3)</td>
</tr>
</tbody>
</table>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 randomforest 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="정형-데이터마이닝.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span></code></pre></div>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>## 
## Attaching package: &#39;randomForest&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     margin</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="정형-데이터마이닝.html#cb104-1" aria-hidden="true" tabindex="-1"></a>(rf.model<span class="ot">&lt;-</span><span class="fu">randomForest</span>(credit.rating <span class="sc">~</span> ., </span>
<span id="cb104-2"><a href="정형-데이터마이닝.html#cb104-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data=</span>train, </span>
<span id="cb104-3"><a href="정형-데이터마이닝.html#cb104-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">ntree=</span><span class="dv">50</span>, <span class="co"># 나무 50개 사용</span></span>
<span id="cb104-4"><a href="정형-데이터마이닝.html#cb104-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">mtry=</span><span class="fu">sqrt</span>(<span class="dv">20</span>), <span class="co"># 사용할 변수의 개수 (classification이므로 sqrt(20)개)</span></span>
<span id="cb104-5"><a href="정형-데이터마이닝.html#cb104-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">importance=</span><span class="cn">TRUE</span>) <span class="co"># 변수중요도를 결과를 확인</span></span>
<span id="cb104-6"><a href="정형-데이터마이닝.html#cb104-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = credit.rating ~ ., data = train, ntree = 50,      mtry = sqrt(20), importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 50
## No. of variables tried at each split: 4
## 
##         OOB estimate of  error rate: 25.43%
## Confusion matrix:
##    0   1 class.error
## 0 88 117   0.5707317
## 1 61 434   0.1232323</code></pre>
<ul>
<li>랜덤포레스트 분석 결과에서 “OOB estimate of error rate”의 값은 에러 추정치로서 값이 낮을수록 분류모델의 성능이 좋다고 판단할 수 있다. Confusion matrix의 결과에서 class.error값으로 분류 에러를 통해 모델 성능을 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="정형-데이터마이닝.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(rf.model)</span></code></pre></div>
<pre><code>##  [1] &quot;call&quot;            &quot;type&quot;            &quot;predicted&quot;       &quot;err.rate&quot;       
##  [5] &quot;confusion&quot;       &quot;votes&quot;           &quot;oob.times&quot;       &quot;classes&quot;        
##  [9] &quot;importance&quot;      &quot;importanceSD&quot;    &quot;localImportance&quot; &quot;proximity&quot;      
## [13] &quot;ntree&quot;           &quot;mtry&quot;            &quot;forest&quot;          &quot;y&quot;              
## [17] &quot;test&quot;            &quot;inbag&quot;           &quot;terms&quot;</code></pre>
<ul>
<li>names 함수를 통해 randomForest 함수로 생성된 결과들에 어떤 것들이 있는지 확인이 가능하다. 주로 사용하는 인자들에 대한 설명은 아래와 같다.
<ul>
<li>predicted: Out-of-bag samples에 기초한 예측값을 확인할 수 있다.</li>
<li>err.rate: 입력데이터 각각에 대한 예측 오류율을 확인할 수 있다.</li>
<li>importance: 변수 중요도를 나타내며 Gini값을 기준으로 한다. MeanDecreaseAccuracy와 MeanDecreaseGini 모두 값이 클수록 중요도가 높다고 해석할 수 있다.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="정형-데이터마이닝.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.model)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<ul>
<li>varImpPlot 함수로 importance 인자 결과를 시각화할 수 있다. 변수의 상대적 중요도를 Mean DecreaseGini를 기준으로 봤을 때, credit.amout, age, account.balance 순서로 변수 중요도가 크다는 것을 파악할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="정형-데이터마이닝.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb109-2"><a href="정형-데이터마이닝.html#cb109-2" aria-hidden="true" tabindex="-1"></a>pred.rf<span class="ot">&lt;-</span><span class="fu">predict</span>(rf.model, test[,<span class="sc">-</span><span class="dv">1</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb109-3"><a href="정형-데이터마이닝.html#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.rf, <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  44  21
##          1  51 184
##                                           
##                Accuracy : 0.76            
##                  95% CI : (0.7076, 0.8072)
##     No Information Rate : 0.6833          
##     P-Value [Acc &gt; NIR] : 0.0021620       
##                                           
##                   Kappa : 0.3941          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.0006316       
##                                           
##             Sensitivity : 0.8976          
##             Specificity : 0.4632          
##          Pos Pred Value : 0.7830          
##          Neg Pred Value : 0.6769          
##              Prevalence : 0.6833          
##          Detection Rate : 0.6133          
##    Detection Prevalence : 0.7833          
##       Balanced Accuracy : 0.6804          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>정분류율은 0.76이며, 민감도는 0.8976으로 높게 나타났다. 또 특이도는 0.4632이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="정형-데이터마이닝.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb111-2"><a href="정형-데이터마이닝.html#cb111-2" aria-hidden="true" tabindex="-1"></a>pred.rf.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.rf), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb111-3"><a href="정형-데이터마이닝.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.rf.roc,<span class="st">&quot;tpr&quot;</span>,<span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb111-4"><a href="정형-데이터마이닝.html#cb111-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>,<span class="at">b=</span><span class="dv">1</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="정형-데이터마이닝.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.rf.roc, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values[[<span class="dv">1</span>]]</span></code></pre></div>
<pre><code>## [1] 0.6803594</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.6804로 나타났다.</li>
</ul>
<p><strong>Q. 앞서 분리한 iris 데이터의 Species를 분류하는 랜덤포레스트분석을 실시하고 오분류표를 만들어 보자.</strong></p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="정형-데이터마이닝.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb114-2"><a href="정형-데이터마이닝.html#cb114-2" aria-hidden="true" tabindex="-1"></a>(rf.model2<span class="ot">&lt;-</span><span class="fu">randomForest</span>(Species <span class="sc">~</span> ., <span class="at">data=</span>train.iris, <span class="at">ntree=</span><span class="dv">50</span>, <span class="at">mtry=</span><span class="fu">sqrt</span>(<span class="dv">4</span>), <span class="at">importance=</span><span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = train.iris, ntree = 50,      mtry = sqrt(4), importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 50
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 6.67%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         35          0         0   0.0000000
## versicolor      0         37         3   0.0750000
## virginica       0          4        26   0.1333333</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="정형-데이터마이닝.html#cb116-1" aria-hidden="true" tabindex="-1"></a>pred.rf2<span class="ot">&lt;-</span><span class="fu">predict</span>(rf.model2, test.iris[,<span class="sc">-</span><span class="dv">5</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb116-2"><a href="정형-데이터마이닝.html#cb116-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.rf2, <span class="at">reference=</span>test.iris[,<span class="dv">5</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0         10         1
##   virginica       0          0        19
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9778          
##                  95% CI : (0.8823, 0.9994)
##     No Information Rate : 0.4444          
##     P-Value [Acc &gt; NIR] : 8.12e-15        
##                                           
##                   Kappa : 0.9656          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.9500
## Specificity                 1.0000            0.9714           1.0000
## Pos Pred Value              1.0000            0.9091           1.0000
## Neg Pred Value              1.0000            1.0000           0.9615
## Prevalence                  0.3333            0.2222           0.4444
## Detection Rate              0.3333            0.2222           0.4222
## Detection Prevalence        0.3333            0.2444           0.4222
## Balanced Accuracy           1.0000            0.9857           0.9750</code></pre>
</div>
</div>
</div>
<div id="svm-support-vector-machine" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> SVM (Support Vector Machine)</h3>
<ul>
<li>서포트 벡터 머신은 기계학습 분야 중 하나로 패턴인식, 자료 분석 등을 위한 지도학습 모델이며 주로 회귀와 분류 문제 해결에 사용된다.</li>
<li>서포트 벡터 머신 알고리즘은 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어떤 범주에 속할 것인지를 판단하는 <b>비확률적 이진 선형 분류 모델을 생성</b>한다.</li>
</ul>
<div id="작동-원리" class="section level4" number="4.2.4.1">
<h4><span class="header-section-number">4.2.4.1</span> 작동 원리</h4>
<ul>
<li>데이터의 각 그룹을 구분하는 분류자를 <b>결정 초평면</b>, 각 그룹에 속한 데이터들 중에서도 초평면에 가장 가까이에 붙어 있는 최정방 데이터들을 <b>서포트 벡터</b>, 서포트 벡터와 초평면 사이의 수직거리를 <b>마진</b>이라고 한다.</li>
<li>SVM은 고차원 혹은 무한 차원의 공간에서 <b>마진을 최대화하는 초평면 (MMH, Maximum Margin Hyperplane: 최대마진 초평면) 을 찾아 분류와 회귀를 수행</b>한다.</li>
<li>SVM 모형은 선형 분류뿐만 아니라 <b>비선형 분류</b>에서도 사용되는데, 비선형 분류에서는 입력자료를 다차원 공간상으로 매핑할 때 <b>커널 트릭</b>을 사용하기도 한다.</li>
</ul>
</div>
<div id="r을-이용한-svm-분석" class="section level4" number="4.2.4.2">
<h4><span class="header-section-number">4.2.4.2</span> R을 이용한 SVM 분석</h4>
<p><b>[함수사용법]</b></p>
<pre><code>svm(formula, data, kernel, gamma, cost, ...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수 ~ 독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>kernel</td>
<td>훈련과 예측에 사용되는 커널<br/>“radial”,“linear”,“polynomial”,“sigmoid”가 있음.<br/>실제 문제에서 커널의 선택이 결과의 정확도에 큰 영향을 주지 않음.</td>
</tr>
<tr class="even">
<td>gamma</td>
<td>초평면의 기울기, default=1/(데이터차원)</td>
</tr>
<tr class="odd">
<td>cost</td>
<td>과적합을 막는 정도, default=1</td>
</tr>
</tbody>
</table>
<pre><code>tune.svm(formula, data, kernel, gamma, cost, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수 ~ 독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>gamma</td>
<td>초평면의 기울기</td>
</tr>
<tr class="even">
<td>cost</td>
<td>과적합을 막는 정도</td>
</tr>
</tbody>
</table>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터를 이용하여 tune.svm 함수로 최적의 파라미터를 찾고 SVM 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="정형-데이터마이닝.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;e1071&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb120-2"><a href="정형-데이터마이닝.html#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb120-3"><a href="정형-데이터마이닝.html#cb120-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tune.svm</span>(credit.rating <span class="sc">~</span> ., <span class="at">data=</span>credit, <span class="at">gamma =</span> <span class="dv">10</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">6</span><span class="sc">:-</span><span class="dv">1</span>), <span class="at">cost =</span> <span class="dv">10</span><span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  gamma cost
##   0.01   10
## 
## - best performance: 0.229</code></pre>
<ul>
<li>tune.svm 함수에서 gamma와 cost의 주어진 범위 내에서 최적값을 찾아준다. 여기서는 gamma 6개, cost 2개, 즉 6 * 12개의 조합에서 모수조율이 이루어진다. 분석결과에서 best parameters를 통해 gamma는 0.01, cost는 10이 최적의 파라미터임을 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="정형-데이터마이닝.html#cb122-1" aria-hidden="true" tabindex="-1"></a>svm.model<span class="ot">&lt;-</span><span class="fu">svm</span>(credit.rating<span class="sc">~</span>., <span class="at">data=</span>train, <span class="at">kernel=</span><span class="st">&quot;radial&quot;</span>, <span class="at">gamma=</span><span class="fl">0.01</span>, <span class="at">cost=</span><span class="dv">10</span>)</span>
<span id="cb122-2"><a href="정형-데이터마이닝.html#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(svm.model)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = credit.rating ~ ., data = train, kernel = &quot;radial&quot;, 
##     gamma = 0.01, cost = 10)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  10 
## 
## Number of Support Vectors:  389
## 
##  ( 212 177 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  0 1</code></pre>
<ul>
<li>svm 함수에서 gamma와 cost를 설정하고, kernel을 “radial”으로 지정한다. kernel은 radial (가우시안 RBF)이 default로 되어 있다. summary 함수로 svm 모델의 cost값과 Support Vectors의 수(train 데이터 수)를 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="정형-데이터마이닝.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측을 통한 정분류를 확인</span></span>
<span id="cb124-2"><a href="정형-데이터마이닝.html#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;caret&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb124-3"><a href="정형-데이터마이닝.html#cb124-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb124-4"><a href="정형-데이터마이닝.html#cb124-4" aria-hidden="true" tabindex="-1"></a>pred.svm<span class="ot">&lt;-</span><span class="fu">predict</span>(svm.model, test, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb124-5"><a href="정형-데이터마이닝.html#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.svm, <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  52  31
##          1  43 174
##                                           
##                Accuracy : 0.7533          
##                  95% CI : (0.7005, 0.8011)
##     No Information Rate : 0.6833          
##     P-Value [Acc &gt; NIR] : 0.004761        
##                                           
##                   Kappa : 0.41            
##                                           
##  Mcnemar&#39;s Test P-Value : 0.200994        
##                                           
##             Sensitivity : 0.8488          
##             Specificity : 0.5474          
##          Pos Pred Value : 0.8018          
##          Neg Pred Value : 0.6265          
##              Prevalence : 0.6833          
##          Detection Rate : 0.5800          
##    Detection Prevalence : 0.7233          
##       Balanced Accuracy : 0.6981          
##                                           
##        &#39;Positive&#39; Class : 1               
## </code></pre>
<ul>
<li>정분류율을 0.7533이며, 민감도는 0.8488로 높게 나타났다. 또, 특이도는 0.5474이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="정형-데이터마이닝.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;ROCR&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb126-2"><a href="정형-데이터마이닝.html#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb126-3"><a href="정형-데이터마이닝.html#cb126-3" aria-hidden="true" tabindex="-1"></a>pred.svm.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.svm), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb126-4"><a href="정형-데이터마이닝.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.svm.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb126-5"><a href="정형-데이터마이닝.html#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="정형-데이터마이닝.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.svm.roc, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6980745</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values</span> 값으로 확인한 결과 0.6981로 나타났다.</li>
</ul>
<p><strong>Q. 앞서 분리한 iris 데이터의 Species를 분류하는 SVM 분석을 실시하고 오분류표를 만들어 보자.</strong></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="정형-데이터마이닝.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;e1071&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb129-2"><a href="정형-데이터마이닝.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb129-3"><a href="정형-데이터마이닝.html#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tune.svm</span>(Species <span class="sc">~</span> ., <span class="at">data=</span>iris, <span class="at">gamma=</span><span class="dv">2</span><span class="sc">^</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>), <span class="at">cost=</span><span class="dv">2</span><span class="sc">^</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>))</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  gamma cost
##    0.5   16
## 
## - best performance: 0.04</code></pre>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="정형-데이터마이닝.html#cb131-1" aria-hidden="true" tabindex="-1"></a>svm.model2<span class="ot">&lt;-</span><span class="fu">svm</span>(Species<span class="sc">~</span>., <span class="at">data=</span>train.iris, <span class="at">kernel=</span><span class="st">&quot;radial&quot;</span>, <span class="at">gamma=</span><span class="fl">0.5</span>, <span class="at">cost=</span><span class="dv">16</span>)</span>
<span id="cb131-2"><a href="정형-데이터마이닝.html#cb131-2" aria-hidden="true" tabindex="-1"></a>pred.svm2<span class="ot">&lt;-</span><span class="fu">predict</span>(svm.model2, test.iris, <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb131-3"><a href="정형-데이터마이닝.html#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.svm2, <span class="at">reference=</span>test.iris[,<span class="dv">5</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         15          0         0
##   versicolor      0          9         1
##   virginica       0          1        19
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9556          
##                  95% CI : (0.8485, 0.9946)
##     No Information Rate : 0.4444          
##     P-Value [Acc &gt; NIR] : 2.275e-13       
##                                           
##                   Kappa : 0.9308          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            0.9000           0.9500
## Specificity                 1.0000            0.9714           0.9600
## Pos Pred Value              1.0000            0.9000           0.9500
## Neg Pred Value              1.0000            0.9714           0.9600
## Prevalence                  0.3333            0.2222           0.4444
## Detection Rate              0.3333            0.2000           0.4222
## Detection Prevalence        0.3333            0.2222           0.4444
## Balanced Accuracy           1.0000            0.9357           0.9550</code></pre>
</div>
</div>
<div id="나이브-베이즈-분류" class="section level3" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> 나이브 베이즈 분류</h3>
<ul>
<li>나이브 베이즈 분류는 데이터에서 변수들에 대한 조건부 독립을 가정하는 알고리즘으로 클래스에 대한 사전 정보와 데이터로부터 추출된 정보를 결합하고, 베이즈 정리를 이용하여 특정 데이터가 어떤 클래스에 속하는지를 분류하는 알고리즘이다.</li>
<li>텍스트 분류에서 문서를 여러 범주중 하나로 판단하는 문제에 대한 솔루션으로 사용될 수 있다.</li>
</ul>
<div id="bayes-theorem" class="section level4" number="4.2.5.1">
<h4><span class="header-section-number">4.2.5.1</span> Bayes theorem</h4>
<ul>
<li><p>나이브 베이즈 알고리즘의 기본이 되는 개념으로, 두 확률 변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리이다.</p></li>
<li><p>사건 A와 B가 있을 때, 사건 B가 일어난 것을 전제로 한 사건 A의 조건부 확률을 구하고자 한다. 하지만 현재 가지고 있는 정보는 사건 A가 일어난 것을 전제로 한 사건 B의 조건부 확률, A의 확률, B의 확률뿐이다. 이때, 원래 구하고자 했던 ’사건 B가 일어난 것을 전제로 한 사건 A의 조건부 확률’을 다음과 같이 구할 수 있다는 것이 베이즈 정리이다. <br />
<span class="math inline">\(P(A|B) = \frac{P(B \cap A)}{P(B)} = \frac{P(A)P(B|A)}{P(B)}=\frac{P(A)P(B|A)}{P(A)P(B|A)+P(A^{C}P(B|A^{C}))}\)</span></p></li>
<li><p><span class="math inline">\(P(A|B)\)</span> : 사건 B가 발생했을 때 사건 A가 발생할 확률 -&gt; 사후확률 (posterior)</p></li>
<li><p><span class="math inline">\(P(B|A)\)</span> : 사건 A가 발생했을 때 사건 B가 발생할 확률 -&gt; 우도 (likelihood)</p></li>
<li><p><span class="math inline">\(P(A \cap B)\)</span> : 사건 A와 B가 동시에 발생할 확률</p></li>
<li><p><span class="math inline">\(P(A)\)</span> : 사건 A가 발생할 확률 -&gt; 사전확률 (prior)</p></li>
<li><p><span class="math inline">\(P(B)\)</span> : 사건 B가 발생할 화률 -&gt; 관찰값 (evidence)</p></li>
<li><p>위 식을 다음과 같은 식으로도 표현이 가능하다. <br /><span class="math inline">\(posterior = \frac{prior\times likelihood}{evidence}\)</span></p></li>
</ul>
</div>
<div id="나이브-베이즈-분류-1" class="section level4" number="4.2.5.2">
<h4><span class="header-section-number">4.2.5.2</span> 나이브 베이즈 분류</h4>
<ul>
<li>나이브 베이즈 분류는 하나의 속성값을 기준으로 다른 속성이 독립적이라 전제했을 때 해당 속성 값이 클래스 분류에 미치는 영향을 측정한다.</li>
<li>속성값에 대해 다른 속성이 독립적이라는 가정은<b>클래스 조건 독립성</b>이라 한다.</li>
</ul>
</div>
<div id="r을-이용한-나이브-베이즈-분류-분석" class="section level4" number="4.2.5.3">
<h4><span class="header-section-number">4.2.5.3</span> R을 이용한 나이브 베이즈 분류 분석</h4>
<p><b>함수사용법</b></p>
<pre><code>naiveBayes(formula, data, laplace=0, ...)</code></pre>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 나이브 베이즈 분류 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="정형-데이터마이닝.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(e1071)</span>
<span id="cb134-2"><a href="정형-데이터마이닝.html#cb134-2" aria-hidden="true" tabindex="-1"></a>nb.model<span class="ot">&lt;-</span><span class="fu">naiveBayes</span>(credit.rating<span class="sc">~</span>., <span class="at">data=</span>train, <span class="at">laplace=</span><span class="dv">0</span>)</span>
<span id="cb134-3"><a href="정형-데이터마이닝.html#cb134-3" aria-hidden="true" tabindex="-1"></a>nb.model</span></code></pre></div>
<pre><code>## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##         0         1 
## 0.2928571 0.7071429 
## 
## Conditional probabilities:
##    account.balance
## Y       [,1]      [,2]
##   0 1.746341 0.7436323
##   1 2.381818 0.7983236
## 
##    credit.duration.months
## Y       [,1]     [,2]
##   0 24.37073 13.31920
##   1 18.99192 11.00404
## 
##    previous.credit.payment.status
## Y       [,1]      [,2]
##   0 2.126829 0.6211250
##   1 2.375758 0.5728491
## 
##    credit.purpose
## Y       [,1]      [,2]
##   0 3.102439 0.8768504
##   1 2.868687 0.9841504
## 
##    credit.amount
## Y       [,1]     [,2]
##   0 3765.078 3338.421
##   1 2974.749 2453.003
## 
##    savings
## Y       [,1]      [,2]
##   0 1.497561 0.9631667
##   1 2.008081 1.2288434
## 
##    employment.duration
## Y       [,1]     [,2]
##   0 2.263415 1.088657
##   1 2.529293 1.079178
## 
##    installment.rate
## Y       [,1]     [,2]
##   0 3.112195 1.067385
##   1 2.937374 1.130242
## 
##    marital.status
## Y       [,1]     [,2]
##   0 2.224390 1.097408
##   1 2.385859 1.046781
## 
##    guarantor
## Y       [,1]      [,2]
##   0 1.082927 0.2764467
##   1 1.107071 0.3095159
## 
##    residence.duration
## Y       [,1]     [,2]
##   0 2.814634 1.077752
##   1 2.852525 1.105960
## 
##    current.assets
## Y       [,1]     [,2]
##   0 2.580488 1.043002
##   1 2.258586 1.040575
## 
##    age
## Y       [,1]     [,2]
##   0 33.16098 11.01730
##   1 36.25051 11.45939
## 
##    other.credits
## Y       [,1]      [,2]
##   0 1.760976 0.4275317
##   1 1.848485 0.3589130
## 
##    apartment.type
## Y       [,1]      [,2]
##   0 1.863415 0.5948126
##   1 1.929293 0.4856759
## 
##    bank.credits
## Y       [,1]      [,2]
##   0 1.326829 0.4702025
##   1 1.361616 0.4809545
## 
##    occupation
## Y       [,1]      [,2]
##   0 2.931707 0.6456639
##   1 2.872727 0.6378446
## 
##    dependents
## Y       [,1]      [,2]
##   0 1.141463 0.3493521
##   1 1.155556 0.3628001
## 
##    telephone
## Y       [,1]      [,2]
##   0 1.346341 0.4769683
##   1 1.414141 0.4930714
## 
##    foreign.worker
## Y       [,1]       [,2]
##   0 1.009756 0.09853057
##   1 1.046465 0.21070209</code></pre>
<ul>
<li>분석 결과에서 A-priori probabilities는 사전확률을 나타내고 있으며, Conditional probabilities로 각 변수에 대해 조건부 확률을 표로 제공하고 있다. 수치형 변수의 경우 평균, 표준편차를 제공한다.</li>
</ul>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="정형-데이터마이닝.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측을 통한 정분류율 확인</span></span>
<span id="cb136-2"><a href="정형-데이터마이닝.html#cb136-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb136-3"><a href="정형-데이터마이닝.html#cb136-3" aria-hidden="true" tabindex="-1"></a>pred.nb<span class="ot">&lt;-</span><span class="fu">predict</span>(nb.model, test[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb136-4"><a href="정형-데이터마이닝.html#cb136-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>pred.nb, <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  65  53
##          1  30 152
##                                          
##                Accuracy : 0.7233         
##                  95% CI : (0.669, 0.7732)
##     No Information Rate : 0.6833         
##     P-Value [Acc &gt; NIR] : 0.07551        
##                                          
##                   Kappa : 0.3997         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.01574        
##                                          
##             Sensitivity : 0.7415         
##             Specificity : 0.6842         
##          Pos Pred Value : 0.8352         
##          Neg Pred Value : 0.5508         
##              Prevalence : 0.6833         
##          Detection Rate : 0.5067         
##    Detection Prevalence : 0.6067         
##       Balanced Accuracy : 0.7128         
##                                          
##        &#39;Positive&#39; Class : 1              
## </code></pre>
<ul>
<li>정분류율(Accuracy)은 0.7233이며, 민감도(Sensitivity)는 0.7415로 높게 나타났다. 또, 특이도 (Specificity)는 0.6842이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="정형-데이터마이닝.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;ROCR&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb138-2"><a href="정형-데이터마이닝.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb138-3"><a href="정형-데이터마이닝.html#cb138-3" aria-hidden="true" tabindex="-1"></a>pred.nb.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.nb), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb138-4"><a href="정형-데이터마이닝.html#cb138-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.nb.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb138-5"><a href="정형-데이터마이닝.html#cb138-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="정형-데이터마이닝.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.nb.roc, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.712837</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.7128로 나타났다.</li>
</ul>
</div>
</div>
<div id="k-nn-k-nearest-neighbor" class="section level3" number="4.2.6">
<h3><span class="header-section-number">4.2.6</span> K-NN (K-Nearest Neighbor)</h3>
<ul>
<li>K-NN은 어떤 범주로 나누어져 있는 데이터셋이 있을 때, 새로운 데이터가 추가된다면 이를 어떤 범주로 분류할 것인지를 결정할 때 사용할 수 있는 분류 알고리즘으로 지도학습 (Supervised Learning)의 한 종류이다.</li>
</ul>
<div id="k-nn-알고리즘의-원리" class="section level4" number="4.2.6.1">
<h4><span class="header-section-number">4.2.6.1</span> K-NN 알고리즘의 원리</h4>
<ul>
<li>K-NN 알고리즘에서는 새로운 데이터의 클래스를 해당 데이터와 가장 가까운 K개 데이터들의 클래스(범주)로 결정한다.</li>
<li>K-NN 알고리즘에서는 최근접 이웃 간의 거리를 계산할 때 유클리디안 거리, 맨하탄 거리, 민코우스키 거리 등을 사용할 수 있으며, 대표적으로 유클리디안 거리를 사용한다.</li>
</ul>
</div>
<div id="k의-선택" class="section level4" number="4.2.6.2">
<h4><span class="header-section-number">4.2.6.2</span> K의 선택</h4>
<ul>
<li>K의 선택은 학습의 난이도와 데이터의 개수에 따라 결정될 수 있으며, 일반적으로는 훈련 데이터 개수의 제곱근으로 설정한다. 그리고 k를 짝수로 했을 때, 인접객체의 범주가 동률일 경우가 나오므로 반드시 홀수의 값으로 k를 선택하는 것이 중요하다.</li>
<li>K를 너무 크게 설정할 경우 주변에 있는 데이터와 근접성이 떨어져 클러스터링이 잘 이루어지지 않고, 너무 작게 설정할 경우 이상치 혹은 잡음 데이터와 이웃이 될 가능성이 있으므로 적절한 k를 선택하는 것이 중요하다.</li>
</ul>
</div>
<div id="r을-이용한-k-nn-분석" class="section level4" number="4.2.6.3">
<h4><span class="header-section-number">4.2.6.3</span> R을 이용한 K-NN 분석</h4>
<ul>
<li>knn 분석 이전에 훈련, 데스트 데이터의 종속변수를 제외한 뒤에 분석을 실시한다. 그리고 거리를 이용한 분석이므로 데이터의 형태가 범주형 변수가 아닌 수치형으로 변환되어야 한다.</li>
</ul>
<p><b>함수사용법</b></p>
<pre><code>knn(train, test, cl, k, ...)</code></pre>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 K-NN 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="정형-데이터마이닝.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb142-2"><a href="정형-데이터마이닝.html#cb142-2" aria-hidden="true" tabindex="-1"></a>train.data<span class="ot">&lt;-</span>train[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb142-3"><a href="정형-데이터마이닝.html#cb142-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(train.data)</span></code></pre></div>
<pre><code>##     account.balance credit.duration.months previous.credit.payment.status
## 415               3                     12                              3
## 463               3                     15                              2
## 179               3                     18                              2
## 526               3                     36                              3
## 195               3                     12                              2
## 938               2                     18                              3
##     credit.purpose credit.amount savings employment.duration installment.rate
## 415              3           522       3                   4                4
## 463              1          3812       2                   1                1
## 179              4          1950       1                   3                4
## 526              3          9566       1                   2                2
## 195              3          1262       1                   2                3
## 938              4           884       1                   4                4
##     marital.status guarantor residence.duration current.assets age
## 415              3         1                  4              2  42
## 463              1         1                  4              3  23
## 179              3         1                  1              3  34
## 526              1         1                  2              3  31
## 195              3         1                  2              3  25
## 938              3         1                  4              3  36
##     other.credits apartment.type bank.credits occupation dependents telephone
## 415             2              2            2          3          2         2
## 463             2              2            1          3          1         2
## 179             1              2            2          3          1         2
## 526             1              2            2          3          1         1
## 195             2              2            1          3          1         1
## 938             2              2            1          3          2         2
##     foreign.worker
## 415              1
## 463              1
## 179              1
## 526              1
## 195              1
## 938              1</code></pre>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="정형-데이터마이닝.html#cb144-1" aria-hidden="true" tabindex="-1"></a>test.data<span class="ot">&lt;-</span>test[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb144-2"><a href="정형-데이터마이닝.html#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(test.data)</span></code></pre></div>
<pre><code>##    account.balance credit.duration.months previous.credit.payment.status
## 1                1                     18                              3
## 3                2                     12                              2
## 4                1                     12                              3
## 7                1                      8                              3
## 9                3                     18                              3
## 12               1                     30                              3
##    credit.purpose credit.amount savings employment.duration installment.rate
## 1               2          1049       1                   1                4
## 3               4           841       2                   3                2
## 4               4          2122       1                   2                3
## 7               4          3398       1                   3                1
## 9               3          1098       1                   1                4
## 12              1          6187       2                   3                1
##    marital.status guarantor residence.duration current.assets age other.credits
## 1               1         1                  4              2  21             2
## 3               1         1                  4              1  23             2
## 4               3         1                  2              1  39             2
## 7               3         1                  4              1  39             2
## 9               1         1                  4              3  65             2
## 12              4         1                  4              3  24             2
##    apartment.type bank.credits occupation dependents telephone foreign.worker
## 1               1            1          3          1         1              1
## 3               1            1          2          1         1              1
## 4               1            2          2          2         1              2
## 7               2            2          2          1         1              2
## 9               2            2          1          1         1              1
## 12              1            2          3          1         1              1</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="정형-데이터마이닝.html#cb146-1" aria-hidden="true" tabindex="-1"></a>class<span class="ot">&lt;-</span>train[,<span class="dv">1</span>]</span>
<span id="cb146-2"><a href="정형-데이터마이닝.html#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(class)</span></code></pre></div>
<pre><code>## [1] 1 1 1 1 1 0
## Levels: 0 1</code></pre>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="정형-데이터마이닝.html#cb148-1" aria-hidden="true" tabindex="-1"></a>knn<span class="fl">.3</span><span class="ot">&lt;-</span><span class="fu">knn</span>(train.data, test.data, class, <span class="at">k=</span><span class="dv">3</span>)</span>
<span id="cb148-2"><a href="정형-데이터마이닝.html#cb148-2" aria-hidden="true" tabindex="-1"></a>knn<span class="fl">.7</span><span class="ot">&lt;-</span><span class="fu">knn</span>(train.data, test.data, class, <span class="at">k=</span><span class="dv">7</span>)</span>
<span id="cb148-3"><a href="정형-데이터마이닝.html#cb148-3" aria-hidden="true" tabindex="-1"></a>knn<span class="fl">.10</span><span class="ot">&lt;-</span><span class="fu">knn</span>(train.data, test.data, class, <span class="at">k=</span><span class="dv">10</span>)</span>
<span id="cb148-4"><a href="정형-데이터마이닝.html#cb148-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb148-5"><a href="정형-데이터마이닝.html#cb148-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 각각의 k에 대해 분류 table 작성과 분류 정확도 확인</span></span>
<span id="cb148-6"><a href="정형-데이터마이닝.html#cb148-6" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.1</span><span class="ot">&lt;-</span><span class="fu">table</span>(knn<span class="fl">.3</span>, test<span class="sc">$</span>credit.rating))</span></code></pre></div>
<pre><code>##      
## knn.3   0   1
##     0  27  51
##     1  68 154</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="정형-데이터마이닝.html#cb150-1" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.1</span>[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">+</span>t<span class="fl">.1</span>[<span class="dv">2</span>,<span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(t<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.6033333</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="정형-데이터마이닝.html#cb152-1" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.2</span><span class="ot">&lt;-</span><span class="fu">table</span>(knn<span class="fl">.7</span>, test<span class="sc">$</span>credit.rating))</span></code></pre></div>
<pre><code>##      
## knn.7   0   1
##     0  18  26
##     1  77 179</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="정형-데이터마이닝.html#cb154-1" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.2</span>[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">+</span>t<span class="fl">.2</span>[<span class="dv">2</span>,<span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(t<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## [1] 0.6566667</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="정형-데이터마이닝.html#cb156-1" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.3</span><span class="ot">&lt;-</span><span class="fu">table</span>(knn<span class="fl">.10</span>, test<span class="sc">$</span>credit.rating))</span></code></pre></div>
<pre><code>##       
## knn.10   0   1
##      0  12  17
##      1  83 188</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="정형-데이터마이닝.html#cb158-1" aria-hidden="true" tabindex="-1"></a>(t<span class="fl">.3</span>[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">+</span>t<span class="fl">.3</span>[<span class="dv">2</span>,<span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(t<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.6666667</code></pre>
<ul>
<li>분석 이전에 종속변수(credit.rating)을 제외한 데이터를 train.data와 test.data에 저장하고 class에 훈련 데이터의 종속변수를 저장한다 .그리고 k가 3, 7, 10일 때 각각 모델을 knn 함수를 사용하여 만든다.</li>
<li>분석 결과를 확인하기 위해서 각각의 k에 대해 분류 table과 정분류율을 계산하여 가장 정분류율이 높은 모델을 찾는다. 위의 결과에서 k를 10으로 했을 때 정분류율이 67%로 가장 높게 나타났다.</li>
</ul>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="정형-데이터마이닝.html#cb160-1" aria-hidden="true" tabindex="-1"></a>result<span class="ot">&lt;-</span><span class="fu">numeric</span>()</span>
<span id="cb160-2"><a href="정형-데이터마이닝.html#cb160-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">3</span><span class="sc">:</span><span class="dv">22</span></span>
<span id="cb160-3"><a href="정형-데이터마이닝.html#cb160-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> k) {</span>
<span id="cb160-4"><a href="정형-데이터마이닝.html#cb160-4" aria-hidden="true" tabindex="-1"></a>  pred<span class="ot">&lt;-</span><span class="fu">knn</span>(train.data, test.data, class, <span class="at">k=</span>i<span class="dv">-2</span>)</span>
<span id="cb160-5"><a href="정형-데이터마이닝.html#cb160-5" aria-hidden="true" tabindex="-1"></a>  t<span class="ot">&lt;-</span><span class="fu">table</span>(pred, test<span class="sc">$</span>credit.rating)</span>
<span id="cb160-6"><a href="정형-데이터마이닝.html#cb160-6" aria-hidden="true" tabindex="-1"></a>  result[i<span class="dv">-2</span>]<span class="ot">&lt;-</span>(t[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">+</span> t[<span class="dv">2</span>,<span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(t)</span>
<span id="cb160-7"><a href="정형-데이터마이닝.html#cb160-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb160-8"><a href="정형-데이터마이닝.html#cb160-8" aria-hidden="true" tabindex="-1"></a>result</span></code></pre></div>
<pre><code>##  [1] 0.5966667 0.5666667 0.6033333 0.6000000 0.6300000 0.6500000 0.6566667
##  [8] 0.6633333 0.6766667 0.6500000 0.6700000 0.6700000 0.6800000 0.6766667
## [15] 0.6733333 0.6833333 0.6900000 0.6766667 0.6900000 0.6866667</code></pre>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="정형-데이터마이닝.html#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(result, <span class="at">decreasing=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##  [1] 0.6900000 0.6900000 0.6866667 0.6833333 0.6800000 0.6766667 0.6766667
##  [8] 0.6766667 0.6733333 0.6700000 0.6700000 0.6633333 0.6566667 0.6500000
## [15] 0.6500000 0.6300000 0.6033333 0.6000000 0.5966667 0.5666667</code></pre>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="정형-데이터마이닝.html#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(result<span class="sc">==</span><span class="fu">max</span>(result))</span></code></pre></div>
<pre><code>## [1] 17 19</code></pre>
<ul>
<li>K-NN에서 최적의 K를 선정하는 것이 중요하다. 그렇기 때문에 최적의 k의 값을 선정해야 하며, 여기에서는 정분류율이 가장 높은 k가 최적의 k값이라고 선정하여 함수를 구현했다.</li>
<li>위의 결과에서 k가 17, 19일 때 분류 정확도가 가장 좋다고 나타나며, 정분류율은 69%이다.</li>
</ul>
</div>
</div>
<div id="인공신경망-모형-artificial-neural-network" class="section level3" number="4.2.7">
<h3><span class="header-section-number">4.2.7</span> 인공신경망 모형 (Artificial Neural Network)</h3>
<ul>
<li>인공신경망 모형은 동물의 뇌신경계를 모방하여 분류 또는 예측하기 위해 만들어진 모형이다. 신경망에서는 입력은 인간의 뇌의 시냅스에 해당하며 개별 신호의 강도에 따라 가중되며, 활성 함수는 인공신경망의 출력을 계산한다.</li>
<li>인공신경망은 가중치를 반복적으로 조정하여 학습하며 뉴런들은 링크로 연결되어 있고, 각 링크에는 수치적인 가중치가 있다. 인공신경망은 신경망의 가중치를 초기화하고 훈련 데이터를 통해 가중치를 갱신하여 신경망의 구조를 선택하고, 활용할 학습 알고리즘을 결정한 후 신경망을 훈련 시킨다.</li>
</ul>
<div id="특징" class="section level4" number="4.2.7.1">
<h4><span class="header-section-number">4.2.7.1</span> 특징</h4>
<div id="구조" class="section level5" number="4.2.7.1.1">
<h5><span class="header-section-number">4.2.7.1.1</span> 구조</h5>
<ul>
<li>입력 링크에서 여러 신호를 받아서 새로운 활성화 수준을 계산하고, 출력 링크로 출력 신호를 보낸다.</li>
<li>입력신호는 미가공 데이터 또는 다른 뉴런으로부터의 출력이며, 출력신호는 문제의 최종해 (Solution)이 되거나 다른 뉴런의 입력이 될 수 있다.</li>
</ul>
</div>
<div id="뉴런의-계산" class="section level5" number="4.2.7.1.2">
<h5><span class="header-section-number">4.2.7.1.2</span> 뉴런의 계산</h5>
<ul>
<li>뉴런은 전이함수, 즉 활성화 함수 (activation function)를 사용하며, 활성화 함수를 이용해 출력을 결정하며 입력신호의 가중치 합을 계산하여 임계값과 비교한다.</li>
<li>가중치 합이 임계값보다 작으면 뉴런의 출력은 -1 혹은 0, 같거나 크면 +1 혹은 x의 값을 출력한다.</li>
</ul>
</div>
<div id="뉴런의-활성화-함수" class="section level5" number="4.2.7.1.3">
<h5><span class="header-section-number">4.2.7.1.3</span> 뉴런의 활성화 함수</h5>
<ul>
<li>시그모이드 함수</li>
<li>softmax 함수</li>
<li>Relu 함수</li>
</ul>
</div>
<div id="단일-뉴런의-학습-단층-퍼셉트론" class="section level5" number="4.2.7.1.4">
<h5><span class="header-section-number">4.2.7.1.4</span> 단일 뉴런의 학습 (단층 퍼셉트론)</h5>
<ul>
<li>퍼셉트론은 선형 결합기와 하드 리미터로 구성되며, 초평면은 n차원 공간을 두 개의 영역으로 나눈다.</li>
<li>초평면을 선형 분리함수로 정의한다. <span class="math display">\[\sum_{i=1}^n x_iw_i-\theta=0\]</span></li>
</ul>
</div>
</div>
<div id="r을-이용한-인공신경망-분석" class="section level4" number="4.2.7.2">
<h4><span class="header-section-number">4.2.7.2</span> R을 이용한 인공신경망 분석</h4>
<ul>
<li>R에서 인공신경망 분석을 수행할 수 있는 패키지는 nnet와 neuralnet이 있으며 각각 nnet 함수와 neuralnet 함수를 제공한다.</li>
</ul>
<div id="nnet" class="section level5" number="4.2.7.2.1">
<h5><span class="header-section-number">4.2.7.2.1</span> nnet</h5>
<ul>
<li>nnet 패키지는 전통적인 역전파를 가지고 feed-forward 신경망을 훈련하는 알고리즘을 제공한다. 그리고 신경망의 매개변수는 엔트로피와 SSE로 최적화되며, 출력결과를 softmax 함수를 사용해 확률 형태로 변환이 가능하고 과적합을 막기 위해 가중치 감소를 제공한다.</li>
<li>nnet 함수는 size, maxit, decay 인자 외에도 가중치를 설정하는 weights, 초기 가중치 값을 설정하는 wts 등의 인자가 있다.</li>
<li>nnet 함수로 생성된 모델의 변수 중요도를 파악하기 위해서는 NeuralNetTools 패키지의 garson 함수를 사용하여 확인한다.</li>
</ul>
<p><b>함수사용법</b></p>
<pre><code>nnet(formula, data, size, maxit, decay=5e-04 ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수 ~ 독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>size</td>
<td>hidden node의 개수</td>
</tr>
<tr class="even">
<td>maxit</td>
<td>학습 반복횟수, 반복 중 가장 좋은 모델을 선정함.</td>
</tr>
<tr class="odd">
<td>decay</td>
<td>가중치 감소의 모수, 보통 5e-04 채택</td>
</tr>
</tbody>
</table>
<p><b>함수사용법</b></p>
<pre><code>garson(mod_in)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>mod_in</td>
<td>생성된 인공신경망 모델</td>
</tr>
</tbody>
</table>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 nnet 함수를 활용한 인공신경망 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="정형-데이터마이닝.html#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb168-2"><a href="정형-데이터마이닝.html#cb168-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1231</span>)</span>
<span id="cb168-3"><a href="정형-데이터마이닝.html#cb168-3" aria-hidden="true" tabindex="-1"></a>nn.model<span class="ot">&lt;-</span><span class="fu">nnet</span>(credit.rating <span class="sc">~</span> ., <span class="at">data=</span>train, <span class="at">size=</span><span class="dv">2</span>, <span class="at">maxit=</span><span class="dv">200</span>, <span class="at">decay=</span><span class="fl">5e-04</span>)</span></code></pre></div>
<pre><code>## # weights:  45
## initial  value 431.435559 
## iter  10 value 423.284097
## iter  20 value 423.069450
## iter  30 value 412.275788
## iter  40 value 379.171871
## iter  50 value 343.935787
## iter  60 value 338.439394
## iter  70 value 334.864491
## iter  80 value 331.713287
## iter  90 value 331.330445
## iter 100 value 330.202215
## iter 110 value 328.168809
## iter 120 value 320.901862
## iter 130 value 316.684662
## iter 140 value 313.512983
## iter 150 value 312.780486
## iter 160 value 312.686319
## iter 170 value 312.614992
## iter 180 value 312.507704
## iter 190 value 312.286285
## iter 200 value 312.204529
## final  value 312.204529 
## stopped after 200 iterations</code></pre>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="정형-데이터마이닝.html#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nn.model)</span></code></pre></div>
<pre><code>## a 20-2-1 network with 45 weights
## options were - entropy fitting  decay=5e-04
##   b-&gt;h1  i1-&gt;h1  i2-&gt;h1  i3-&gt;h1  i4-&gt;h1  i5-&gt;h1  i6-&gt;h1  i7-&gt;h1  i8-&gt;h1  i9-&gt;h1 
##  -11.03   35.33   -1.77   14.85   -6.62    0.00   26.54   -2.95   -1.53    4.76 
## i10-&gt;h1 i11-&gt;h1 i12-&gt;h1 i13-&gt;h1 i14-&gt;h1 i15-&gt;h1 i16-&gt;h1 i17-&gt;h1 i18-&gt;h1 i19-&gt;h1 
##   -6.35    0.83  -23.34    1.32    3.49    8.71   -3.97  -24.77   -9.60    6.63 
## i20-&gt;h1 
##   -5.47 
##   b-&gt;h2  i1-&gt;h2  i2-&gt;h2  i3-&gt;h2  i4-&gt;h2  i5-&gt;h2  i6-&gt;h2  i7-&gt;h2  i8-&gt;h2  i9-&gt;h2 
##   -3.17   10.72  -10.34    7.07    0.76   -0.02    1.81    7.05   -2.46   13.33 
## i10-&gt;h2 i11-&gt;h2 i12-&gt;h2 i13-&gt;h2 i14-&gt;h2 i15-&gt;h2 i16-&gt;h2 i17-&gt;h2 i18-&gt;h2 i19-&gt;h2 
##    1.54   -0.92   -7.43    1.62    1.62    1.12   -6.78    1.57  -11.20   11.62 
## i20-&gt;h2 
##   -1.12 
##   b-&gt;o  h1-&gt;o  h2-&gt;o 
##  -0.71   2.34   3.51</code></pre>
<ul>
<li>분석 결과를 확인하면 총 45개의 가중치가 주어졌음을 #weights: 45에서 확인할 수 있으며, iteration이 반복될수록 error이 줄어들고 있음을 확인할 수 있다. 그리고 200번째 반복 후에 학습을 멈췄으며, 최종 error값이 312.204529임을 final value를 보고 확인할 수 있다.</li>
<li>summary 함수로 분석결과를 확인하면 “a 20-2-1 network with 45 weights”는 입력노드 20개, 은닉노드 2개, 출력노드 1개를 의미하고 가중치는 총 45개임을 알 수 있다.</li>
</ul>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="정형-데이터마이닝.html#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;devtools&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb172-2"><a href="정형-데이터마이닝.html#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(devtools)</span>
<span id="cb172-3"><a href="정형-데이터마이닝.html#cb172-3" aria-hidden="true" tabindex="-1"></a><span class="fu">source_url</span>(<span class="st">&#39;https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r&#39;</span>)</span>
<span id="cb172-4"><a href="정형-데이터마이닝.html#cb172-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X11()</span></span>
<span id="cb172-5"><a href="정형-데이터마이닝.html#cb172-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.nnet</span>(nn.model)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-46-1.png" width="672" />
- summary의 결과에서 나타난 것처럼 20개의 입력노드, 2개의 은닉노드, 1개의 출력노드, 2개의 상수항을 확인할 수 있다. 그림에서 선의 굵기는 연결선의 가중치에 비례한다.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="정형-데이터마이닝.html#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;NeuralNetTools&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb173-2"><a href="정형-데이터마이닝.html#cb173-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(NeuralNetTools)</span>
<span id="cb173-3"><a href="정형-데이터마이닝.html#cb173-3" aria-hidden="true" tabindex="-1"></a><span class="co"># X11()</span></span>
<span id="cb173-4"><a href="정형-데이터마이닝.html#cb173-4" aria-hidden="true" tabindex="-1"></a><span class="fu">garson</span>(nn.model)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<ul>
<li>변수 중요도 그래프를 통해 모델의 분류에서 중요한 변수를 확인할 수 있다. 변수 중요도를 파악한 결과 account.balance, current.assets, dependents 순으로 변수 중요도가 크다는 것을 파악할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="정형-데이터마이닝.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;caret&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb174-2"><a href="정형-데이터마이닝.html#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb174-3"><a href="정형-데이터마이닝.html#cb174-3" aria-hidden="true" tabindex="-1"></a>pred.nn<span class="ot">&lt;-</span><span class="fu">predict</span>(nn.model, test[,<span class="sc">-</span><span class="dv">1</span>], <span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span>
<span id="cb174-4"><a href="정형-데이터마이닝.html#cb174-4" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span><span class="fu">as.factor</span>(pred.nn), <span class="at">reference=</span>test[,<span class="dv">1</span>], <span class="at">positive=</span><span class="st">&#39;1&#39;</span>)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  51  41
##          1  44 164
##                                         
##                Accuracy : 0.7167        
##                  95% CI : (0.662, 0.767)
##     No Information Rate : 0.6833        
##     P-Value [Acc &gt; NIR] : 0.1185        
##                                         
##                   Kappa : 0.3397        
##                                         
##  Mcnemar&#39;s Test P-Value : 0.8283        
##                                         
##             Sensitivity : 0.8000        
##             Specificity : 0.5368        
##          Pos Pred Value : 0.7885        
##          Neg Pred Value : 0.5543        
##              Prevalence : 0.6833        
##          Detection Rate : 0.5467        
##    Detection Prevalence : 0.6933        
##       Balanced Accuracy : 0.6684        
##                                         
##        &#39;Positive&#39; Class : 1             
## </code></pre>
<ul>
<li>정분류율을 0.7167이며, 민감도는 0.8000으로 높게 나타났다. 또, 특이도는 0.5368이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석 분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="정형-데이터마이닝.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;ROCR&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb176-2"><a href="정형-데이터마이닝.html#cb176-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb176-3"><a href="정형-데이터마이닝.html#cb176-3" aria-hidden="true" tabindex="-1"></a>pred.nn.roc<span class="ot">&lt;-</span><span class="fu">prediction</span>(<span class="fu">as.numeric</span>(pred.nn), <span class="fu">as.numeric</span>(test[,<span class="dv">1</span>]))</span>
<span id="cb176-4"><a href="정형-데이터마이닝.html#cb176-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">performance</span>(pred.nn.roc, <span class="st">&quot;tpr&quot;</span>, <span class="st">&quot;fpr&quot;</span>))</span>
<span id="cb176-5"><a href="정형-데이터마이닝.html#cb176-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>, <span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="정형-데이터마이닝.html#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="fu">performance</span>(pred.nn.roc, <span class="st">&quot;auc&quot;</span>)<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## [[1]]
## [1] 0.6684211</code></pre>
<ul>
<li>prediction 함수와 performance 함수로 값을 구하여 plot 함수로 ROC 커브를 그렸으며, AUC값은 <span class="citation">@y.values값으로</span> 확인한 결과 0.6684로 나타났다.</li>
</ul>
</div>
<div id="neuralnet" class="section level5" number="4.2.7.2.2">
<h5><span class="header-section-number">4.2.7.2.2</span> neuralnet</h5>
<ul>
<li>neuralnet 패키지는 회귀분석의 맥락에서 신경망을 훈련하기 위해 만들어져서 탄력적 역전파가 사용되었고 인공싱경망 중 빠른 알고리즘의 하나이다.</li>
<li>neuralnet함수는 다양한 역전파 알고리즘을 통해 모형을 적합하며, 수행결과는 plot 함수로 편리하게 시각화가 가능하다. 아래의 설명인자 이외에도 err.fct(오차 총합 지정, sse와 ce), act.fct(활서오하 함수 지정, logistic과 tanh) 등으로 추가 모형의 조정이 가능하다.</li>
</ul>
<p><b>함수사용법</b></p>
<pre><code>neuralnet(formula, data, algorithm, threshold, hidden, stepmax ...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>formula</td>
<td>수식(종속변수 ~ 독립변수)</td>
</tr>
<tr class="even">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="odd">
<td>algorithm</td>
<td>사용할 알고리즘을 지정, “backprop”(역전파), “rprop+”(Default), “rprop-” 등이 있음</td>
</tr>
<tr class="even">
<td>threshold</td>
<td>훈련중단 기준으로 default는 0.01</td>
</tr>
<tr class="odd">
<td>hidden</td>
<td>은닉 노드의 개수, c(n,m)으로 입력하면 첫번째 hidden layer에 n개의 hidden node를 가지고 두번째 hidden layer에 m개의 hidden node를 가짐</td>
</tr>
<tr class="even">
<td>stepmax</td>
<td>인공 신경망 훈련 수행 최대횟수</td>
</tr>
</tbody>
</table>
<p><strong>Q. infert 데이터는 자연유산과 인공유산 후의 불임에 대한 사례-대조 연구자료로 8개의 변수와 248개의 관측치를 가지고 있다. 반응변수 case 변수는 (1:사례, 0:대조)로 나타낸다. infert 데이터를 train, test로 분할하고 neuralnet 함수를 활용하여 인공신경망 모델을 만들어 보자.</strong></p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="정형-데이터마이닝.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;neuralnet&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb180-2"><a href="정형-데이터마이닝.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(neuralnet)</span>
<span id="cb180-3"><a href="정형-데이터마이닝.html#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(infert)</span>
<span id="cb180-4"><a href="정형-데이터마이닝.html#cb180-4" aria-hidden="true" tabindex="-1"></a>in.part<span class="ot">&lt;-</span><span class="fu">createDataPartition</span>(infert<span class="sc">$</span>case, <span class="at">times=</span><span class="dv">1</span>, <span class="at">p=</span><span class="fl">0.7</span>)</span>
<span id="cb180-5"><a href="정형-데이터마이닝.html#cb180-5" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(infert[in.part<span class="sc">$</span>Resample1, <span class="st">&quot;case&quot;</span>])</span></code></pre></div>
<pre><code>## 
##   0   1 
## 118  56</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="정형-데이터마이닝.html#cb182-1" aria-hidden="true" tabindex="-1"></a>parts<span class="ot">&lt;-</span><span class="fu">as.vector</span>(in.part<span class="sc">$</span>Resample1)</span>
<span id="cb182-2"><a href="정형-데이터마이닝.html#cb182-2" aria-hidden="true" tabindex="-1"></a>train.infert<span class="ot">&lt;-</span>infert[parts,]</span>
<span id="cb182-3"><a href="정형-데이터마이닝.html#cb182-3" aria-hidden="true" tabindex="-1"></a>test.infert<span class="ot">&lt;-</span>infert[<span class="sc">-</span>parts,]</span>
<span id="cb182-4"><a href="정형-데이터마이닝.html#cb182-4" aria-hidden="true" tabindex="-1"></a>nn.model2<span class="ot">&lt;-</span><span class="fu">neuralnet</span>(case<span class="sc">~</span>age<span class="sc">+</span>parity<span class="sc">+</span>induced<span class="sc">+</span>spontaneous, <span class="at">data=</span>train.infert,</span>
<span id="cb182-5"><a href="정형-데이터마이닝.html#cb182-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">hidden=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">algorithm=</span><span class="st">&quot;rprop+&quot;</span>, <span class="at">threshold=</span><span class="fl">0.01</span>, <span class="at">stepmax=</span><span class="fl">1e+5</span>)</span>
<span id="cb182-6"><a href="정형-데이터마이닝.html#cb182-6" aria-hidden="true" tabindex="-1"></a><span class="co"># X11()</span></span>
<span id="cb182-7"><a href="정형-데이터마이닝.html#cb182-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nn.model2)</span></code></pre></div>
<ul>
<li>plot으로 나타냈을 때, hidden layer 2개에 hidden node도 2개가 나타남을 확인할 수 있으며, nnet의 그래프와 다르게 가중치가 선의 굵기로 나타나지 않고 수치로 나타남을 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="정형-데이터마이닝.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(nn.model2)</span></code></pre></div>
<pre><code>##  [1] &quot;call&quot;                &quot;response&quot;            &quot;covariate&quot;          
##  [4] &quot;model.list&quot;          &quot;err.fct&quot;             &quot;act.fct&quot;            
##  [7] &quot;linear.output&quot;       &quot;data&quot;                &quot;exclude&quot;            
## [10] &quot;net.result&quot;          &quot;weights&quot;             &quot;generalized.weights&quot;
## [13] &quot;startweights&quot;        &quot;result.matrix&quot;</code></pre>
<ul>
<li>neuralnet() 함수의 수행 결과의 추가적인 정보는 names 함수를 통해 확인할 수 있다. 분석에 사용한 전체 자료는 $data에 저장되어 있으며, 모형 적합에 사용된 자료는 $covariate와 $response를 통해 확인이 가능하다. 그리고 적합값은 $net.result에 제공되고 가중치의 초기값과 적합값은 $startweights와 $weights에서 제공한다.</li>
</ul>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="정형-데이터마이닝.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(neuralnet)</span>
<span id="cb185-2"><a href="정형-데이터마이닝.html#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1231</span>)</span>
<span id="cb185-3"><a href="정형-데이터마이닝.html#cb185-3" aria-hidden="true" tabindex="-1"></a>test.infert<span class="sc">$</span>nn.model2_pred.prob <span class="ot">&lt;-</span> <span class="fu">compute</span>(nn.model2, <span class="at">covariate=</span>test.infert[,<span class="fu">c</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>,<span class="dv">6</span>)])<span class="sc">$</span>net.result</span></code></pre></div>
<ul>
<li>compute 함수는 각 뉴런의 출력값을 계산해주며, 기존의 분류모형에서 사용된 predict 함수의 역할을 하여 예측값을 구해준다. 분석에 사용한 예측변수를 covariate 인자에 추가하여 예측값을 $net.result를 통해 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="정형-데이터마이닝.html#cb186-1" aria-hidden="true" tabindex="-1"></a>test.infert<span class="sc">$</span>nn.model2_pred <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(test.infert<span class="sc">$</span>nn.model2_pred.prob <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<ul>
<li>로지스틱 회귀분석과 동일하게 neuralnet의 예측값은 범주로 나타나는 것이 아닌 확률값으로 나타나기 때문에 기준이 되는 확률보다 크면 1, 작으면 0으로 범주를 추가한다.</li>
</ul>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="정형-데이터마이닝.html#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="fu">as.factor</span>(test.infert<span class="sc">$</span>nn.model2_pred), <span class="fu">as.factor</span>(test.infert[,<span class="dv">5</span>]))</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  0  1
##          0 41 16
##          1  6 11
##                                           
##                Accuracy : 0.7027          
##                  95% CI : (0.5852, 0.8034)
##     No Information Rate : 0.6351          
##     P-Value [Acc &gt; NIR] : 0.13806         
##                                           
##                   Kappa : 0.3037          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.05501         
##                                           
##             Sensitivity : 0.8723          
##             Specificity : 0.4074          
##          Pos Pred Value : 0.7193          
##          Neg Pred Value : 0.6471          
##              Prevalence : 0.6351          
##          Detection Rate : 0.5541          
##    Detection Prevalence : 0.7703          
##       Balanced Accuracy : 0.6399          
##                                           
##        &#39;Positive&#39; Class : 0               
## </code></pre>
<ul>
<li>정분류율은 0.7이며, 민감도는 0.8163으로 높게 나타났다. 또 특이도는 0.4800이다. 정확도가 높다고 해서 무조건 좋은 모형은 아니며, 분석분야에 따라 다양한 지표들을 활용하여 분석 모형을 선택할 수 있다.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="군집분석" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> 군집분석</h2>
<p>군집분석은 각 개체의 유사성을 측정하여 유사성이 높은 대상 집단을 분류하고, 군집에 속한 객체들의 유사성과 서로 다른 군집에 속한 개체간의 상이성을 규명하는 다변량 분석기법이다. 군집 분석에서 이용되는 다변량 자료는 별도의 반응변수가 요구되지 않으며, 오로지 개체들간의 유사성에만 기초하여 군집을 형성한다. 군집 분석은 이상값 탐지에도 사용되며, 심리학, 사회학, 경영학, 생물학 등 다양한 분야에 이용되고 있다.</p>
<div id="군집분석-1" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> 군집분석</h3>
<div id="개요" class="section level4" number="4.3.1.1">
<h4><span class="header-section-number">4.3.1.1</span> 개요</h4>
<ul>
<li>각 객체의 유사성을 측정하여 유사성이 높은 대상 집단을 분류하고, 군집에 속한 객체들의 유사성과 서로 다른 군집에 속한 객체 간의 상이성을 규명하는 분석 방법이다.</li>
<li>군집 분석은 특성에 따라 고객을 여러개의 배타적인 집단으로 나누는 것이며, 결과는 구체적인 군집 분석 방법에 따라 차이가 나타날 수 있다.</li>
<li>군집의 개수나 구조에 대한 가정 없이 데이터들 사이의 거리를 기준으로 군집화를 유도하며, 마케팅 조사에서 소비자들의 상품구매행동이나 life style에 따른 소비자 군을 분류하여 시장 전략 수립 등에 활용한다.</li>
</ul>
</div>
<div id="특징-1" class="section level4" number="4.3.1.2">
<h4><span class="header-section-number">4.3.1.2</span> 특징</h4>
<div id="요인분석과의-차이점" class="section level5" number="4.3.1.2.1">
<h5><span class="header-section-number">4.3.1.2.1</span> 요인분석과의 차이점</h5>
<ul>
<li>요인분석은 유사한 변수를 함께 묶어주는 것이 목적이다.</li>
</ul>
</div>
<div id="판별분석과의-차이점" class="section level5" number="4.3.1.2.2">
<h5><span class="header-section-number">4.3.1.2.2</span> 판별분석과의 차이점</h5>
<ul>
<li>판별분석은 사저넹 집단이 나누어져 있는 자료를 통해 새로운 데이터를 기존의 집단에 할당하는 것이 목적이다.</li>
</ul>
</div>
</div>
<div id="거리" class="section level4" number="4.3.1.3">
<h4><span class="header-section-number">4.3.1.3</span> 거리</h4>
<div id="연속형-변수의-경우" class="section level5" number="4.3.1.3.1">
<h5><span class="header-section-number">4.3.1.3.1</span> 연속형 변수의 경우</h5>
<ul>
<li>유클리디안 거리</li>
<li>표준화 거리</li>
<li>마할라노비스 거리</li>
<li>체비셰프 거리</li>
<li>맨하탄 거리</li>
<li>캔버라 거리</li>
<li>민코우스키 거리</li>
</ul>
</div>
<div id="범주형-변수의-경우" class="section level5" number="4.3.1.3.2">
<h5><span class="header-section-number">4.3.1.3.2</span> 범주형 변수의 경우</h5>
<ul>
<li>자카드 거리</li>
<li>자카드 계수</li>
<li>코사인 유사도</li>
</ul>
</div>
</div>
</div>
<div id="계층적-군집분석" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> 계층적 군집분석</h3>
<ul>
<li>계층적 군집분석은 n개의 군집으로 시작해 점차 군집의 개수를 줄여 나가는 방법이다.</li>
<li>계층적 군집을 형성하는 방법에는 합병형 방법과 분리형 방법이 있다.</li>
</ul>
<div id="계층적-군집분석-종류" class="section level4" number="4.3.2.1">
<h4><span class="header-section-number">4.3.2.1</span> 계층적 군집분석 종류</h4>
<div id="최단연결법" class="section level5" number="4.3.2.1.1">
<h5><span class="header-section-number">4.3.2.1.1</span> 최단연결법</h5>
</div>
<div id="최장연결법" class="section level5" number="4.3.2.1.2">
<h5><span class="header-section-number">4.3.2.1.2</span> 최장연결법</h5>
</div>
<div id="평균연결법" class="section level5" number="4.3.2.1.3">
<h5><span class="header-section-number">4.3.2.1.3</span> 평균연결법</h5>
</div>
<div id="와드연결법" class="section level5" number="4.3.2.1.4">
<h5><span class="header-section-number">4.3.2.1.4</span> 와드연결법</h5>
</div>
<div id="군집화" class="section level5" number="4.3.2.1.5">
<h5><span class="header-section-number">4.3.2.1.5</span> 군집화</h5>
</div>
<div id="r을-활용한-계층적-군집분석" class="section level5" number="4.3.2.1.6">
<h5><span class="header-section-number">4.3.2.1.6</span> R을 활용한 계층적 군집분석</h5>
<p><b>함수사용법</b></p>
<pre><code>dist(data, method)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="even">
<td>method</td>
<td>거리측정 방법, “euclidean”,“maximum”,“manhattan”,“canberra”,“binary”,“minkowski”가 있음</td>
</tr>
</tbody>
</table>
<p><b>함수사용법</b></p>
<pre><code>hclust(data, method)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>dist 함수로 거리가 측정된 데이터</td>
</tr>
<tr class="even">
<td>method</td>
<td>거리측정 방법, “single”, “complete”, “average”, “median”, “ward.D”가 있음</td>
</tr>
</tbody>
</table>
<p><strong>Q. USArrests 데이터는 미국 주(State)별 강력 범죄율 정보를 담고 있다. USArrests 데이터의 정보로 거리를 구하고 최단, 최장, 평균연결법을 실시해보자. </strong></p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="정형-데이터마이닝.html#cb191-1" aria-hidden="true" tabindex="-1"></a>US<span class="ot">&lt;-</span>USArrests</span>
<span id="cb191-2"><a href="정형-데이터마이닝.html#cb191-2" aria-hidden="true" tabindex="-1"></a>US.dist<span class="ot">&lt;-</span><span class="fu">dist</span>(US, <span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<ul>
<li>USArrests 데이터를 US라는 변수에 저장하고, dist 함수로 유클리디안 거리를 구한 뒤 US.dist 변수에 저장하여 데이터를 확인하면 위와 같다.</li>
</ul>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="정형-데이터마이닝.html#cb192-1" aria-hidden="true" tabindex="-1"></a>US.single<span class="ot">&lt;-</span><span class="fu">hclust</span>(US.dist<span class="sc">^</span><span class="dv">2</span>, <span class="at">method=</span><span class="st">&quot;single&quot;</span>)</span>
<span id="cb192-2"><a href="정형-데이터마이닝.html#cb192-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(US.single)</span>
<span id="cb192-3"><a href="정형-데이터마이닝.html#cb192-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb192-4"><a href="정형-데이터마이닝.html#cb192-4" aria-hidden="true" tabindex="-1"></a>US.complete<span class="ot">&lt;-</span><span class="fu">hclust</span>(US.dist<span class="sc">^</span><span class="dv">2</span>, <span class="at">method=</span><span class="st">&quot;complete&quot;</span>)</span>
<span id="cb192-5"><a href="정형-데이터마이닝.html#cb192-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(US.single)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="정형-데이터마이닝.html#cb193-1" aria-hidden="true" tabindex="-1"></a>US.average<span class="ot">&lt;-</span><span class="fu">hclust</span>(US.dist<span class="sc">^</span><span class="dv">2</span>, <span class="at">method=</span><span class="st">&quot;average&quot;</span>)</span>
<span id="cb193-2"><a href="정형-데이터마이닝.html#cb193-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(US.single)</span></code></pre></div>
<ul>
<li>US.dist 데이터를 hclust 함수를 활용하여 최단, 최장, 평균 거리법으로 군집화하고 덴드로그램을 그려보자. hclust 함수 안의 US.dist 데이터를 제곱한 이유는 거리의 차이를 많이 두어 군집이 나니ㅜ는 것을 쉽게 확인하기 위해서이다. method를 “single”, “complete”, “average”로 지정하여 최단, 최장, 평균 거리법을 실행할 수 있다. 그리고 해당 결과를 plot 함수로 덴드로그램을 그릴 수 있다.</li>
<li>덴드로그램에서 Height 값에 따라 선을 그어 적절한 군집수를 선정할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="정형-데이터마이닝.html#cb194-1" aria-hidden="true" tabindex="-1"></a>group<span class="ot">&lt;-</span><span class="fu">cutree</span>(US.average, <span class="at">k=</span><span class="dv">6</span>)</span>
<span id="cb194-2"><a href="정형-데이터마이닝.html#cb194-2" aria-hidden="true" tabindex="-1"></a>group</span></code></pre></div>
<pre><code>##        Alabama         Alaska        Arizona       Arkansas     California 
##              1              1              1              2              1 
##       Colorado    Connecticut       Delaware        Florida        Georgia 
##              2              3              1              4              2 
##         Hawaii          Idaho       Illinois        Indiana           Iowa 
##              5              3              1              3              5 
##         Kansas       Kentucky      Louisiana          Maine       Maryland 
##              3              3              1              5              1 
##  Massachusetts       Michigan      Minnesota    Mississippi       Missouri 
##              6              1              5              1              2 
##        Montana       Nebraska         Nevada  New Hampshire     New Jersey 
##              3              3              1              5              6 
##     New Mexico       New York North Carolina   North Dakota           Ohio 
##              1              1              4              5              3 
##       Oklahoma         Oregon   Pennsylvania   Rhode Island South Carolina 
##              6              6              3              6              1 
##   South Dakota      Tennessee          Texas           Utah        Vermont 
##              5              2              2              3              5 
##       Virginia     Washington  West Virginia      Wisconsin        Wyoming 
##              6              6              5              5              6</code></pre>
<ul>
<li>cutree함수로 계층적 군집의 결과를 이용하여 tree의 높이나 그룹의 수를 옵션으로 지정하여 원하는 수의 그룹으로 나눌 수 있다.</li>
</ul>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="정형-데이터마이닝.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(US.average)</span>
<span id="cb196-2"><a href="정형-데이터마이닝.html#cb196-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rect.hclust</span>(US.average, <span class="at">k=</span><span class="dv">6</span>, <span class="at">border=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<ul>
<li>덴드로그램은 plot함수와 rect.hclust 함수를 이용하여 각각의 그룹을 사각형으로 구분지어 나타낼 수 있다.</li>
</ul>
</div>
</div>
</div>
<div id="비계층적-군집분석" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> 비계층적 군집분석</h3>
<div id="개요-1" class="section level4" number="4.3.3.1">
<h4><span class="header-section-number">4.3.3.1</span> 개요</h4>
<ul>
<li>n개의 개체를 k개의 군집으로 나눌 수 있는 모든 가능한 방법을 점검해 최적화한 군집을 형성하는 것이다.</li>
</ul>
</div>
<div id="k-평균-군집분석" class="section level4" number="4.3.3.2">
<h4><span class="header-section-number">4.3.3.2</span> K-평균 군집분석</h4>
<ul>
<li>주어진 데이터를 k개의 클러스터로 묶는 알고리즘으로, 각 클러스터와 거리 차이의 분산을 최소화하는 방식으로 동작한다.</li>
</ul>
<div id="k-평균-군집분석-과정" class="section level5" number="4.3.3.2.1">
<h5><span class="header-section-number">4.3.3.2.1</span> K-평균 군집분석 과정</h5>
<ul>
<li>원하는 군집의 개수와 초기값들을 정해 seed 중심으로 군집을 형성한다.</li>
<li>각 데이터를 거리가 가장 가까운 seed가 있는 군집으로 분류한다.</li>
<li>각 군집의 seed값을 다시 계산한다.</li>
</ul>
</div>
<div id="k-평균-군집분석의-특징" class="section level5" number="4.3.3.2.2">
<h5><span class="header-section-number">4.3.3.2.2</span> K-평균 군집분석의 특징</h5>
<ul>
<li><p>거리 계산을 통해 군집화가 이루어지므로 연속형 변수에 활용이 가능하다.</p></li>
<li><p>K개의 초기 중심값은 임의로 선택이 가능하며 가급적이면 멀리 떨어지는 것이 바람직하다.</p></li>
<li><p>초기 중심값을 임의로 선택할 때 일렬(위아래, 좌우)로 선택하면 군집이 혼합되지 ㅇ낳고 층으로 나누어질 수 있어 주의하여야 한다. 초기 중심값의 선정에 따라 결과가 달라질 수 있다.</p></li>
<li><p>초기 중심으로부터의 오차 제곱합을 최소화하는 방향으로 군집이 형성되는 탐욕적(greedy) 알고리즘이므로 안정된 군집은 보장하나 최적이라는 보장은 없다.</p></li>
<li><p>장점</p>
<ul>
<li>알고리즘이 단순하며, 빠르게 수행되어 분석방법 적용이 용이하다.</li>
<li>계층적 군집분석에 비해 많은 양의 데이터를 다룰 수 있다.</li>
<li>내부 구조에 대한 사전정보가 없어도 의미있는 자료구조를 찾을 수 있다.</li>
<li>다양한 형태의 데이터에 적용이 가능하다.</li>
</ul></li>
<li><p>단점</p>
<ul>
<li>군집의 수, 가중치와 거리 정의가 어렵다.</li>
<li>사전에 주어진 목적이 없으므로 결과해석이 어렵다.</li>
<li>잡음이나 이상값의 영향을 많이 받는다.</li>
<li>블록한 형태가 아닌 군집이 존재할 경우에는 성능이 떨어진다.</li>
<li>초기 군집 수 결정에 어려움이 있다.</li>
</ul></li>
</ul>
</div>
<div id="r을-활용한-k-means-군집분석" class="section level5" number="4.3.3.2.3">
<h5><span class="header-section-number">4.3.3.2.3</span> R을 활용한 K-means 군집분석</h5>
<p><b>함수사용법</b></p>
<pre><code>kmeans(data, centers, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="even">
<td>centers</td>
<td>군집의 개수를 설정</td>
</tr>
</tbody>
</table>
<pre><code>Nbclust(data, min.nc, max.nc, method, ...)</code></pre>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>분석하고자 하는 데이터</td>
</tr>
<tr class="even">
<td>min.nc</td>
<td>최소군집의 수</td>
</tr>
<tr class="odd">
<td>max.nc</td>
<td>최대군집의 수</td>
</tr>
<tr class="even">
<td>method</td>
<td>군집분석 방법을 정함. “kmeans”, “median”, “single”, “complete”, “average” 등이 있음</td>
</tr>
</tbody>
</table>
<p><strong>Q. 앞서 분할한 credit 데이터의 train 데이터로 kmenas 군집분석을 해보자.</strong></p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="정형-데이터마이닝.html#cb199-1" aria-hidden="true" tabindex="-1"></a>train.data<span class="ot">&lt;-</span>train[,<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb199-2"><a href="정형-데이터마이닝.html#cb199-2" aria-hidden="true" tabindex="-1"></a>credit.kmeans<span class="ot">&lt;-</span><span class="fu">kmeans</span>(train.data, <span class="at">centers=</span><span class="dv">2</span>)</span></code></pre></div>
<ul>
<li>kmeans 군집 분석을 실시하기 전에 종속변수를 제외한 데이터로 군집분석을 실시해 원래 종속 변수와 군집분석 결과의 정분류율을 확인해 본다.</li>
</ul>
<details>
<summary>
Click for Result
</summary>
<pre><code>## K-means clustering with 2 clusters of sizes 117, 583
## 
## Cluster means:
##   account.balance credit.duration.months previous.credit.payment.status
## 1        2.111111               35.73504                       2.384615
## 2        2.212693               17.52316                       2.286449
##   credit.purpose credit.amount  savings employment.duration installment.rate
## 1       2.752137      8369.906 2.000000            2.512821         2.495726
## 2       2.974271      2169.919 1.830189            2.439108         3.087479
##   marital.status guarantor residence.duration current.assets      age
## 1       2.470085  1.102564           2.752137       2.974359 35.71795
## 2       2.312178  1.099485           2.859348       2.228130 35.27101
##   other.credits apartment.type bank.credits occupation dependents telephone
## 1      1.811966       2.059829     1.401709   3.145299   1.153846  1.606838
## 2      1.825043       1.879931     1.341338   2.838765   1.150943  1.351630
##   foreign.worker
## 1       1.017094
## 2       1.039451
## 
## Clustering vector:
##  415  463  179  526  195  938  818  118  299  229  244   14  374  665  602  603 
##    2    2    2    1    2    2    2    2    2    2    2    1    2    2    2    2 
##  768  709   91  953  348  649  355  840   26  519  426  979  766  211  932  590 
##    2    1    2    2    2    2    2    2    2    1    2    2    2    2    2    2 
##  593  555  871  373  844  143  544  490  621  775  905  937  842   23  923  309 
##    1    2    2    1    1    2    2    2    1    2    2    2    2    2    2    2 
##  135  821  954  224  166  217  290  581   72  588  575  141  722  865  859  153 
##    2    1    1    1    2    2    2    2    2    2    1    2    2    1    2    1 
##  294  277  999   41  431   90  316  223  528  116  606  774  747  456  598  854 
##    2    2    1    2    2    2    2    2    2    1    2    1    2    1    2    2 
##   39  159  752  209  988  994   34  516   13   69  895  755  409  308  278   89 
##    2    1    2    1    2    2    2    2    2    2    2    1    2    2    2    2 
##  537  291  424  880  286  671  121  110  158   64  483  477  480  711   67  663 
##    2    2    2    2    2    2    2    2    1    1    2    2    2    2    2    2 
##  847   85  165  648   51   74  178  362  236  610  330  726  127  212  686  785 
##    2    2    2    1    2    2    2    2    2    2    1    2    2    2    2    2 
##  814  310  744  243  862  888  792  113  619  893  151  666  614  767  160  391 
##    2    1    1    2    2    1    2    2    2    2    2    2    2    2    2    2 
##  155  974    5  326  784  280  800  789  567  843  238  764  339  920  822  137 
##    2    1    2    2    2    2    2    2    1    2    2    1    2    1    1    2 
##  455  738  560  589   83  696  867  196  769  680  900  926  500  852  344  966 
##    2    2    2    2    1    1    2    1    2    2    2    2    2    2    2    1 
##  459   20  996  164   52  534  177  554   84  523  633  392  302  597  706  864 
##    2    1    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
##  837  430  710  761  712  428  672  250  429  398  928  381  545   40  522  473 
##    2    2    1    2    2    2    2    2    2    2    2    2    2    2    1    1 
##  200  125  265  959  186  573  252  458  152   54  538  235  289  185  765  413 
##    2    2    2    2    1    1    1    2    2    2    2    2    2    2    2    2 
##  627  794  981  783  205  904  564  857  908  727  346  858  468  509   57  457 
##    2    2    2    1    2    2    2    2    2    2    2    2    1    2    2    2 
##  617  357  279  270  646  347  129  218  618  698  337  976  539  975  861  553 
##    1    2    2    2    1    2    2    2    2    2    2    1    2    2    2    2 
##  724  390  498  222  899  657  421  762  660  163  846  673  578  913  878  225 
##    1    2    2    2    2    2    2    2    2    2    2    2    2    2    1    2 
##  389  117  771  885   55  947  811  557  658  682 1000  134  891  688  447  104 
##    2    2    2    2    1    2    1    1    2    2    1    2    1    2    2    1 
##  716  845  210  349  401  258  915  386  941   24  466  130  886  943  377  170 
##    2    1    2    2    2    2    2    2    1    2    2    2    1    2    2    2 
##  445  234  422  508  910   80  894  548  475  903  343  323  479  838  450  111 
##    2    2    2    1    1    2    2    2    2    2    2    2    2    2    2    2 
##  317  741  287  585  292  226  297  605  637  834  237  700  809   33  836  396 
##    2    2    2    1    2    2    2    2    2    2    2    2    2    1    1    2 
##  935  917   76   94   30  723  175  916  685  115  751  608  465  358  902   96 
##    2    2    2    2    2    2    2    2    2    2    2    2    1    2    2    2 
##  782  397  404  148  813  968  714  338  869  106   11  625  364  705  403  461 
##    2    1    2    2    2    2    2    2    2    2    2    1    2    2    2    1 
##  704   31  655  661   16  420  882  417  464  412  810  524  437  732  562  204 
##    2    2    1    2    2    2    2    2    2    2    2    2    2    1    2    1 
##  720  965  624  384  122  399  634  315  259  494  780   48  331  100  108  301 
##    1    2    2    2    1    2    2    2    2    2    2    2    2    1    2    2 
##   10  697  851  980  402  889  804  925  395  986    8  261  541  306  853  883 
##    2    2    2    2    2    2    2    2    1    2    2    2    2    2    2    1 
##  282  267  262  760  219  352  119  452   36  870  961  240  304  600  694  105 
##    2    2    2    2    1    2    2    2    2    2    1    2    2    2    2    2 
##  388  934  180  906  615  241  703  559   37  303   19  378  549  990  733  188 
##    1    2    1    2    1    2    1    1    2    2    2    1    2    2    2    2 
##  860  393  139  992  371  189  311  547  418  382   38  816  319  596  120  604 
##    2    2    2    1    1    2    2    2    1    2    2    2    2    1    2    2 
##  533  441  199  499  944  609   81  942  717  650    6  128   49  476  239  340 
##    2    2    2    2    1    2    2    2    1    2    2    2    2    2    2    2 
##  193  824  561  645  190  191  446  668  630  571  512   59  305  832   61  570 
##    1    2    2    2    2    2    2    2    2    2    2    2    2    2    2    1 
##  591  676  770  955  510  962   88  132  438  777  788  471  251  203  246  481 
##    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
##  574  440  435  626  492  817  131  667  478  162  322  692  168  442  276   78 
##    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
##  957  819  527  835   95  406  552  379  342  221  184  161  504  448  242  181 
##    2    2    2    2    1    1    2    2    2    2    2    2    2    2    1    2 
##  718  812  918  930  414  407  991  949  273  187  535  171  501  753  601  136 
##    2    1    2    1    2    2    2    2    2    2    2    1    2    2    1    2 
##   79  951  670  890  295  802  505  443  284  595   87  805  651  138  365  803 
##    2    2    2    1    2    2    1    1    2    2    2    2    2    2    2    2 
##  933  644  754  336  739  232  334  987  433  328  876  470  264  779  201  820 
##    2    1    2    2    2    2    2    1    2    2    2    2    2    2    2    2 
##  729  620  815  707   65  507   29  823  206  124  691  263  228   45  332  281 
##    1    2    2    2    2    2    2    2    2    2    1    2    2    2    2    2 
##  982  632  427  629  577  268  969  327  271  746  781  167  255  807  612   71 
##    2    1    1    2    2    2    2    2    2    2    1    1    1    2    2    2 
##  260  530  623  451  636  734  757  798  841  872  927   46  863  558  719   98 
##    2    2    2    2    2    2    2    2    2    1    2    2    2    2    2    2 
##  434  220  566  679  324  931  721  877  275  687  231  197  831  169  659  960 
##    2    2    2    2    2    2    1    2    2    2    2    1    2    2    2    2 
##  341  911  320  662    2  274  376  639  681  532  881  638  207   56  750  613 
##    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
##  394  958  503  647   68  725  419   53  922  230  333  677  256  742  318  940 
##    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    1 
##  640  745  678  173  702  351  873  266  372  172  298  778 
##    2    2    2    2    1    2    2    2    2    2    2    2 
## 
## Within cluster sum of squares by cluster:
## [1] 801760259 789310923
##  (between_SS / total_SS =  70.2 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;     &quot;tot.withinss&quot;
## [6] &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;         &quot;ifault&quot;</code></pre>
</details>
<ul>
<li>군집의 수를 2개로 분할하여 kmeans 군집분석을 실시한 결과, 117,583의 개체가 모인 군집으로 나누어졌다. 그리고 전체 변동에서 군집간 변동이 차지하는 비율인 (between_SS/total_SS)이 1에 가까울수록 군집이 잘 분류되었다고 판단할 수 있지만, 70.2%이므로 좋은 모델이라고 할 수는 없다.</li>
</ul>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="정형-데이터마이닝.html#cb201-1" aria-hidden="true" tabindex="-1"></a>(kmeans.table<span class="ot">&lt;-</span><span class="fu">table</span>(train<span class="sc">$</span>credit.rating, credit.kmeans<span class="sc">$</span>cluster))</span></code></pre></div>
<pre><code>##    
##       1   2
##   0  45 160
##   1  72 423</code></pre>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="정형-데이터마이닝.html#cb203-1" aria-hidden="true" tabindex="-1"></a>(kmeans.table[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">+</span>kmeans.table[<span class="dv">2</span>,<span class="dv">2</span>]) <span class="sc">/</span> <span class="fu">sum</span>(kmeans.table)</span></code></pre></div>
<pre><code>## [1] 0.6685714</code></pre>
<ul>
<li>정분류율은 0.67로 나타나 좋은 성능을 가지지 않았다고 판단할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="정형-데이터마이닝.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;NbClust&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb205-2"><a href="정형-데이터마이닝.html#cb205-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(NbClust)</span>
<span id="cb205-3"><a href="정형-데이터마이닝.html#cb205-3" aria-hidden="true" tabindex="-1"></a>nc<span class="ot">&lt;-</span><span class="fu">NbClust</span>(train.data, <span class="at">min.nc=</span><span class="dv">2</span>, <span class="at">max.nc=</span><span class="dv">15</span>, <span class="at">method=</span><span class="st">&quot;kmeans&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<pre><code>## *** : The Hubert index is a graphical method of determining the number of clusters.
##                 In the plot of Hubert index, we seek a significant knee that corresponds to a 
##                 significant increase of the value of the measure i.e the significant peak in Hubert
##                 index second differences plot. 
## </code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-63-2.png" width="672" /></p>
<pre><code>## *** : The D index is a graphical method of determining the number of clusters. 
##                 In the plot of D index, we seek a significant knee (the significant peak in Dindex
##                 second differences plot) that corresponds to a significant increase of the value of
##                 the measure. 
##  
## ******************************************************************* 
## * Among all indices:                                                
## * 6 proposed 2 as the best number of clusters 
## * 3 proposed 3 as the best number of clusters 
## * 2 proposed 4 as the best number of clusters 
## * 4 proposed 5 as the best number of clusters 
## * 2 proposed 8 as the best number of clusters 
## * 1 proposed 9 as the best number of clusters 
## * 1 proposed 10 as the best number of clusters 
## * 1 proposed 11 as the best number of clusters 
## * 4 proposed 15 as the best number of clusters 
## 
##                    ***** Conclusion *****                            
##  
## * According to the majority rule, the best number of clusters is  2 
##  
##  
## *******************************************************************</code></pre>
<ul>
<li>“According to the majority rule, the best number of clusters is 2”를 통해 최적의 k는 2로 나타났음을 확인할 수 있다. 분석 전에 최적의 k를 찾고 kmeans 분석을 실시하는 것이 필요하다.</li>
</ul>
</div>
</div>
</div>
<div id="혼합-분포-군집" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> 혼합 분포 군집</h3>
<div id="개요-2" class="section level4" number="4.3.4.1">
<h4><span class="header-section-number">4.3.4.1</span> 개요</h4>
<ul>
<li>모형 기반의 군집 방법이며, 데이터가 k개의 모수적 모형의 가중합으로 표현되는 모집단 모형으로부터 나왔다는 가정하에서 모수와 함께 가중치를 자료로부터 추정하는 방법을 사용한다.</li>
<li>K개의 각 모형은 군집을 의미하며, 각 데이터는 추정된 k개의 모형중 어느 모형으로부터 나왔을 확률이 높은지에 따라 군집의 분류가 이루어진다.</li>
<li>흔히 혼합모형에서의 모수와 가중치의 추정(최대가능도추정)에는 EM 알고리즘이 사용된다.</li>
</ul>
</div>
<div id="특징-2" class="section level4" number="4.3.4.2">
<h4><span class="header-section-number">4.3.4.2</span> 특징</h4>
<ul>
<li>K-평균군집의 절차와 유사하지만 확률분포를 도입하여 군집을 수행한다.</li>
<li>군집을 몇개의 모수로 표현할 수 있으며, 서로 다른 크기나 모양의 군집을 찾을 수 있다.</li>
<li>EM 알고리즘을 이용한 모수 추정에서 데이터가 커지면 수렵에 시간이 걸릴 수 있다.</li>
<li>군집의 크기가 너무 작으면 추정의 정도가 떨어지거나 어려울 수 있다.</li>
<li>K-평균군집과 같이 이상치 자료에 민감하므로 사전에 조치가 필요하다.</li>
</ul>
</div>
<div id="혼합-분포모형으로-설명할-수-있는-데이터의-형태" class="section level4" number="4.3.4.3">
<h4><span class="header-section-number">4.3.4.3</span> 혼합 분포모형으로 설명할 수 있는 데이터의 형태</h4>
</div>
<div id="emexpectation-maximization-알고리즘의-진행-과정" class="section level4" number="4.3.4.4">
<h4><span class="header-section-number">4.3.4.4</span> EM(Expectation-Maximization) 알고리즘의 진행 과정</h4>
<ul>
<li>E단계: 잠재변수 Z의 기대치 계산</li>
<li>M단계: 잠재변수 Z의 기대치를 이용하여 파라미터를 추정</li>
</ul>
</div>
<div id="r을-이용한-혼합-분포-군집분석" class="section level4" number="4.3.4.5">
<h4><span class="header-section-number">4.3.4.5</span> R을 이용한 혼합 분포 군집분석</h4>
<p><b>함수사용법</b></p>
<pre><code>Mclust(data, G, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>분석하고자 하는 데이터(벡터, 매트릭스, 데이터프레임의 관측치). 단, 수치형 변수만 가능함</td>
</tr>
<tr class="even">
<td>G</td>
<td>BIC를 계산할 혼합분포 클러스터의 수를 지정, Default는 1:9</td>
</tr>
</tbody>
</table>
<p><strong>Q. iris 데이터의 Species를 제외하고 혼합 분포 군집분석을 실시해 보자.</strong></p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="정형-데이터마이닝.html#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;mclust&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb209-2"><a href="정형-데이터마이닝.html#cb209-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span></code></pre></div>
<pre><code>## Package &#39;mclust&#39; version 5.4.7
## Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="정형-데이터마이닝.html#cb211-1" aria-hidden="true" tabindex="-1"></a>mc<span class="ot">&lt;-</span><span class="fu">Mclust</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], <span class="at">G=</span><span class="dv">3</span>)</span>
<span id="cb211-2"><a href="정형-데이터마이닝.html#cb211-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mc, <span class="at">parameters=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 3 components: 
## 
##  log-likelihood   n df       BIC       ICL
##        -186.074 150 38 -562.5522 -566.4673
## 
## Clustering table:
##  1  2  3 
## 50 45 55 
## 
## Mixing probabilities:
##         1         2         3 
## 0.3333333 0.3005423 0.3661243 
## 
## Means:
##               [,1]     [,2]     [,3]
## Sepal.Length 5.006 5.915044 6.546807
## Sepal.Width  3.428 2.777451 2.949613
## Petal.Length 1.462 4.204002 5.482252
## Petal.Width  0.246 1.298935 1.985523
## 
## Variances:
## [,,1]
##              Sepal.Length Sepal.Width Petal.Length Petal.Width
## Sepal.Length   0.13320850  0.10938369  0.019191764 0.011585649
## Sepal.Width    0.10938369  0.15495369  0.012096999 0.010010130
## Petal.Length   0.01919176  0.01209700  0.028275400 0.005818274
## Petal.Width    0.01158565  0.01001013  0.005818274 0.010695632
## [,,2]
##              Sepal.Length Sepal.Width Petal.Length Petal.Width
## Sepal.Length   0.22572159  0.07613348   0.14689934  0.04335826
## Sepal.Width    0.07613348  0.08024338   0.07372331  0.03435893
## Petal.Length   0.14689934  0.07372331   0.16613979  0.04953078
## Petal.Width    0.04335826  0.03435893   0.04953078  0.03338619
## [,,3]
##              Sepal.Length Sepal.Width Petal.Length Petal.Width
## Sepal.Length   0.42943106  0.10784274   0.33452389  0.06538369
## Sepal.Width    0.10784274  0.11596343   0.08905176  0.06134034
## Petal.Length   0.33452389  0.08905176   0.36422115  0.08706895
## Petal.Width    0.06538369  0.06134034   0.08706895  0.08663823</code></pre>
<ul>
<li>MClust 함수에서 클러스터의 수를 3으로 지정했으며, summary 함수의 parameter 인자를 True로 하여 혼합분포의 모수추정치와 함께 각 군집별 해당 자료에 대한 요약 결과를 확인할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="정형-데이터마이닝.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.Mclust</span>(mc)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-65-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-65-2.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-65-3.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-65-4.png" width="672" /></p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="정형-데이터마이닝.html#cb214-1" aria-hidden="true" tabindex="-1"></a>mc<span class="sc">$</span>classification</span></code></pre></div>
<pre><code>##   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
##  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 2
##  [75] 2 2 2 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3
## [112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
## [149] 3 3</code></pre>
<ul>
<li>plot.Mclust 함수를 통해 다양한 방식으로 군집 결과를 시각화할 수 있으며, $classification 인자를 통해 각 개체가 어느 그룹으로 분류되었는지를 확인할 수 있다.</li>
</ul>
</div>
</div>
</div>
<div id="연관분석" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> 연관분석</h2>
<p>연관 분석은 기업의 데이터베이스에 상품의 구매, 서비스 등 일련의 거래 또는 사건들 간의 규칙을 발견하여 If-Then의 구조로 분석 결과의 연관성을 파악하는 데이터마이닝 방법론이다. 연관 분석은 효율적인 상품 진열, 패키지 상품 개발, 교차판매 전략, 기획 상품의 결정 등에 사용되고 있다.</p>
<div id="연관규칙" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> 연관규칙</h3>
<div id="연관규칙분석의-개념" class="section level4" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> 연관규칙분석의 개념</h4>
<ul>
<li>연관성 분석은 흔히 장바구니분석 또는 서열분석이라고 불린다.</li>
<li>기업의 데이터베이스에서 상품의 구매, 서비스 등 일련의 거래 또는 사건들 간의 규칙을 발견하기 위해 적용한다.</li>
<li>장바구니 분석 : 장바구니에 무엇이 같이 들어 있는지에 대한 분석</li>
<li>서열분석 : A를 산 다음에 B를 산다.</li>
</ul>
</div>
<div id="연관규칙의-형태" class="section level4" number="4.4.1.2">
<h4><span class="header-section-number">4.4.1.2</span> 연관규칙의 형태</h4>
<ul>
<li>조건과 반응 (If-Then) 의 형태로 이루어져 있다.</li>
</ul>
</div>
<div id="연관규칙의-측도" class="section level4" number="4.4.1.3">
<h4><span class="header-section-number">4.4.1.3</span> 연관규칙의 측도</h4>
<div id="지지도" class="section level5" number="4.4.1.3.1">
<h5><span class="header-section-number">4.4.1.3.1</span> 지지도</h5>
<ul>
<li>전체 거래 중 항목 A와 항목 B를 동시에 포함하는 거래의 비율로 정의된다.</li>
</ul>
<p><span class="math inline">\(지지도=P(A \cap B)=\frac{A와B가 동시에 포함된 거래수}{전체거래수}=\frac{A \cap B}{전체}\)</span></p>
</div>
<div id="신뢰도" class="section level5" number="4.4.1.3.2">
<h5><span class="header-section-number">4.4.1.3.2</span> 신뢰도</h5>
<ul>
<li>항목 A를 포함한 거래 중에서 항목 A와 항목 B가 같이 포함될 확률이다. 연광성의 정도를 파악할 수 있다.</li>
</ul>
<p><span class="math inline">\(신뢰도 = \frac{P(A \cap B)}{P(A)}=\frac{A와B가동시에 포함된 거래수}{A를 포함하는 거래수}=\frac{지지도}{P(A)}\)</span></p>
</div>
<div id="향상도" class="section level5" number="4.4.1.3.3">
<h5><span class="header-section-number">4.4.1.3.3</span> 향상도</h5>
<ul>
<li>A가 구매되지 않았을 때 품목 B의 구매확률에 비해 A가 구매됐을 때 품목 B의 구매확률의 증가비이다. 연관규칙 A-&gt;B는 품목 A와 품목 B의 구매가 서로 관련이 없는 경우에 향상도가 1이 된다.</li>
</ul>
<p><span class="math inline">\(향상도=\frac{P(B|A)}{P(B)}=\frac{P(A\cap B)}{P(A)P(B)}=\frac{A와B가 동시에 포함된 거래수}{A를 포함하는 거래수\times B를 포함하는 거래수}=\frac{신뢰도}{P(B)}\)</span></p>
</div>
<div id="apriori-알고리즘" class="section level5" number="4.4.1.3.4">
<h5><span class="header-section-number">4.4.1.3.4</span> Apriori 알고리즘</h5>
<center>
<img src="images/tncW2Gn.png" title="fig:" alt="Apriori알고리즘" />
</center>
<ul>
<li>최소지지도보다 큰 지지도값을 갖는 품목의 집합을 빈발항목집합이라고 한다. Apriori 알고리즘은 모든 품목집합에 대한 지지도를 전부 계산하는 것이 아니라, 최소 지지도 이상의 빈발항목집합을 찾은 후 그것들에 대해서만 연관규칙을 계산하는 것이다.</li>
<li>Apriori는 1994년에 발표된 1세대 알고리즘으로 구현과 이해가 쉽다는 장점이 있으나, 지지도가 낮은 후보 집합 생성시 아이템의 개수가 많아지면 계산 복잡도가 증가한다는 문제점을 가지고 있다.</li>
</ul>
</div>
<div id="r을-이용한-연관분석" class="section level5" number="4.4.1.3.5">
<h5><span class="header-section-number">4.4.1.3.5</span> R을 이용한 연관분석</h5>
<ul>
<li>R에서 연관분석을 수행할 수 있는 함수는 apriori이다. apriori함수는 arules 패키지에서 사용이 가능하며, 트랜잭션 데이터를 다루고 데이터 세트 내에서 최소 N번의 트랜잭션이 일어난 아이템 집합들을 찾아 연관규칙을 계산하는 알고리즘이다.</li>
<li>apriori 함수를 이용해 연관분석을 수행하기 전에 as함수를 통해 데이터를 트랜잭션 형태로 변경해야 하며, apriori함수를 이용한 연관분석 결과는 arules 패키지의 inspect함수를 통해 확인할 수 있다.</li>
</ul>
<p><b>함수사용법</b></p>
<pre><code>as(data, class, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>class를 변경하고자 하는 object</td>
</tr>
<tr class="even">
<td>class</td>
<td>object를 변경할 클래스 이름, 연관분석에서는 “transactions”</td>
</tr>
</tbody>
</table>
<pre><code>inspect(x, ...)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x</td>
<td>연관규칙 또는 트랜잭션 또는 아이템 매트릭스 데이터</td>
</tr>
</tbody>
</table>
<p><strong>Q. 통신사의 고객 데이터를 입력하고 as함수로 데이터를 변형하고 inspect 함수로 데이터를 확인해 보자.</strong></p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="정형-데이터마이닝.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;arules&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span>
<span id="cb218-2"><a href="정형-데이터마이닝.html#cb218-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arules)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;arules&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     abbreviate, write</code></pre>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="정형-데이터마이닝.html#cb222-1" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>)</span>
<span id="cb222-2"><a href="정형-데이터마이닝.html#cb222-2" aria-hidden="true" tabindex="-1"></a>gender <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;FEMALE&quot;</span>, <span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>, <span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>)</span>
<span id="cb222-3"><a href="정형-데이터마이닝.html#cb222-3" aria-hidden="true" tabindex="-1"></a>age <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;age_20&quot;</span>, <span class="st">&quot;age_20&quot;</span>, <span class="st">&quot;age_40&quot;</span>, <span class="st">&quot;age_30&quot;</span>, <span class="st">&quot;age_40&quot;</span>, <span class="st">&quot;age_30&quot;</span>)</span>
<span id="cb222-4"><a href="정형-데이터마이닝.html#cb222-4" aria-hidden="true" tabindex="-1"></a>rank <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Gold&quot;</span>, <span class="st">&quot;Silver&quot;</span>, <span class="st">&quot;Silver&quot;</span>, <span class="st">&quot;VIP&quot;</span>, <span class="st">&quot;Gold&quot;</span>, <span class="st">&quot;Gold&quot;</span>)</span>
<span id="cb222-5"><a href="정형-데이터마이닝.html#cb222-5" aria-hidden="true" tabindex="-1"></a>mobile_app_use <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;YES&quot;</span>, <span class="st">&quot;YES&quot;</span>, <span class="st">&quot;NO&quot;</span>, <span class="st">&quot;YES&quot;</span>, <span class="st">&quot;NO&quot;</span>, <span class="st">&quot;YES&quot;</span>)</span>
<span id="cb222-6"><a href="정형-데이터마이닝.html#cb222-6" aria-hidden="true" tabindex="-1"></a>re_order <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;YES&quot;</span>, <span class="st">&quot;NO&quot;</span>, <span class="st">&quot;NO&quot;</span>, <span class="st">&quot;YES&quot;</span>, <span class="st">&quot;NO&quot;</span>, <span class="st">&quot;YES&quot;</span>)</span>
<span id="cb222-7"><a href="정형-데이터마이닝.html#cb222-7" aria-hidden="true" tabindex="-1"></a>cust_tel <span class="ot">&lt;-</span> <span class="fu">cbind</span>(id, gender, age, rank, mobile_app_use, re_order)</span>
<span id="cb222-8"><a href="정형-데이터마이닝.html#cb222-8" aria-hidden="true" tabindex="-1"></a>cust_tel <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(cust_tel)</span>
<span id="cb222-9"><a href="정형-데이터마이닝.html#cb222-9" aria-hidden="true" tabindex="-1"></a>cust_tel_1 <span class="ot">&lt;-</span> <span class="fu">subset</span>(cust_tel, <span class="at">select =</span> <span class="sc">-</span><span class="fu">c</span>(id))</span></code></pre></div>
<details>
<summary>
Click for Result
</summary>
<pre><code>##   gender    age   rank mobile_app_use re_order
## 1 FEMALE age_20   Gold            YES      YES
## 2   MALE age_20 Silver            YES       NO
## 3 FEMALE age_40 Silver             NO       NO
## 4 FEMALE age_30    VIP            YES      YES
## 5   MALE age_40   Gold             NO       NO
## 6 FEMALE age_30   Gold            YES      YES</code></pre>
</details>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="정형-데이터마이닝.html#cb224-1" aria-hidden="true" tabindex="-1"></a>tran.cust<span class="ot">&lt;-</span><span class="fu">as</span>(cust_tel_1, <span class="st">&quot;transactions&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="정형-데이터마이닝.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(tran.cust)</span></code></pre></div>
<pre><code>##     items                transactionID
## [1] {gender=FEMALE,                   
##      age=age_20,                      
##      rank=Gold,                       
##      mobile_app_use=YES,              
##      re_order=YES}                   1
## [2] {gender=MALE,                     
##      age=age_20,                      
##      rank=Silver,                     
##      mobile_app_use=YES,              
##      re_order=NO}                    2
## [3] {gender=FEMALE,                   
##      age=age_40,                      
##      rank=Silver,                     
##      mobile_app_use=NO,               
##      re_order=NO}                    3
## [4] {gender=FEMALE,                   
##      age=age_30,                      
##      rank=VIP,                        
##      mobile_app_use=YES,              
##      re_order=YES}                   4
## [5] {gender=MALE,                     
##      age=age_40,                      
##      rank=Gold,                       
##      mobile_app_use=NO,               
##      re_order=NO}                    5
## [6] {gender=FEMALE,                   
##      age=age_30,                      
##      rank=Gold,                       
##      mobile_app_use=YES,              
##      re_order=YES}                   6</code></pre>
<ul>
<li>as함수를 이용하여 데이터프레임을 transactions 형태로 변환하였으며, 변환된 데이터를 입력하면 데이터의 행과 열의 개수만 나타난다. inspect 함수로 트랜잭션데이터 변환결과를 확인할 수 있다.</li>
</ul>
<p><b>함수사용법</b></p>
<pre><code>apriori(data, parameter, appearance, control)</code></pre>
<table>
<thead>
<tr class="header">
<th>인자</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>data</td>
<td>연관규칙 또는 트랜잭션 또는 아이템 매트릭스 데이터</td>
</tr>
<tr class="even">
<td>parameter</td>
<td>최소 지지도(supp), 신뢰도(conf), 최대아이템개수(maxlen), 최소아이템개수(minlen) 입력</td>
</tr>
<tr class="odd">
<td>appearance</td>
<td>특정 연관규칙 결과를 찾을 수 있음.</td>
</tr>
<tr class="even">
<td>control</td>
<td>결과 보여주기 등의 알고리즘의 성능을 조정할 수 있음</td>
</tr>
</tbody>
</table>
<p><strong>Q. R프로그램의 내장데이터인 Groceries 데이터셋으로 연관규칙분석을 실시해 보자.</strong></p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="정형-데이터마이닝.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="fu">setdiff</span>(<span class="st">&quot;apriori&quot;</span>, <span class="fu">rownames</span>(<span class="fu">installed.packages</span>())))</span></code></pre></div>
<pre><code>## Installing package into &#39;/home/tingyuan/R/x86_64-pc-linux-gnu-library/3.6&#39;
## (as &#39;lib&#39; is unspecified)</code></pre>
<pre><code>## Warning: package &#39;apriori&#39; is not available (for R version 3.6.3)</code></pre>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="정형-데이터마이닝.html#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(arules)</span>
<span id="cb231-2"><a href="정형-데이터마이닝.html#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Groceries&quot;</span>)</span>
<span id="cb231-3"><a href="정형-데이터마이닝.html#cb231-3" aria-hidden="true" tabindex="-1"></a>Groceries</span></code></pre></div>
<pre><code>## transactions in sparse format with
##  9835 transactions (rows) and
##  169 items (columns)</code></pre>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="정형-데이터마이닝.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(Groceries[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span></code></pre></div>
<pre><code>##     items                
## [1] {citrus fruit,       
##      semi-finished bread,
##      margarine,          
##      ready soups}        
## [2] {tropical fruit,     
##      yogurt,             
##      coffee}             
## [3] {whole milk}</code></pre>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="정형-데이터마이닝.html#cb235-1" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">apriori</span>(Groceries, <span class="at">parameter=</span><span class="fu">list</span>(<span class="at">support=</span><span class="fl">0.01</span>, <span class="at">confidence=</span><span class="fl">0.3</span>))</span></code></pre></div>
<pre><code>## Apriori
## 
## Parameter specification:
##  confidence minval smax arem  aval originalSupport maxtime support minlen
##         0.3    0.1    1 none FALSE            TRUE       5    0.01      1
##  maxlen target  ext
##      10  rules TRUE
## 
## Algorithmic control:
##  filter tree heap memopt load sort verbose
##     0.1 TRUE TRUE  FALSE TRUE    2    TRUE
## 
## Absolute minimum support count: 98 
## 
## set item appearances ...[0 item(s)] done [0.00s].
## set transactions ...[169 item(s), 9835 transaction(s)] done [0.01s].
## sorting and recoding items ... [88 item(s)] done [0.00s].
## creating transaction tree ... done [0.01s].
## checking subsets of size 1 2 3 4 done [0.00s].
## writing ... [125 rule(s)] done [0.00s].
## creating S4 object  ... done [0.00s].</code></pre>
<ul>
<li>parameter값을 최소 지지도는 0.01, 최소신뢰도는 0.3으로 지정했으며, 분석 결과를 확인했을 때, 125 rule(s)를 통해 총 125개의 연관규칙이 생성되었음을 알 수 있다.</li>
<li>parameter specification을 통해 구체적인 매개변수 값을 확인할 수 있고 규칙의 수에 따라 지지도와 신뢰도를 높이거나 낮추어 규칙을 조정할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="정형-데이터마이닝.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(<span class="fu">sort</span>(rules, <span class="at">by=</span><span class="fu">c</span>(<span class="st">&quot;confidence&quot;</span>), <span class="at">decreasing=</span><span class="cn">TRUE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>##     lhs                                 rhs                support   
## [1] {citrus fruit,root vegetables}   =&gt; {other vegetables} 0.01037112
## [2] {tropical fruit,root vegetables} =&gt; {other vegetables} 0.01230300
## [3] {curd,yogurt}                    =&gt; {whole milk}       0.01006609
## [4] {other vegetables,butter}        =&gt; {whole milk}       0.01148958
## [5] {tropical fruit,root vegetables} =&gt; {whole milk}       0.01199797
##     confidence coverage   lift     count
## [1] 0.5862069  0.01769192 3.029608 102  
## [2] 0.5845411  0.02104728 3.020999 121  
## [3] 0.5823529  0.01728521 2.279125  99  
## [4] 0.5736041  0.02003050 2.244885 113  
## [5] 0.5700483  0.02104728 2.230969 118</code></pre>
<ul>
<li>sort 함수를 통해 confidence에 따라 내림차순 정리했으며, 1~5위까지의 연관규칙을 확인할 수 있다. lhs는 좌항, rhs는 우항을 뜻하고 좌항을 구매했을 때 우항을 구매하는 규칙이다. 각각의 지지도, 신뢰도, 향상도도 확인이 가능하며, count는 해당 규칙의 개수를 나타낸다.</li>
<li>해당 규칙에서 confidence가 높다는 뜻은 구매 품목들의 연관성이 높음을 뜻하며, lift가 높다는 뜻은 좌항의 제품을 구매할 때, 우항의 제품을 구매할 확률이 약 n배 가량 높음을 뜻한다.</li>
</ul>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="정형-데이터마이닝.html#cb239-1" aria-hidden="true" tabindex="-1"></a>prune.dup.rules<span class="ot">&lt;-</span><span class="cf">function</span>(rules) {</span>
<span id="cb239-2"><a href="정형-데이터마이닝.html#cb239-2" aria-hidden="true" tabindex="-1"></a>  rule.subset.matrix<span class="ot">&lt;-</span><span class="fu">is.subset</span>(rules, rules, <span class="at">sparse=</span><span class="cn">FALSE</span>)</span>
<span id="cb239-3"><a href="정형-데이터마이닝.html#cb239-3" aria-hidden="true" tabindex="-1"></a>  rule.subset.matrix[<span class="fu">lower.tri</span>(rule.subset.matrix, <span class="at">diag=</span><span class="cn">TRUE</span>)]<span class="ot">&lt;-</span><span class="cn">NA</span></span>
<span id="cb239-4"><a href="정형-데이터마이닝.html#cb239-4" aria-hidden="true" tabindex="-1"></a>  dup.rules<span class="ot">&lt;-</span><span class="fu">colSums</span>(rule.subset.matrix, <span class="at">na.rm=</span><span class="cn">TRUE</span>) <span class="sc">&gt;=</span> <span class="dv">1</span></span>
<span id="cb239-5"><a href="정형-데이터마이닝.html#cb239-5" aria-hidden="true" tabindex="-1"></a>  pruned.rules<span class="ot">&lt;-</span>rules[<span class="sc">!</span>dup.rules]</span>
<span id="cb239-6"><a href="정형-데이터마이닝.html#cb239-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(pruned.rules)</span>
<span id="cb239-7"><a href="정형-데이터마이닝.html#cb239-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ul>
<li>좌항에서 우항, 우항에서 좌항의 규칙이 겹치는 경우가 있으므로, 중복 규칙은 없애야 한다. arules 패키지에서는 중복 가지치기 함수를 제공하지 않아 함수를 직접 구현한다.</li>
</ul>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="정형-데이터마이닝.html#cb240-1" aria-hidden="true" tabindex="-1"></a>metric.params<span class="ot">&lt;-</span><span class="fu">list</span>(<span class="at">supp=</span><span class="fl">0.001</span>, <span class="at">conf=</span><span class="fl">0.5</span>, <span class="at">minlen=</span><span class="dv">2</span>)</span>
<span id="cb240-2"><a href="정형-데이터마이닝.html#cb240-2" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">apriori</span>(<span class="at">data=</span>Groceries, <span class="at">parameter=</span>metric.params, </span>
<span id="cb240-3"><a href="정형-데이터마이닝.html#cb240-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">appearance=</span><span class="fu">list</span>(<span class="at">default=</span><span class="st">&quot;lhs&quot;</span>, <span class="at">rhs=</span><span class="st">&quot;soda&quot;</span>), <span class="at">control=</span><span class="fu">list</span>(<span class="at">verbose=</span><span class="cn">FALSE</span>))</span>
<span id="cb240-4"><a href="정형-데이터마이닝.html#cb240-4" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">prune.dup.rules</span>(rules)</span>
<span id="cb240-5"><a href="정형-데이터마이닝.html#cb240-5" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">sort</span>(rules, <span class="at">decreasing=</span><span class="cn">TRUE</span>, <span class="at">by=</span><span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb240-6"><a href="정형-데이터마이닝.html#cb240-6" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(rules[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>##     lhs                                     rhs    support     confidence
## [1] {coffee,misc. beverages}             =&gt; {soda} 0.001016777 0.7692308 
## [2] {sausage,bottled water,bottled beer} =&gt; {soda} 0.001118454 0.7333333 
## [3] {sausage,white bread,shopping bags}  =&gt; {soda} 0.001016777 0.6666667 
## [4] {rolls/buns,bottled water,chocolate} =&gt; {soda} 0.001321810 0.6500000 
## [5] {pastry,misc. beverages}             =&gt; {soda} 0.001220132 0.6315789 
##     coverage    lift     count
## [1] 0.001321810 4.411303 10   
## [2] 0.001525165 4.205442 11   
## [3] 0.001525165 3.823129 10   
## [4] 0.002033554 3.727551 13   
## [5] 0.001931876 3.621912 12</code></pre>
<ul>
<li>parameter를 리스트 형태로 저장하여 apriori 함수에 적용했으며, appearance를 통해 우측의 soda를 사기 위해 좌항의 아이템을 찾는 것으로 설정했다. control 인자에서 verbose는 apriori 함수 실행 결과를 나타낼지의 여부를 묻는 인자로 FALSE를 지정하여 나타내지 않게했다.</li>
<li>생성된 규칙을 중복 규칙 가지치기를 실기하고, confidence를 기준으로 정렬하여 결과를 확인한다. 분석 결과에서 coffee와 misc.beverages를 함께 구매할 경우 soda를 구매한다는 규칙의 confidence가 가장 높게 나타났다.</li>
</ul>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="정형-데이터마이닝.html#cb242-1" aria-hidden="true" tabindex="-1"></a>metric.params<span class="ot">&lt;-</span><span class="fu">list</span>(<span class="at">supp=</span><span class="fl">0.001</span>, <span class="at">conf=</span><span class="fl">0.3</span>, <span class="at">minlen=</span><span class="dv">2</span>)</span>
<span id="cb242-2"><a href="정형-데이터마이닝.html#cb242-2" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">apriori</span>(<span class="at">data=</span>Groceries, <span class="at">parameter=</span>metric.params, </span>
<span id="cb242-3"><a href="정형-데이터마이닝.html#cb242-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">appearance=</span><span class="fu">list</span>(<span class="at">default=</span><span class="st">&quot;rhs&quot;</span>, <span class="at">lhs=</span><span class="fu">c</span>(<span class="st">&quot;yogurt&quot;</span>,<span class="st">&quot;sugar&quot;</span>)), </span>
<span id="cb242-4"><a href="정형-데이터마이닝.html#cb242-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">control=</span><span class="fu">list</span>(<span class="at">verbose=</span><span class="cn">FALSE</span>))</span>
<span id="cb242-5"><a href="정형-데이터마이닝.html#cb242-5" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">prune.dup.rules</span>(rules)</span>
<span id="cb242-6"><a href="정형-데이터마이닝.html#cb242-6" aria-hidden="true" tabindex="-1"></a>rules<span class="ot">&lt;-</span><span class="fu">sort</span>(rules, <span class="at">decreasing=</span><span class="cn">TRUE</span>, <span class="at">by=</span><span class="st">&quot;confidence&quot;</span>)</span>
<span id="cb242-7"><a href="정형-데이터마이닝.html#cb242-7" aria-hidden="true" tabindex="-1"></a><span class="fu">inspect</span>(rules[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>##     lhs               rhs                  support     confidence coverage   
## [1] {sugar}        =&gt; {whole milk}         0.015048297 0.4444444  0.033858668
## [2] {yogurt}       =&gt; {whole milk}         0.056024403 0.4016035  0.139501779
## [3] {sugar}        =&gt; {other vegetables}   0.010777834 0.3183183  0.033858668
## [4] {yogurt}       =&gt; {other vegetables}   0.043416370 0.3112245  0.139501779
## [5] {yogurt,sugar} =&gt; {whipped/sour cream} 0.002135231 0.3088235  0.006914082
##     lift     count
## [1] 1.739400 148  
## [2] 1.571735 551  
## [3] 1.645119 106  
## [4] 1.608457 427  
## [5] 4.308198  21</code></pre>
<ul>
<li>최소 지지도는 0.001, 최소 신뢰도는 0.3, 최소 물품수는 2로 지정하고, appearance를 통해 yogurt, sugar를 구매했을 때, 우항의 아이템을 찾는다. 분석 결과를 확인했을 때, sugar를 구매하면 whole milk를 구매한다는 규칙의 confidence가 가장 높게 나타남을 확인할 수 있다.</li>
</ul>

</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="통계분석.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsubsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
