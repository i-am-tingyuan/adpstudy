[["index.html", "ADPStudy 1 R기초", " ADPStudy tingyuan 2021-09-20 1 R기초 R 기초 "],["데이터-전처리.html", "2 데이터 전처리 2.1 제어문 2.2 데이터 변환 2.3 데이터 결합 및 요약 2.4 패키지를 활용한 데이터 전처리 2.5 결측치 2.6 이상치 인식 2.7 날짜 데이터 전처리", " 2 데이터 전처리 2.1 제어문 2.2 데이터 변환 2.2.1 파생변수 생성 2.2.2 변수 축소 2.2.2.1 주성분분석 2.2.2.1.1 개념 주성분분석이란 데이터에 여러 변수들이 있을 때 서로 상관성이 높은 변수들의 선형결합으로 이루어진 ‘주성분’ 이라는 새로운 변수를 만들어 변수들을 요약하고 축소하는 기법이다. 예를 들어, 변수 x와 z로 y를 예측하고자 할 때 x=3a, z=a+1, y=2x+z와 같은 관계가 성립된다면 굳이 x와 z라는 두 변수를 사용하지 않고, 변수 a로만 y를 예측하는 것이 더 좋을 것이다. 이와 같이 여러 변수의 선형조합으로 만들어진 주성분을 통해 변수들을 축소할 수 있다. 주성분분석을 할 때, 첫 번째 주성분으로 전체 변동을 가장 많이 설명할 수 있도록 하고, 두 번째 주성분으로는 첫 번째 주성분이 설명하지 못하는 나머지 변동을 정보의 손실 없이 가장 많이 설명할 수 있도록 변수들의 선형조합을 만든다. 각 주성분은 서로 독립인 것(상관계수 = 0)을 원칙으로 한다. 2.2.2.1.2 목적 소수의 주성분으로 차원을 축소함. 다중공선성이 존재하는 경우, 상관성이 없는 (적은) 주성분으로 변수들을 축소 주성분분석을 통해 변수 차원을 축소한 후 군집분석을 수행하면 군집화 결과와 연산속도를 개선할 수 있다. 2.2.2.1.3 주성분의 선택 기여율 ’주성분 기여율’을 사용하여 주성분이 데이터를 얼마나 잘 설명하는지 평가함. 주성분 기여율 : 원변수의 총변동 (각 변수들의 분산값 총합) 분의 주성분 변수의 분산으로, 총변동에 대한 주성분의 설명력을 의미한다. 기여율은 1에 가까울수록 적절하고 0에 가까울수록 데이터에 대한 설명력이 떨어진다고 판단한다. 첫번째 주성분부터 차례대로 기여율을 합한 누적 기여율(cumulative proportion)이 85% 이상이 되면 해당 지점까지를 주성분의 수로 결정한다. 아래의 사진에서는 두 번째 주성분까지의 누적 기여율이 약 87%이므로, 주성분의 수를 두 개로 결정한다. 스크리 산점도 (Scree Plot) 주성분을 x축, 각 주성분의 고유값(주성분의 분산)을 y축에 둔 그래프이다. 고유치가 급격히 완만해지는 지점의 바로 전 단계로 주성분의 수를 선택한다. 2.2.2.1.4 R을 이용한 주성분 분석 prcomp(data, center=TRUE, scale.=FALSE, ...) princomp(data, cor=FALSE, scores=TRUE, ...) Q. R에 내장된 USArrests 데이터는 1973년 미국 50개주 100,000명의 인구 당 체포된 세가지 강력범죄수(assault, murder, rape)와 각 주마다 도시에 거주하는 인구의 비율(%)로 구성되어 있다. 주성분 분석을 수행하여 해당 데이터이ㅡ 변수들을 가장 잘 요약하는 주성분을 구하고 해석해 보자. USArrests 데이터는 변수들 간의 척도 차이가 상당히 크기 때문에 상관행렬을 사용하여 분석한다. 특이치 분해를 사용하는 경우 자료 행렬 각 변수의 평균과 제곱의 합이 1로 표준화되었다고 가정할 수 있다. (1) 데이터 확인 및 산점도를 통한 변수 간 상관관계 파악 library(datasets) data(USArrests) head(USArrests) ## Murder Assault UrbanPop Rape ## Alabama 13.2 236 58 21.2 ## Alaska 10.0 263 48 44.5 ## Arizona 8.1 294 80 31.0 ## Arkansas 8.8 190 50 19.5 ## California 9.0 276 91 40.6 ## Colorado 7.9 204 78 38.7 pairs(USArrests, panel=panel.smooth, main=&quot;USArrests data&quot;) (2) 주성분분석 수행 US.prin &lt;- princomp(USArrests, cor=TRUE) summary(US.prin) ## Importance of components: ## Comp.1 Comp.2 Comp.3 Comp.4 ## Standard deviation 1.5748783 0.9948694 0.5971291 0.41644938 ## Proportion of Variance 0.6200604 0.2474413 0.0891408 0.04335752 ## Cumulative Proportion 0.6200604 0.8675017 0.9566425 1.00000000 주성분 분석 결과에 summary함수를 적용하면 결과에 대한 요약 설명이 나온다. summary 결과로 나오는 Standard deviation은 주성분의 표준편차, Proportion of Variance는 주성분의 기여율, Cumulative Proportion은 누적기여율을 의미한다. 제1주성분과 제2주성분까지의 누적 기여율은 대략 86.8%로 2개의 주성분변수를 활용하여 전체 데이터의 약 86.8%를 설명할 수 있다. plot(US.prin, type=&#39;l&#39;) - 주성분들에 의해 설명되는 변동의 비율은 Screeplot을 통해 시각적으로도 확인이 가능하다. 그래프의 3번재 주성분에서 기울기가 급격하게 줄어드는 형태를 보이므로, 그 이전 주성분인 2번째 주성분까지 선택하는 것이 적절하다. (3) Loading US.prin$loadings ## ## Loadings: ## Comp.1 Comp.2 Comp.3 Comp.4 ## Murder 0.536 0.418 0.341 0.649 ## Assault 0.583 0.188 0.268 -0.743 ## UrbanPop 0.278 -0.873 0.378 0.134 ## Rape 0.543 -0.167 -0.818 ## ## Comp.1 Comp.2 Comp.3 Comp.4 ## SS loadings 1.00 1.00 1.00 1.00 ## Proportion Var 0.25 0.25 0.25 0.25 ## Cumulative Var 0.25 0.50 0.75 1.00 주성분분석 결과의 loading을 통해 주성분계수 즉, 네 개의 변수가 각 주성분에 기여하는 가중치가 제시된다. 제 1주성분은 0.536 * Murder + 0.583 * Assault + 0.278 * UrbanPop + 0.543 * Rape의 선형결합식으로 이루어져 있음을 파악할 수 있다. (4) Scores 주성분분석 결과, 차원축소로 얻어지는 주성분점수는 scores 인자를 통해 확인할 수 있다. 주성분 점수는 주성분들의 선형식을 통해 새롭게 계산된 각 행별 좌표를 나타낸다. head(US.prin$scores) ## Comp.1 Comp.2 Comp.3 Comp.4 ## Alabama 0.9855659 1.1333924 0.44426879 0.156267145 ## Alaska 1.9501378 1.0732133 -2.04000333 -0.438583440 ## Arizona 1.7631635 -0.7459568 -0.05478082 -0.834652924 ## Arkansas -0.1414203 1.1197968 -0.11457369 -0.182810896 ## California 2.5239801 -1.5429340 -0.59855680 -0.341996478 ## Colorado 1.5145629 -0.9875551 -1.09500699 0.001464887 (5) 제 1-2 주성분에 의한 행렬도 biplot(US.prin, scale=0) biplot 함수는 제1주성분과 제2주성분으로 이루어진 좌표평면상에 원데이터 행들의 주성분점수를 산점도의 형태로 나타내고, 각 변수에 대한 주성분계수를 화살표로 시각화하여 그래프로 표현해 준다. 제1주성분의 모든 주성분계수는 양수이므로 가로축(PC1)을 기준으로 모든 변수가 0 이상의 값을 가리키는 축을 나타내고 있다. PC1을 이루는 선형 결합식에서 상대적 부하량의 절대값이 가장 큰 Assault 변수는 가장 수평의 형태를 나타내고 있으며, 상대적 부하량의 절대값이 가장 작은 UrbanPop 변수는 가장 수직에 가까운 형태를 나타내고 있다. 2.2.2.2 요인분석 2.2.2.2.1 개념 여러개의 변수들로 이루어진 데이터에서 변수들 간의 상관관계를 고려하여 서로 유사한 변수들을 묶어 새로운 잠재요인들을 추출해내는 분석방법으로, 변수를 축소하고 데이터를 요약하는데 사용 예를 들어, 시험성적에 대한 데이터가 ’국어, 영어, 중국어, 수학, 물리, 음악, 미술’에 해당하는 7개의 변수로 이루어져 있다고 하자. 이 7개가 아닌 공통의 변수들을 파악해 국어, 영어, 중국어를 (언어능력), 수락, 물리를 (수리능력), 음악, 미술을 (예술적 재능) 등과 같이 새로운 요인들로 구성해낼 때 요인분석을 사용한다. 요인분석을 수행하기 위해서는 변수가 간격척도 혹은 비율척도로 측정되어야 하며, 표본(관측치)의 크기는 100개 이상이 바람직하며 최소 50개 이상이 되어야 한다. 2.2.2.2.2 주성분분석 .vs. 요인분석 주성분분석 요인분석 공통점 * 원데이터를 활용하여 몇개의 새로운 변수를 생성* 변수축소 및 데이터 요약에 사용됨 생성되는 변수의 수 통상적으로 2개 지정된 개수 없음 생성되는 변수의 이름 제1, 2주성분과 같이 표현됨 분석가가 변수의 이름을 지정함 생성되는 변수들의 관계 제1주성분이 가장중요. 2주성분이 그다음 대등한 관계 분석방법의 의미 목표변수를 잘 예측/분류하기 위해 기존 변수들의 선형결합으로 이루어진 몇 개의 주성분을 찾아냄 목표변수를 고려하지 않고 주어진 변수들을 비슷한 성격으로 묶어서 새로운 (잠재)변수를 생성 2.2.2.2.3 요인추출방법 주성분분석 : 변수들로부터 요인을 추출하는 방식으로, 전체분산을 토대로 요인을 추출. 가장 많이 사용 공통요인분석 : 잠재요인으로부터 변수들이 산출된 것으로 보는 방식, 공통분산만을 토대로 요인을 추출. 2.2.2.2.4 요인의 수 결정 고유값을 기준으로 할 때는, 고유값이 1이상인 요인들을 추출한다. 스크리 도표에서 요인의 설명력이 하락하다가 완만한 하락으로 추세가 바뀌기 직전의 요인수를 기준으로 요인을 추출한다. 경우에 따라 추출할 요인의 수를 사전에 정의한 후 요인분석을 수행할 수도 있다. 2.2.2.2.5 R을 이용한 요인분석 R에서 요인추출법으로 주성분분석을 사용할 때는 prcomp 혹은 principal 함수를 활용하며, 요인추출법으로 공통요인분석을 사용할 때는 factanal 함수를 사용한다. factanal(data, factors=n, rotation=&quot;varimax&quot;, scores=&quot;regression&quot;, ...) 인자 설명 data 요인분석을 수행할 숫자형 행렬 혹은 데이터프레임 factors 요인의 개수 지정 rotation 요인 회전방법을 선택 (“varimax”, “promax”, “none”이 있음) scores 요인점수 계산방법을 선택 (“regression”, “Bartlett”가 있음) Q. R의 내장 데이터 swiss는 1888년 경 스위스 내 47개주의 사회 경제적 지표(교육, 농업 종사자 비율 등)와 출산율에 대한 데이터이다. 원활한 분석을 위해 먼저 해당 데이터의 6가지 변수들을 min-max 정규화한 뒤 (2장 3절 표준화와 정규화 참고), 요인분석을 실시하여 변수들을 3개의 요인으로 축소해 보자. (factanal 함수 사용) (1) swiss 데이터 확인 data(swiss) str(swiss) ## &#39;data.frame&#39;: 47 obs. of 6 variables: ## $ Fertility : num 80.2 83.1 92.5 85.8 76.9 76.1 83.8 92.4 82.4 82.9 ... ## $ Agriculture : num 17 45.1 39.7 36.5 43.5 35.3 70.2 67.8 53.3 45.2 ... ## $ Examination : int 15 6 5 12 17 9 16 14 12 16 ... ## $ Education : int 12 9 5 7 15 7 7 8 7 13 ... ## $ Catholic : num 9.96 84.84 93.4 33.77 5.16 ... ## $ Infant.Mortality: num 22.2 22.2 20.2 20.3 20.6 26.6 23.6 24.9 21 24.4 ... (2) 정규화 수행 및 실습용 데이터 생성 Min &lt;- apply(swiss, 2, min) Max &lt;- apply(swiss, 2, max) swiss_fa &lt;- scale(swiss, center=Min, scale=(Max-Min)) head(swiss_fa) ## Fertility Agriculture Examination Education Catholic ## Courtelary 0.7860870 0.1785311 0.35294118 0.21153846 0.07981604 ## Delemont 0.8365217 0.4960452 0.08823529 0.15384615 0.84506898 ## Franches-Mnt 1.0000000 0.4350282 0.05882353 0.07692308 0.93254982 ## Moutier 0.8834783 0.3988701 0.26470588 0.11538462 0.32314768 ## Neuveville 0.7286957 0.4779661 0.41176471 0.26923077 0.03076137 ## Porrentruy 0.7147826 0.3853107 0.17647059 0.11538462 0.90362800 ## Infant.Mortality ## Courtelary 0.7215190 ## Delemont 0.7215190 ## Franches-Mnt 0.5949367 ## Moutier 0.6012658 ## Neuveville 0.6202532 ## Porrentruy 1.0000000 (3) 요인분석 수행 factanal(x = swiss_fa, factors=3) ## ## Call: ## factanal(x = swiss_fa, factors = 3) ## ## Uniquenesses: ## Fertility Agriculture Examination Education ## 0.005 0.286 0.213 0.114 ## Catholic Infant.Mortality ## 0.083 0.743 ## ## Loadings: ## Factor1 Factor2 Factor3 ## Fertility -0.512 0.203 0.832 ## Agriculture -0.774 0.312 -0.129 ## Examination 0.751 -0.423 -0.211 ## Education 0.901 -0.262 ## Catholic -0.186 0.913 0.220 ## Infant.Mortality 0.500 ## ## Factor1 Factor2 Factor3 ## SS loadings 2.273 1.164 1.120 ## Proportion Var 0.379 0.194 0.187 ## Cumulative Var 0.379 0.573 0.759 ## ## The degrees of freedom for the model is 0 and the fit was 1e-04 요인분석 결과의 Proportion Var는 각 요인이 설명하는 분산의 비율이며 Cumulative Var는 요인별 해당값의 누적치이다. 세번째 요인에 대한 Cumulative Var 값이 0.759이므로 세 요인은 전체 데이터 분산의 약 76%를 설명할 수 있다고 해석이 가능한다. 2.2.3 표준화와 정규화 2.2.3.1 표준화 (standardization) 각 개체들이 평균을 기준으로 얼마나 떨어져 있는지를 나타내는 값으로 변환하는 과정을 의미하여, 표준화한 후 특정 범위를 벗어난 데이터를 확인하여 이상치 판별에 활용할 수도 있다. Z-Score 표준화는 각 요소의 값에서 평균을 뺀 후 표준편차로 나누어 수행한다. 변환 후 데이터의 평균은 0, 표준편차는 1의 값을 갖게 된다. scale 함수 혹은 사용자 정의 함수를 이용하여 R에서 구현할 수 있다. scale(data, center=TRUE, scale=TRUE) 인자 설명 data 숫자형벡터 center TRUE이면 데이터에서 해당 벡터의 평균을 뺌 Q. R의 내장 데이터 ’mtcars’의 mpg(마일)변수와 hp(총 마력)변수로만 이루어진 데이터프레임(test, cars)을 생성하고, 각 변수를 표준화한 새로운 변수를 추가해 보자. (mpg를 표준화한 변수의 이름은 mpg_scale, hp를 표준화한 변수의 이름은 hp_scale로 지정) data(&quot;mtcars&quot;) str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... test.cars &lt;- mtcars[,c(&quot;mpg&quot;, &quot;hp&quot;)] head(test.cars) ## mpg hp ## Mazda RX4 21.0 110 ## Mazda RX4 Wag 21.0 110 ## Datsun 710 22.8 93 ## Hornet 4 Drive 21.4 110 ## Hornet Sportabout 18.7 175 ## Valiant 18.1 105 test.cars &lt;- transform(test.cars, mpg_scale=scale(test.cars$mpg), hp_scale=scale(test.cars$hp)) head(test.cars) ## mpg hp mpg_scale hp_scale ## Mazda RX4 21.0 110 0.1508848 -0.5350928 ## Mazda RX4 Wag 21.0 110 0.1508848 -0.5350928 ## Datsun 710 22.8 93 0.4495434 -0.7830405 ## Hornet 4 Drive 21.4 110 0.2172534 -0.5350928 ## Hornet Sportabout 18.7 175 -0.2307345 0.4129422 ## Valiant 18.1 105 -0.3302874 -0.6080186 2.2.3.2 정규화 (Normalization) 정규화란 데이터의 범위를 0과 1사이로 변환하여 데이터의 분포를 조정하는 방법으로, 데이터군 내에서 특정 개체가 가지는 위치를 파악하고 비교할 때 유용하게 사용할 수 있다. 일반적으로 많이 사용되는 min-max 정규화는 ’(xi - minx)/(maxi-minx)’의 공식을 이용하며, scale함수 혹은 사용자 정의 함수를 이용하는 등 다양한 방법을 사용할 수 있다. 2.2.3.3 scale 함수 이용 Min &lt;- min(iris$Sepal.Length) Max &lt;- max(iris$Sepal.Length) iris$SL_new &lt;- scale(iris$Sepal.Length, center=Min, scale=Max-Min) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species SL_new ## 1 5.1 3.5 1.4 0.2 setosa 0.22222222 ## 2 4.9 3.0 1.4 0.2 setosa 0.16666667 ## 3 4.7 3.2 1.3 0.2 setosa 0.11111111 ## 4 4.6 3.1 1.5 0.2 setosa 0.08333333 ## 5 5.0 3.6 1.4 0.2 setosa 0.19444444 ## 6 5.4 3.9 1.7 0.4 setosa 0.30555556 2.3 데이터 결합 및 요약 2.3.1 데이터 결합 2.3.1.1 rbind 2.3.1.2 cbind 2.3.1.3 merge merge는 두 데이터프레임에서 기준이 되는 특정 칼럼의 값이 같은 행끼리 묶어 병합하는 함수이다. 이는 데이터베이스에서 join과 같은 역할을 한다. merge(x, y, by, by.x, by.y, all=FALSE, all.x,) (id_name &lt;- data.frame(id=c(&quot;c01&quot;, &quot;c02&quot;, &quot;c03&quot;, &quot;c04&quot;, &quot;c05&quot;, &quot;c06&quot;, &quot;c07&quot;), last_name=c(&quot;Lee&quot;, &quot;Kim&quot;, &quot;Choi&quot;, &quot;park&quot;, &quot;Lim&quot;, &quot;Bae&quot;, &quot;Kim&quot;))) ## id last_name ## 1 c01 Lee ## 2 c02 Kim ## 3 c03 Choi ## 4 c04 park ## 5 c05 Lim ## 6 c06 Bae ## 7 c07 Kim (id_number &lt;- data.frame(id=c(&quot;c03&quot;, &quot;c04&quot;, &quot;c05&quot;, &quot;c06&quot;, &quot;c07&quot;, &quot;c08&quot;, &quot;c09&quot;), number=c(3, 1, 0, 7, 3, 4, 1))) ## id number ## 1 c03 3 ## 2 c04 1 ## 3 c05 0 ## 4 c06 7 ## 5 c07 3 ## 6 c08 4 ## 7 c09 1 Q-1. Inner Join merge(id_name, id_number, by=&quot;id&quot;) ## id last_name number ## 1 c03 Choi 3 ## 2 c04 park 1 ## 3 c05 Lim 0 ## 4 c06 Bae 7 ## 5 c07 Kim 3 Q-2. Outer Join merge(id_name, id_number, by=&quot;id&quot;, all=TRUE) ## id last_name number ## 1 c01 Lee NA ## 2 c02 Kim NA ## 3 c03 Choi 3 ## 4 c04 park 1 ## 5 c05 Lim 0 ## 6 c06 Bae 7 ## 7 c07 Kim 3 ## 8 c08 &lt;NA&gt; 4 ## 9 c09 &lt;NA&gt; 1 Q-3. Left Outer Join merge(id_name, id_number, by=&quot;id&quot;, all.x=TRUE) ## id last_name number ## 1 c01 Lee NA ## 2 c02 Kim NA ## 3 c03 Choi 3 ## 4 c04 park 1 ## 5 c05 Lim 0 ## 6 c06 Bae 7 ## 7 c07 Kim 3 Q-4. Right Outer Join merge(id_name, id_number, by=&quot;id&quot;, all.y=TRUE) ## id last_name number ## 1 c03 Choi 3 ## 2 c04 park 1 ## 3 c05 Lim 0 ## 4 c06 Bae 7 ## 5 c07 Kim 3 ## 6 c08 &lt;NA&gt; 4 ## 7 c09 &lt;NA&gt; 1 2.3.2 데이터 요약 2.3.2.1 aggregate aggregate(x, by, FUN) aggregate(formula, data, FUN) Q1. iris 데이터에서 종별 Sepal.width의 평균을 구해보자. aggregate(Sepal.Width~Species, iris, mean) ## Species Sepal.Width ## 1 setosa 3.428 ## 2 versicolor 2.770 ## 3 virginica 2.974 Q2. iris 데이터에서 종별 Sepal.Width와 Petal.Width의 평균을 구해보자. aggregate(cbind(Sepal.Width, Petal.Width)~Species, iris, mean) ## Species Sepal.Width Petal.Width ## 1 setosa 3.428 0.246 ## 2 versicolor 2.770 1.326 ## 3 virginica 2.974 2.026 2.3.2.2 table Q1. 내장 데이터 Titanic은 타이타닉호 탑승자들의 특성에 따른 생존여부를 기록해놓은 데이터이다. Titanic 데이터에서 좌석등급을 의미하는 Class 변수에 대해서 도수분포표를 생성해 보자. 내장데이터 Titanic의 구조 확인 str(Titanic) ## &#39;table&#39; num [1:4, 1:2, 1:2, 1:2] 0 0 35 0 0 0 17 0 118 154 ... ## - attr(*, &quot;dimnames&quot;)=List of 4 ## ..$ Class : chr [1:4] &quot;1st&quot; &quot;2nd&quot; &quot;3rd&quot; &quot;Crew&quot; ## ..$ Sex : chr [1:2] &quot;Male&quot; &quot;Female&quot; ## ..$ Age : chr [1:2] &quot;Child&quot; &quot;Adult&quot; ## ..$ Survived: chr [1:2] &quot;No&quot; &quot;Yes&quot; 데이터프레임으로 변환한 뒤 다시 구조를 확인 Titanic&lt;-as.data.frame(Titanic) str(Titanic) ## &#39;data.frame&#39;: 32 obs. of 5 variables: ## $ Class : Factor w/ 4 levels &quot;1st&quot;,&quot;2nd&quot;,&quot;3rd&quot;,..: 1 2 3 4 1 2 3 4 1 2 ... ## $ Sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 1 1 1 1 2 2 2 2 1 1 ... ## $ Age : Factor w/ 2 levels &quot;Child&quot;,&quot;Adult&quot;: 1 1 1 1 1 1 1 1 2 2 ... ## $ Survived: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Freq : num 0 0 35 0 0 0 17 0 118 154 ... table 함수를 이용하여 범주형 변수 Class에 대한 도수분포표를 생성 table(Titanic$Class) ## ## 1st 2nd 3rd Crew ## 8 8 8 8 Q2. 내장데이터 Titanic에서 Survived 변수는 승객의 생존여부를 의미한다. 좌석등급과 생존여부의 관계를 살펴보기 위해 Class 변수에 따른 Survived 변수의 도수를 표 형태로 나타내 보자. table(Titanic$Class, Titanic$Survived) ## ## No Yes ## 1st 4 4 ## 2nd 4 4 ## 3rd 4 4 ## Crew 4 4 2.3.2.3 prop.table prop.table(table) prop.table(table, 1) prop.table(table, 2) Q. Titanic 데이터에서 Age 변수는 해당 승객이 어른인지 아이인지의 여부를 나타낸다. Age 변수에 따른 생존여부의 관계를 전체에 대한 비율, 행별 비율, 열별 비율로 살펴보자. prop.table(table(Titanic$Age, Titanic$Survived)) ## ## No Yes ## Child 0.25 0.25 ## Adult 0.25 0.25 prop.table(table(Titanic$Age, Titanic$Survived), 1) ## ## No Yes ## Child 0.5 0.5 ## Adult 0.5 0.5 prop.table(table(Titanic$Age, Titanic$Survived), 2) ## ## No Yes ## Child 0.5 0.5 ## Adult 0.5 0.5 2.3.3 apply 계열 함수 2.3.3.1 apply apply는 데이터의 행 혹은 열 방향으로 주어진 함수를 한번에 적용한 뒤 그 결과를 벡터, 배열, 리스트로 반환하는 함수이다. apply(X, MARGIN, FUN) a &lt;- matrix(1:12, nrow=4, ncol=3) apply(a, 1, max) ## [1] 9 10 11 12 apply(iris[, 1:4], 2, mean) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 5.843333 3.057333 3.758000 1.199333 2.3.3.2 lapply lapply(X, FUN, ...) a &lt;- c(1, 2, 3) lapply(a, FUN=function(x){x ^ 2}) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 9 class(lapply(a, FUN=function(x){x^2})) ## [1] &quot;list&quot; b&lt;- lapply(a, FUN=function(x){x^2}) unlist(b) ## [1] 1 4 9 2.3.3.3 sapply sapply(X, FUN, simplify=TRUE, ...) Q1. iris 데이터에서 각 칼럼별 데이터 타입을 구해보자. sapply(iris, class) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species SL_new ## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;factor&quot; &quot;matrix&quot; Q2. iris 데이터에서 각 칼럼에 summary 함수를 적용해 보자. sapply(iris, summary) ## $Sepal.Length ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4.300 5.100 5.800 5.843 6.400 7.900 ## ## $Sepal.Width ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.000 2.800 3.000 3.057 3.300 4.400 ## ## $Petal.Length ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.600 4.350 3.758 5.100 6.900 ## ## $Petal.Width ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.100 0.300 1.300 1.199 1.800 2.500 ## ## $Species ## setosa versicolor virginica ## 50 50 50 ## ## $SL_new ## V1 ## Min. :0.0000 ## 1st Qu.:0.2222 ## Median :0.4167 ## Mean :0.4287 ## 3rd Qu.:0.5833 ## Max. :1.0000 2.3.3.4 vapply vapply(X, FUN, FUN.VALUE, ...) Q. 1~100까지의 숫자가 저장된 리스트에 fivenum 함수를 적용한 후, 각 값에 이름을 부여하여 리스트 형태로 출력해 보자. test &lt;- c(1:100) fivenum(test) ## [1] 1.0 25.5 50.5 75.5 100.0 test &lt;- list(test) (test2 &lt;- vapply(test, fivenum, c(&quot;Min&quot;=0, &quot;Q1&quot;=0, &quot;Median&quot;=0, &quot;Q3&quot;=0, &quot;Max&quot;=0))) ## [,1] ## Min 1.0 ## Q1 25.5 ## Median 50.5 ## Q3 75.5 ## Max 100.0 2.3.3.5 mapply mapply(FUN, arg1, arg2, ..., argn, ...) Q. 1을 4번, 2를 3번, 3을 2번, 4를 1번 반복하는 4개의 수열을 구해보자. 이 때 rep 함수를 이용할 때와 mapply 함수를 이용 할 때를 비교해 보자. mapply(rep, c(1:4), c(4:1)) ## [[1]] ## [1] 1 1 1 1 ## ## [[2]] ## [1] 2 2 2 ## ## [[3]] ## [1] 3 3 ## ## [[4]] ## [1] 4 2.3.3.6 tapply tapply 함수를 이용하면 데이터를 특정 기준에 따라 그룹으로 나눈 뒤 각 그룹별로 함수를 적용하여 그 결과를 반환할 수 있다. tapply(DATA, INDEX, FUN, ...) Q1. R의 googleVis 패키지에 있는 Fruits 데이터에서 과일종류별 판매량의 평균을 구해보자. install.packages(setdiff(&quot;googleVis&quot;, rownames(installed.packages()))) library(googleVis) ## Creating a generic function for &#39;toJSON&#39; from package &#39;jsonlite&#39; in package &#39;googleVis&#39; ## ## Welcome to googleVis version 0.6.10 ## ## Please read Google&#39;s Terms of Use ## before you start using the package: ## https://developers.google.com/terms/ ## ## Note, the plot method of googleVis will by default use ## the standard browser to display its output. ## ## See the googleVis package vignettes for more details, ## or visit https://github.com/mages/googleVis. ## ## To suppress this message use: ## suppressPackageStartupMessages(library(googleVis)) head(Fruits) ## Fruit Year Location Sales Expenses Profit Date ## 1 Apples 2008 West 98 78 20 2008-12-31 ## 2 Apples 2009 West 111 79 32 2009-12-31 ## 3 Apples 2010 West 89 76 13 2010-12-31 ## 4 Oranges 2008 East 96 81 15 2008-12-31 ## 5 Bananas 2008 East 85 76 9 2008-12-31 ## 6 Oranges 2009 East 93 80 13 2009-12-31 tapply(Fruits$Sales, Fruits$Fruit, mean) ## Apples Bananas Oranges ## 99.33333 86.66667 95.66667 Q2. Fruits 데이터에서 Location이 West인 것과 아닌 것으로 그룹을 지정하여 Profit의 평균을 구해보자. tapply(Fruits$Profit, Fruits$Location==&quot;West&quot;, mean) ## FALSE TRUE ## 11.66667 21.66667 2.4 패키지를 활용한 데이터 전처리 2.4.1 plyr 2.4.1.1 plyr 패키지 plyr 패키지의 함수들은 데이터를 분할(split)한 뒤 원하는 방향으로 특정 함수를 적용하고 (apply), 그 결과를 재조합 (combine) 하여 반환해 준다. 2.4.1.2 adply adply(data, margins, fun) Q. R의 iris 데이터에서 Petal.Length 변수가 1.5 미만이면서 Species 변수 값이 ’setosa’인 조건을 만족하는 경우 ’1’을 그렇지 않은 경우 ’0’을 부여한 칼럼을 생성하여, 원래의 iris 데이터와 함께 데이터프레임 형태로 출력해 보자. install.packages(setdiff(&quot;plyr&quot;, rownames(installed.packages()))) library(plyr) head(adply(iris, 1, function(row) {ifelse(row$Petal.Length &lt; 1.5 &amp; row$Species == &quot;setosa&quot;, &quot;1&quot;, &quot;0&quot;)})) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species SL_new V1 ## 1 5.1 3.5 1.4 0.2 setosa 0.22222222 1 ## 2 4.9 3.0 1.4 0.2 setosa 0.16666667 1 ## 3 4.7 3.2 1.3 0.2 setosa 0.11111111 1 ## 4 4.6 3.1 1.5 0.2 setosa 0.08333333 0 ## 5 5.0 3.6 1.4 0.2 setosa 0.19444444 1 ## 6 5.4 3.9 1.7 0.4 setosa 0.30555556 0 2.4.1.3 ddply ddply(data, .variables, ddply-func, fun) Q1. iris 데이터에서 Species별로 나머지 네 개 변수의 평균을 출력해 보자. ddply(iris, .(Species), function(sub) { data.frame( mean_SL = mean(sub$Sepal.Length), mean_SW = mean(sub$Sepal.Width), mean_PL = mean(sub$Petal.Length), mean_PW = mean(sub$Petal.Width) ) }) ## Species mean_SL mean_SW mean_PL mean_PW ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026 Q2. iris 데이터에서 Species와 Petal.Length가 1.5 미만인지 여부로 데이터를 그룹지어 네 개 변수의 평균을 출력해 보자. ddply(iris, .(Species, Petal.Length&lt;1.5), function(sub) { data.frame( mean_SL = mean(sub$Sepal.Length), mean_SW = mean(sub$Sepal.Width), mean_PL = mean(sub$Petal.Length), mean_PW = mean(sub$Petal.Width)) }) ## Species Petal.Length &lt; 1.5 mean_SL mean_SW mean_PL mean_PW ## 1 setosa FALSE 5.107692 3.515385 1.588462 0.2730769 ## 2 setosa TRUE 4.895833 3.333333 1.325000 0.2166667 ## 3 versicolor FALSE 5.936000 2.770000 4.260000 1.3260000 ## 4 virginica FALSE 6.588000 2.974000 5.552000 2.0260000 2.4.1.3.1 transform head(ddply(baseball, .(id), transform, avgG=sum(g)/length(year))) ## id year stint team lg g ab r h X2b X3b hr rbi sb cs bb so ibb ## 1 aaronha01 1954 1 ML1 NL 122 468 58 131 27 6 13 69 2 2 28 39 NA ## 2 aaronha01 1955 1 ML1 NL 153 602 105 189 37 9 27 106 3 1 49 61 5 ## 3 aaronha01 1956 1 ML1 NL 153 609 106 200 34 14 26 92 2 4 37 54 6 ## 4 aaronha01 1957 1 ML1 NL 151 615 118 198 27 6 44 132 1 1 57 58 15 ## 5 aaronha01 1958 1 ML1 NL 153 601 109 196 34 4 30 95 4 1 59 49 16 ## 6 aaronha01 1959 1 ML1 NL 154 629 116 223 46 7 39 123 8 0 51 54 17 ## hbp sh sf gidp avgG ## 1 3 6 4 13 143.3913 ## 2 3 7 4 20 143.3913 ## 3 2 5 7 21 143.3913 ## 4 0 0 3 13 143.3913 ## 5 1 0 3 21 143.3913 ## 6 4 0 9 19 143.3913 2.4.1.3.2 mutate # avgG 칼럼과 avgG_RND 칼럼을 한번에 추가하여 출력. # 이 경우, mutate가 아닌 tansform을 사용하면 에러가 발생함. head(ddply(baseball, .(id), mutate, avgG=sum(g)/length(year), avgG_RND=round(avgG))) ## id year stint team lg g ab r h X2b X3b hr rbi sb cs bb so ibb ## 1 aaronha01 1954 1 ML1 NL 122 468 58 131 27 6 13 69 2 2 28 39 NA ## 2 aaronha01 1955 1 ML1 NL 153 602 105 189 37 9 27 106 3 1 49 61 5 ## 3 aaronha01 1956 1 ML1 NL 153 609 106 200 34 14 26 92 2 4 37 54 6 ## 4 aaronha01 1957 1 ML1 NL 151 615 118 198 27 6 44 132 1 1 57 58 15 ## 5 aaronha01 1958 1 ML1 NL 153 601 109 196 34 4 30 95 4 1 59 49 16 ## 6 aaronha01 1959 1 ML1 NL 154 629 116 223 46 7 39 123 8 0 51 54 17 ## hbp sh sf gidp avgG avgG_RND ## 1 3 6 4 13 143.3913 143 ## 2 3 7 4 20 143.3913 143 ## 3 2 5 7 21 143.3913 143 ## 4 0 0 3 13 143.3913 143 ## 5 1 0 3 21 143.3913 143 ## 6 4 0 9 19 143.3913 143 2.4.1.3.3 summarise head(ddply(baseball, .(id), summarise, year_fin=max(year))) ## id year_fin ## 1 aaronha01 1976 ## 2 abernte02 1972 ## 3 adairje01 1970 ## 4 adamsba01 1926 ## 5 adamsbo03 1959 ## 6 adcocjo01 1966 head(ddply(baseball, .(team), summarise, hr_sum=sum(hr))) ## team hr_sum ## 1 ALT 0 ## 2 ANA 134 ## 3 ARI 809 ## 4 ATL 3272 ## 5 BAL 4243 ## 6 BFN 74 2.4.2 dplyr 2.4.2.1 dplyr 패키지 2.4.2.2 filter dataframe name %&gt;% filter(condition) Q. Cars93 데이터에서 제조사가 “Audi” 혹은 “BMW”이면서, 엔진크기가 2.4 이상인 행들만 추출해 보자. install.packages(setdiff(&quot;dplyr&quot;, rownames(installed.packages()))) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:plyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select Cars93 %&gt;% filter((Manufacturer==&quot;Audi&quot;|Manufacturer==&quot;BMW&quot;) &amp; EngineSize &gt;= 2.4) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Audi 90 Compact 25.9 29.1 32.3 20 26 ## 2 Audi 100 Midsize 30.8 37.7 44.6 19 26 ## 3 BMW 535i Midsize 23.7 30.0 36.2 22 30 ## AirBags DriveTrain Cylinders EngineSize Horsepower RPM ## 1 Driver only Front 6 2.8 172 5500 ## 2 Driver &amp; Passenger Front 6 2.8 172 5500 ## 3 Driver only Rear 4 3.5 208 5700 ## Rev.per.mile Man.trans.avail Fuel.tank.capacity Passengers Length Wheelbase ## 1 2280 Yes 16.9 5 180 102 ## 2 2535 Yes 21.1 6 193 106 ## 3 2545 Yes 21.1 4 186 109 ## Width Turn.circle Rear.seat.room Luggage.room Weight Origin Make ## 1 67 37 28 14 3375 non-USA Audi 90 ## 2 70 37 31 17 3405 non-USA Audi 100 ## 3 69 39 27 13 3640 non-USA BMW 535i 2.4.2.3 select Q1. Cars93 데이터의 모델번호, 종류, 가격 변수들만 추출해 보자. # Cars93 %&gt;% select(Model, Type, Price) # Error in select(., Model, Type, Price) : unused arguments (Model, Type, Price) Calls: &lt;Anomymous&gt; ... # withCallingHandlers -&gt; withVisible -&gt; eval -&gt; eval -&gt; %&gt;% Execution halted # 에러 발생 이유 : MASS 패키지의 select()와 dplyr의 select()가 충돌하기 때문 head(Cars93 %&gt;% dplyr::select(Model, Type, Price)) ## Model Type Price ## 1 Integra Small 15.9 ## 2 Legend Midsize 33.9 ## 3 90 Compact 29.1 ## 4 100 Midsize 37.7 ## 5 535i Midsize 30.0 ## 6 Century Midsize 15.7 Q2. 제조사가 “Chevrolet” 혹은 “Volkswagen” 이면서, 가격이 10 이상인 행들의 제조사, 모델, 종류, 가격 변수들만 추출해 보자. Cars93 %&gt;% filter((Manufacturer==&quot;Chevrolet&quot;|Manufacturer==&quot;Volkswagen&quot;) &amp; Price &gt;= 10) %&gt;% dplyr::select(Manufacturer, Model, Type, Price) ## Manufacturer Model Type Price ## 1 Chevrolet Cavalier Compact 13.4 ## 2 Chevrolet Corsica Compact 11.4 ## 3 Chevrolet Camaro Sporty 15.1 ## 4 Chevrolet Lumina Midsize 15.9 ## 5 Chevrolet Lumina_APV Van 16.3 ## 6 Chevrolet Astro Van 16.6 ## 7 Chevrolet Caprice Large 18.8 ## 8 Chevrolet Corvette Sporty 38.0 ## 9 Volkswagen Eurovan Van 19.7 ## 10 Volkswagen Passat Compact 20.0 ## 11 Volkswagen Corrado Sporty 23.3 2.4.2.4 group_by 와 summarise Q1. Cars93 데이터의 제조사별 가격의 평균과 무게의 최댓값을 산출한 뒤 변수명을 각각 mean_Price, max_Weight로 지정하여 출력해 보자. Cars93 %&gt;% group_by(Manufacturer) %&gt;% summarise(mean_Price=mean(Price), max_Weight=max(Weight)) ## # A tibble: 32 x 3 ## Manufacturer mean_Price max_Weight ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Acura 24.9 3560 ## 2 Audi 33.4 3405 ## 3 BMW 30 3640 ## 4 Buick 21.6 4105 ## 5 Cadillac 37.4 3935 ## 6 Chevrolet 18.2 4025 ## 7 Chrylser 18.4 3515 ## 8 Chrysler 22.6 3570 ## 9 Dodge 15.7 3805 ## 10 Eagle 15.8 3490 ## # … with 22 more rows Q2. 종류와 에어백을 기준으로 데이터를 그룹화한 뒤, 자동차 평균 무게를 구해 보자. Cars93 %&gt;% group_by(Type, AirBags) %&gt;% summarise(mean_Weight=mean(Weight)) ## `summarise()` has grouped output by &#39;Type&#39;. You can override using the `.groups` argument. ## # A tibble: 15 x 3 ## # Groups: Type [6] ## Type AirBags mean_Weight ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Compact Driver &amp; Passenger 3062. ## 2 Compact Driver only 2991. ## 3 Compact None 2730 ## 4 Large Driver &amp; Passenger 3639. ## 5 Large Driver only 3728. ## 6 Midsize Driver &amp; Passenger 3554. ## 7 Midsize Driver only 3344. ## 8 Midsize None 3285 ## 9 Small Driver only 2423 ## 10 Small None 2278. ## 11 Sporty Driver &amp; Passenger 3115 ## 12 Sporty Driver only 2939. ## 13 Sporty None 2578. ## 14 Van Driver only 3742. ## 15 Van None 3875 2.4.2.5 mutate mutate는 데이터에 새로운 파생변수를 추가해 주는 함수이며, 사용법은 아래와 같다. Q1. Cars93 데이터에서 가격이 12미만이면 “low”, 12 이상 23 미만이면 “middle”, 23 이상이면 “high” 값을 가지는 Pr_level 변수를 생성한 뒤, 모델, 가격, 새로운 파생변수 Pr_level만 출력해 보자. head( Cars93 %&gt;% mutate(Pr_level=ifelse(Price &lt; 12, &quot;low&quot;, ifelse(Price &gt;= 12 &amp; Price &lt; 23, &quot;middle&quot;, &quot;high&quot;))) %&gt;% dplyr::select(Model, Price, Pr_level) ) ## Model Price Pr_level ## 1 Integra 15.9 middle ## 2 Legend 33.9 high ## 3 90 29.1 high ## 4 100 37.7 high ## 5 535i 30.0 high ## 6 Century 15.7 middle 2.4.2.6 arrange arrange는 특정열 기준으로 데이터를 정렬해주는 함수이며, 사용법은 아래와 같다. Q. Cars93 데이터에서 종류가 “Midsize” 혹은 “Small”인 데이터의 Model, Type, Weight, Price 변수들만 추출한 뒤, 종류별로 Weight 변수값들이 Weight의 중앙값보다 작은 경우는 “low”, 중앙값 이상인 경우 “high” 값을 갖는 Weight_lv 변수를 생성하라. 그리고 Price 변수를 기준으로 데이터를 오름차순으로 정렬하여 출력하라. Cars93 %&gt;% filter(Type %in% c(&quot;Midsize&quot;, &quot;Small&quot;)) %&gt;% dplyr::select(Model, Type, Weight, Price) %&gt;% group_by(Type) %&gt;% mutate(Weight_lv = ifelse(Weight &lt; median(Weight), &quot;low&quot;, &quot;high&quot;)) %&gt;% arrange(Price) ## # A tibble: 43 x 5 ## # Groups: Type [2] ## Model Type Weight Price Weight_lv ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Festiva Small 1845 7.4 low ## 2 Excel Small 2345 8 high ## 3 323 Small 2325 8.3 low ## 4 Metro Small 1695 8.4 low ## 5 Justy Small 2045 8.4 low ## 6 Swift Small 1965 8.6 low ## 7 LeMans Small 2350 9 high ## 8 Fox Small 2240 9.1 low ## 9 Colt Small 2270 9.2 low ## 10 Tercel Small 2055 9.8 low ## # … with 33 more rows 2.4.2.7 {left, right, inner, full}_join Q. 카페에서 판매하는 메뉴 코드, 이름을 담은 데이터 ’NAME’과 메뉴코드 해당 메뉴의 가격을 담은 데이터 ’PRICE’를 생성해보자. 그 후 각 메뉴의 고유코드를 의미하는 code 변수를 기준으로 left, right, inner, full_join을 수행하여 결과를 확인해 보자. NAME&lt;-data.frame(code=c(&quot;A01&quot;, &quot;A02&quot;, &quot;A03&quot;), name=c(&quot;coffee&quot;, &quot;cake&quot;, &quot;cookie&quot;)) PRICE&lt;-data.frame(code=c(&quot;A01&quot;, &quot;A02&quot;, &quot;A04&quot;), price=c(3000, 4000, 3000)) (cafe_left &lt;- left_join(NAME, PRICE, by=&quot;code&quot;)) ## code name price ## 1 A01 coffee 3000 ## 2 A02 cake 4000 ## 3 A03 cookie NA (cafe_right &lt;- right_join(NAME, PRICE, by=&quot;code&quot;)) ## code name price ## 1 A01 coffee 3000 ## 2 A02 cake 4000 ## 3 A04 &lt;NA&gt; 3000 (cafe_inner &lt;- inner_join(NAME, PRICE, by=&quot;code&quot;)) ## code name price ## 1 A01 coffee 3000 ## 2 A02 cake 4000 (cafe_full &lt;- full_join(NAME, PRICE, by=&quot;code&quot;)) ## code name price ## 1 A01 coffee 3000 ## 2 A02 cake 4000 ## 3 A03 cookie NA ## 4 A04 &lt;NA&gt; 3000 2.4.2.8 bind_rows과 bind_cols # rbind(NAME, PRICE) # 변수명이 다르므로 에러가 발생함 bind_rows(NAME,PRICE) ## code name price ## 1 A01 coffee NA ## 2 A02 cake NA ## 3 A03 cookie NA ## 4 A01 &lt;NA&gt; 3000 ## 5 A02 &lt;NA&gt; 4000 ## 6 A04 &lt;NA&gt; 3000 2.4.3 reshape2 2.4.3.1 reshape2 패키지 2.4.3.2 melt Q. R의 airquality는 1973년 5월~9월 동안 뉴욕이ㅡ 일일 대기 질 측정량에 대한 데이터로, 153개의 행과 6개의 변수로 이루어져 있다. 6개의 변수 중 Month와 Day을 식별자로 두고, 나머지 변수와 변수값은 모두 데이터 내에 포함되는 형태로 변환해 보자. install.packages(setdiff(&quot;reshape2&quot;, rownames(installed.packages()))) library(reshape2) head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 head(melt(airquality, id.vars=c(&quot;Month&quot;, &quot;Day&quot;), na.rm=TRUE)) ## Month Day variable value ## 1 5 1 Ozone 41 ## 2 5 2 Ozone 36 ## 3 5 3 Ozone 12 ## 4 5 4 Ozone 18 ## 6 5 6 Ozone 28 ## 7 5 7 Ozone 23 2.4.3.3 dcast air_melt&lt;-melt(airquality, id.vars=c(&quot;Month&quot;, &quot;Day&quot;), na.rm=TRUE) head(air_melt) ## Month Day variable value ## 1 5 1 Ozone 41 ## 2 5 2 Ozone 36 ## 3 5 3 Ozone 12 ## 4 5 4 Ozone 18 ## 6 5 6 Ozone 28 ## 7 5 7 Ozone 23 air_dcast&lt;-dcast(air_melt, Month + Day ~ ...) head(air_dcast) ## Month Day Ozone Solar.R Wind Temp ## 1 5 1 41 190 7.4 67 ## 2 5 2 36 118 8.0 72 ## 3 5 3 12 149 12.6 74 ## 4 5 4 18 313 11.5 62 ## 5 5 5 NA NA 14.3 56 ## 6 5 6 28 NA 14.9 66 2.4.4 data.table 2.4.4.1 data.table 패키지 2.4.4.2 데이터 테이블 생성 Q1. install.packages(setdiff(&quot;data.table&quot;, rownames(installed.packages()))) library(data.table) ## ## Attaching package: &#39;data.table&#39; ## The following objects are masked from &#39;package:reshape2&#39;: ## ## dcast, melt ## The following objects are masked from &#39;package:dplyr&#39;: ## ## between, first, last (mydata&lt;-data.table(x=c(1:3), y=c(&quot;가&quot;, &quot;나&quot;, &quot;다&quot;))) ## x y ## 1: 1 가 ## 2: 2 나 ## 3: 3 다 class(mydata) ## [1] &quot;data.table&quot; &quot;data.frame&quot; 2.4.4.3 데이터 접근 iris_dt&lt;-as.data.table(iris) iris_dt[,mean(Petal.Length), by=Species] ## Species V1 ## 1: setosa 1.462 ## 2: versicolor 4.260 ## 3: virginica 5.552 # Petal.Length값이 1이상인 행들을 Species로 그룹화한 뒤, # Sepal.Length와 Sepal.Width의 평균을 각각 mean.SL과 mean.SW를 변수명으로 하여 출력 iris_dt[Petal.Length&gt;=1, .(mean.SL=mean(Sepal.Length), mean.SW=mean(Sepal.Width)), by=Species] ## Species mean.SL mean.SW ## 1: setosa 5.006 3.428 ## 2: versicolor 5.936 2.770 ## 3: virginica 6.588 2.974 2.4.4.4 새로운 변수 생성 #하나의 변수 추가 데이터테이블[행, 새로운 칼럼명:=값, by=&quot;그룹화 기준 변수&quot;] #여러개의 변수 추가 데이터테이블[행, c(&quot;칼럼명1&quot;, ..., &quot;칼럼명n&quot;):=list(값1, ..., 값n), by=&quot;그룹화 기준 변수&quot;] air&lt;-as.data.table(airquality) air[, Wind_class:=ifelse(Wind&gt;=mean(Wind), &quot;U&quot;, &quot;D&quot;)] head(air) ## Ozone Solar.R Wind Temp Month Day Wind_class ## 1: 41 190 7.4 67 5 1 D ## 2: 36 118 8.0 72 5 2 D ## 3: 12 149 12.6 74 5 3 U ## 4: 18 313 11.5 62 5 4 U ## 5: NA NA 14.3 56 5 5 U ## 6: 28 NA 14.9 66 5 6 U 2.4.4.5 데이터 정렬 air[, season:=ifelse(Month %in% c(12,1,2), &quot;winter&quot;, ifelse(Month %in% c(3:5), &quot;spring&quot;, ifelse(Month %in% c(6:8), &quot;summer&quot;, &quot;fall&quot;)))] head(air) ## Ozone Solar.R Wind Temp Month Day Wind_class season ## 1: 41 190 7.4 67 5 1 D spring ## 2: 36 118 8.0 72 5 2 D spring ## 3: 12 149 12.6 74 5 3 U spring ## 4: 18 313 11.5 62 5 4 U spring ## 5: NA NA 14.3 56 5 5 U spring ## 6: 28 NA 14.9 66 5 6 U spring air[, .(Ozone_mean=mean(Ozone, na.rm=TRUE), Solar.R_mean=mean(Solar.R, na.rm=TRUE)), by=.(season)][order(Ozone_mean, decreasing=TRUE)] ## season Ozone_mean Solar.R_mean ## 1: summer 55.09836 193.5730 ## 2: fall 31.44828 167.4333 ## 3: spring 23.61538 181.2963 2.4.4.6 key를 활용하여 데이터 다루기 baseball&lt;-as.data.table(baseball) setkey(baseball, year) baseball[J(1960)] ## id year stint team lg g ab r h X2b X3b hr rbi sb cs bb so ibb ## 1: abernte02 1960 1 WS1 AL 2 1 1 1 0 0 0 0 0 0 0 0 0 ## 2: adairje01 1960 1 BAL AL 3 5 1 1 0 0 1 1 0 0 0 0 0 ## 3: aguirha01 1960 1 DET AL 37 28 0 1 0 0 0 0 0 0 0 19 0 ## 4: aparilu01 1960 1 CHA AL 153 600 86 166 20 7 2 61 51 8 43 39 3 ## 5: barbest01 1960 1 BAL AL 36 54 1 3 0 0 0 1 0 0 5 32 0 ## --- ## 195: torrejo01 1960 1 ML1 NL 2 2 0 1 0 0 0 0 0 0 0 1 0 ## 196: vernomi01 1960 1 PIT NL 9 8 0 1 0 0 0 1 0 0 1 0 1 ## 197: willibi01 1960 1 CHN NL 12 47 4 13 0 2 2 7 0 0 5 12 0 ## 198: willist02 1960 1 LAN NL 38 64 7 9 1 0 2 7 0 0 3 35 0 ## 199: willsma01 1960 1 LAN NL 148 516 75 152 15 2 0 27 50 12 35 47 8 ## hbp sh sf gidp ## 1: 0 0 0 0 ## 2: 0 0 0 0 ## 3: 0 2 0 0 ## 4: 1 20 6 12 ## 5: 0 4 0 0 ## --- ## 195: 0 0 0 0 ## 196: 0 0 0 0 ## 197: 0 0 0 1 ## 198: 0 7 0 1 ## 199: 3 3 2 11 2.4.4.7 key를 활용한 데이터 병합 2.5 결측치 2.5.1 결측치 인식 2.5.1.1 is.na(x) 2.5.1.2 complete.cases(x) Q1. airquality 데이터의 Ozone 변수에 대한 na값 존재 여부를 파악하고, 만약 na가 존재한다면 그 개수를 확인해 보자. is.na(airquality$Ozone) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] TRUE TRUE TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE ## [37] TRUE FALSE TRUE FALSE FALSE TRUE TRUE FALSE TRUE TRUE FALSE FALSE ## [49] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [61] TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE ## [73] FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE ## [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [97] FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE TRUE FALSE ## [109] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE ## [121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [145] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE sum(is.na(airquality$Ozone)) ## [1] 37 table(is.na(airquality$Ozone)) ## ## FALSE TRUE ## 116 37 Q2. apply 함수는 행 혹은 열별로 함수를 적용하여 한 번에 결과를 산출해 주는 함수이다. apply 함수와 사용자 정의 함수를 활용하여 airquality 데이터의 모든 변수에 대해 각각 결측치(na값)가 몇개씩 존재하는지 확인해 보자. apply(airquality, 2, function(x) sum(is.na(x))) ## Ozone Solar.R Wind Temp Month Day ## 37 7 0 0 0 0 Q3. complete.case 함수를 이용하여 airquality 데이터에서 na값이 하나라도 존재하는 행들을 air_na 변수에 저장하고, na값을 하나도 가지지 않는 행들을 air_com 변수에 저장하여라. # na값이 하나라도 존재하는 행들을 air_na 변수에 저장 # complete.cases 함수를 적용했을 때 FALSE를 반환하는 행들만 저장하면 됨. air_na &lt;- airquality[!complete.cases(airquality),] head(air_na) ## Ozone Solar.R Wind Temp Month Day ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 10 NA 194 8.6 69 5 10 ## 11 7 NA 6.9 74 5 11 ## 25 NA 66 16.6 57 5 25 ## 26 NA 266 14.9 58 5 26 # na값이 하나도 없는 행들은 air_com 변수에 저장 # complete.cases 함수를 적용했을 때 TRUE를 반환하는 행들만 저장하면 됨. air_com &lt;- airquality[complete.cases(airquality),] head(air_com) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 2.5.2 결측치 처리 2.5.2.1 단순 대치법 (Single Imputation) 분류 설명 completes analysis 결측값이 존재하는 행을 삭제 평균 대치법 관측 또는 실험을 통해 얻어진 데이터의 평균으로 결측치를 대치 (비조건부/조건부 평균대치법) 단순확률 대치법 평균대치법에서 추정량 표준 오차이ㅡ 과소 추정문제를 보완하고자 고안된 방법으로 Hot-deck 방법, nearest neightbor 방법 등이 있다. 2.5.2.1.1 결측치 제거 # 결측치가 존재하는 행 제거 데이터명[!is.na(데이터명)] 데이터명[complete.cases(데이터명),] 데이터명 %&gt;% filter(!is.na(데이터명)) # na.omit 함수 활용 na.omit(데이터명) 2.5.2.1.2 평균 대치법 Q. airquality의 Ozone 변수값이 존재하지 않는 경우, Ozone 변수값들의 평균으로 대치해 보자. airquality$Ozone&lt;-ifelse(is.na(airquality$Ozone), mean(airquality$Ozone, na.rm=TRUE), airquality$Ozone) table(is.na(airquality$Ozone)) ## ## FALSE ## 153 2.5.2.2 다중 대치법 (Multiple Imputation) 2.5.2.3 패키지 활용 R에서 결측치를 대치하기 위해 사용될 수 있는 함수에는 DMwR 패키지의 함수들이 있다. Q. DMwR의 함수들을 이용하여 NA값을 해당 변수의 중위수로 대치하는 전처리를 수행해 보자. NA값이 대치되는 ㅗ가정을 확인하기 위해 airquality 데이터에서 NA값을 하나라도 가지고 있는 행번호들을 미리 봅아놓고, 전처리 전의 원본 데이터와 전처리 후의 데이터를 비교하여 전처리가 잘 진행되었는지 확인해 보자. install.packages(setdiff(&quot;DMwR2&quot;, rownames(installed.packages()))) library(DMwR2) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo #airquality에서 na값을 가진 행들의 번호 추출 na_idx&lt;-which(!complete.cases(airquality)) air_before&lt;-airquality #na값을 제거한 데이터를 air_after에 저장(centralImputation 함수 활용) air_after&lt;-centralImputation(airquality) # 두 데이터에서 na_idx에 저장된 행번호에 해당하는 데이터들을 추출하여 na값이 잘 대체되었는지 비교 head(air_before[na_idx,]) ## Ozone Solar.R Wind Temp Month Day ## 5 42.12931 NA 14.3 56 5 5 ## 6 28.00000 NA 14.9 66 5 6 ## 11 7.00000 NA 6.9 74 5 11 ## 27 42.12931 NA 8.0 57 5 27 ## 96 78.00000 NA 6.9 86 8 4 ## 97 35.00000 NA 7.4 85 8 5 head(air_after[na_idx,]) ## Ozone Solar.R Wind Temp Month Day ## 5 42.12931 205 14.3 56 5 5 ## 6 28.00000 205 14.9 66 5 6 ## 11 7.00000 205 6.9 74 5 11 ## 27 42.12931 205 8.0 57 5 27 ## 96 78.00000 205 6.9 86 8 4 ## 97 35.00000 205 7.4 85 8 5 median(airquality$Ozone, na.rm=TRUE) ## [1] 42.12931 median(airquality$Solar.R, na.rm=TRUE) ## [1] 205 2.6 이상치 인식 2.6.1 이상치란? 2.6.2 사분위수 2.6.3 boxplot을 활용한 이상치 판별 Q1. 내장데이터 airquality의 Ozone 변수에 대한 boxplot을 그려보자. 또한 이를 OzoneBP 이라는 변수에 저장하여 lower whisker와 upper whisker 밖에 있는 이상치가 존재하는지를 확인해 보자. (OzoneBP&lt;-boxplot(airquality$Ozone)) ## $stats ## [,1] ## [1,] 1.00000 ## [2,] 21.00000 ## [3,] 42.12931 ## [4,] 46.00000 ## [5,] 82.00000 ## ## $n ## [1] 153 ## ## $conf ## [,1] ## [1,] 38.93592 ## [2,] 45.32270 ## ## $out ## [1] 115 135 97 97 85 108 122 89 110 168 118 84 85 96 91 ## ## $group ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## ## $names ## [1] &quot;1&quot; 데이터는 전체적으로 작은 값들에 많이 분포한 것을 확인할 수 있으며, upper whisker 위로 15개의 이상치 값 ($out)이 있음을 알 수 있다. Q2. lower whisker(Q1-1.5IQR) 보다 작거나 upper whisker(Q3+1.5IQR) 보다 큰값들을 이상치로 간주하고, 해당 값들이 저장된 행번호를 각각 upperOutlier, lowerOutlier 변수에 저장하자. 그리고 해당 행을 출력하여 데이터를 확인해 보자. (LowerQ&lt;-fivenum(airquality$Ozone)[2]) ## [1] 21 (UpperQ&lt;-fivenum(airquality$Ozone)[4]) ## [1] 46 (IQR&lt;-IQR(airquality$Ozone, na.rm=TRUE)) ## [1] 25 # 조건을 만족하는 행번호 추출 (upperOutlier&lt;-which(airquality$Ozone &gt; UpperQ+IQR*1.5)) ## [1] 30 62 69 70 71 86 99 100 101 117 121 122 123 124 127 # 조건을 만족하는 행번호 추출 (lowerOutlier&lt;-which(airquality$Ozone &lt; UpperQ-IQR*1.5)) ## [1] 9 11 18 21 23 76 147 airquality[upperOutlier, &quot;Ozone&quot;] ## [1] 115 135 97 97 85 108 122 89 110 168 118 84 85 96 91 airquality[lowerOutlier, &quot;Ozone&quot;] ## [1] 8 7 6 1 4 7 7 2.7 날짜 데이터 전처리 2.7.1 날짜 데이터 다루기 2.7.1.1 R의 날짜 데이터 형식 분류 설명 Date 날짜만을 나타내는 클래스 이며, 내부적으로 1970년 1월1일 이후 경과된 날 수를 저장함. POSIXct 날짜와 시간을 나타내며, 일초 간격의 정확도로 시간을 표현함. 내부적으로 1970년 1월1일에서 경과된 초 수와 시간대를 저장함. POSIXlt 날짜와 시간을 나타내며 1900년에서부터 경과된 연도, 월, 일, 시, 분, 초를 포함하는 9개의 정보를 리스트에 저장 (today&lt;-Sys.Date()) ## [1] &quot;2021-09-20&quot; class(today) ## [1] &quot;Date&quot; (time&lt;-Sys.time()) ## [1] &quot;2021-09-20 00:19:25 KST&quot; class(time) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; # today 내부의 값 확인: 1970년 1월 1일 이후로 경과한 일 수를 의미함. unclass(today) ## [1] 18890 # time 내부의 값 확인: 1970년 1월 1일 00:00:00 이후로 경과한 초 수를 의미함. unclass(time) ## [1] 1632064766 # unclass를 적용한 time값을 다시 원래 날짜 형식으로 변환하기 # unclass(time)은 1970년 1월 1일 이후로 경과한 초수를 의미하므로, # origin 인자값으로 &#39;1970-01-01&#39;을 지정 as.POSIXct(unclass(time), origin=&quot;1970-01-01&quot;) ## [1] &quot;2021-09-20 00:19:25 KST&quot; 2.7.1.2 날짜 표시형식 변경 Q1. Sys.time 함수를 이용해 현재 날짜와 시간을 now 변수에 저장한 후, 이를 “네자리 년도수-두자리 월-일 시:분:초”의 형태를 가진 문자형 데이터로 변환해 보자. now&lt;-Sys.time() class(now) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; format(now, &quot;%Y-%m-%d %H:%M:%S&quot;) ## [1] &quot;2021-09-20 00:19:26&quot; class(format(now, &quot;%y-%m-%d %H:%M:%S&quot;)) ## [1] &quot;character&quot; Q2. “20200101”이라는 문자열을 Date 형식으로 변환한 후, date 변수에 저장하여 class를 확인해 보자. (date&lt;-as.Date(&quot;20200101&quot;, format=&quot;%Y%m%d&quot;)) ## [1] &quot;2020-01-01&quot; class(date) ## [1] &quot;Date&quot; 2.7.1.3 날짜 데이터의 연산 Sys.Date() + 100 ## [1] &quot;2021-12-29&quot; as.Date(&quot;2021-01-01&quot;, format=&quot;%Y-%m-%d&quot;) + 365 ## [1] &quot;2022-01-01&quot; "],["통계분석.html", "3 통계분석 3.1 통계 자료의 획득방법 3.2 T-검정 (T-Test) 3.3 교차분석 3.4 분산분석 (ANOVA) 3.5 상관분석 3.6 회귀분석", " 3 통계분석 통계란 특정집단을 대상으로 수행한 조사나 실험을 통해 나온 결과에 대한 요약된 형태의 표현이다. 조사 또는 실험을 통해 데이터를 확보하며, 조사대상에 따라 총조사와 표본 조사로 구분한다. 3.1 통계 자료의 획득방법 3.1.1 총조사/전수 조사(census) 3.1.2 표본조사 3.1.2.1 표본추출 방법 (데이터 샘플링) 3.1.2.1.1 단순 임의 추출법 (simple random sampling) 전체 데이터에서 데이터를 선택할 확률을 모두 동일하게 하여 표본을 추출하는 방법이다. 복원추출은 한번 선택한 표본을 다시 추출할 수 있는 방법이며, 비복원추출은 한번 선택된 표본은 다시 추출할 수 없는 방법이다. 일반적으로 데이터를 training data와 test data로 분할할 때 가장 많이 사용하는 표본추출 방법이다. Q. iris 데이터로 분석을 진행하기 위해 전체 데이터를 7:3의 비율로 training data와 test data를 추출한 뒤 새로운 변수에 저장해 보자. (데이터 추출 방법은 단순 임의 추출을 이용한다.) # iris 데이터 행의 개수에서 70%에 해당하는 행번호를 랜덤으로 추출 # nrow(): 데이터의 행 개수를 산출해 주는 함수 idx &lt;- sample(1:nrow(iris), nrow(iris)*0.7, replace=FALSE) training&lt;-iris[idx,] head(training) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species SL_new ## 103 7.1 3.0 5.9 2.1 virginica 0.7777778 ## 111 6.5 3.2 5.1 2.0 virginica 0.6111111 ## 115 5.8 2.8 5.1 2.4 virginica 0.4166667 ## 117 6.5 3.0 5.5 1.8 virginica 0.6111111 ## 127 6.2 2.8 4.8 1.8 virginica 0.5277778 ## 122 5.6 2.8 4.9 2.0 virginica 0.3611111 test&lt;-iris[-idx,] head(test) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species SL_new ## 1 5.1 3.5 1.4 0.2 setosa 0.22222222 ## 4 4.6 3.1 1.5 0.2 setosa 0.08333333 ## 7 4.6 3.4 1.4 0.3 setosa 0.08333333 ## 9 4.4 2.9 1.4 0.2 setosa 0.02777778 ## 12 4.8 3.4 1.6 0.2 setosa 0.13888889 ## 13 4.8 3.0 1.4 0.1 setosa 0.13888889 3.1.2.1.2 계통추출법 (systematic sampling) 3.1.2.1.3 집락추출법 (cluster random sampling) 3.1.2.1.4 층화추출법 (stratified random sampling) 특정 데이터가 여성 계층 70%, 남성 계층 30%로 구성되어 있다고 가정해 보자. 각 계층을 고루 대표할 수 있도록 표본을 추출하기 위해서는 여성과 남성 집단에 대해 0.7:0.3의 비율로 데이터를 뽑아야 한다. 이처럼 여성과 남성이라는 계층별로 표본을 추출하는 것을 층화 임의 추출이라고 한다. Q. iris 데이터에서 species가 setosa인 데이터를 20개, versicolor인 데이터를 15개, versinica인 데이터를 15개씩 층화 임의 추출을 사용해 추출해 보자. strata(data, stratanames=NULL, size, method=c(&quot;srswor&quot;,&quot;srswr&quot;,&quot;poisson&quot;,&quot;systematic&quot;), pik, descrption=FALSE) 인자 설명 data 표본을 추출할 데이터프레임 또는 행렬 stratanames 데이터에서 계층(집단)을 구분하는 변수들 (여러개일 경우 c()안에 나열) size 각 계층에서 추출할 데이터의 개수 method 데이터를 뽑는 방법 지정srswor: 비복원 단순 임의 추출srswr: 복원 단순 임의 추출poisson: 포아송 추출systematic: 계통 추출 install.packages(setdiff(&quot;sampling&quot;, rownames(installed.packages()))) library(sampling) sample&lt;-strata(data=iris, c(&quot;Species&quot;), size=c(20,15,15), method=&quot;srswor&quot;) head(sample) ## Species ID_unit Prob Stratum ## 1 setosa 1 0.4 1 ## 2 setosa 2 0.4 1 ## 3 setosa 3 0.4 1 ## 5 setosa 5 0.4 1 ## 13 setosa 13 0.4 1 ## 14 setosa 14 0.4 1 iris_sample&lt;-getdata(iris, sample) head(iris_sample) ## Sepal.Length Sepal.Width Petal.Length Petal.Width SL_new Species ID_unit ## 1 5.1 3.5 1.4 0.2 0.2222222 setosa 1 ## 2 4.9 3.0 1.4 0.2 0.1666667 setosa 2 ## 3 4.7 3.2 1.3 0.2 0.1111111 setosa 3 ## 5 5.0 3.6 1.4 0.2 0.1944444 setosa 5 ## 13 4.8 3.0 1.4 0.1 0.1388889 setosa 13 ## 14 4.3 3.0 1.1 0.1 0.0000000 setosa 14 ## Prob Stratum ## 1 0.4 1 ## 2 0.4 1 ## 3 0.4 1 ## 5 0.4 1 ## 13 0.4 1 ## 14 0.4 1 table(iris_sample$Species) ## ## setosa versicolor virginica ## 20 15 15 3.1.2.1.5 다단계 추출 (multi-stage sampling) 3.2 T-검정 (T-Test) T-검정은 두 집단의 평균을 통계적으로 비교하기 위해 사용하는 검정방법이다. 어떤 방식으로 집단의 평균을 비교하느냐에 따라 일표본 T-검정, 대응표본 T-검정, 독립표본 T-검정으로 나누어진다. 3.2.1 일표본 T-검정 (One Sample T-Test) 3.2.1.1 일표본 T-검정이란? 단일모집단에서 관심이 있는 연속형 변수의 평균값을 특정 기준값과 비교하고자 할 때 사용하는 검정방법이다. 예를 들어 A과수원에서 생산되는 사과의 평균 무게가 200g이라고 알려져 있을 때, 실제로 A과수원에서 생산되는 전체 사과의 평균 무게가 200g인지 알아보고 싶은 경우에 일표본 t-검정을 수행할 수 있다. 단일모집단에서 알고자 하는 값이 종속변수가 되며, 설정한 기준값과 종속변수의 평균값 사이의 차이가 통계적으로 유의하다면 귀무가설이 기각되고 대립가설이 채택됨으로써 두값이 다르다고 결론을 내릴 수 있다. 3.2.1.2 일표본 T-검정의 가정 모집단의 구성요소들이 정규분포를 이룬다는 가정 종속변수는 연속형 변수여야 하며, 검증하고자 하는 기준값이 있어야 한다. 3.2.1.3 일표본 T-검정의 단계 가설 설정 유의수준 설정 검정통계량의 값 및 유의확률 계산 귀무가설의 기각여부 판단 및 의사결정 일표본 T-검정을 수행하기 전 표본에 대한 정규성을 검정해야 할 경우 샤피로-윈크 검정, 콜모고로프 스미르노프 검정, Q-Q도를 통한 확인 등 다양한 방법을 활용할 수 있다. 그 중에서 샤피로-윌크 검정이 많이 사용된다. 샤피로-윌크 검정의 귀무가설은 “데이터가 정규분포를 따른다.”이고, 대립가설은 “데이터가 정규분포를 따르지 않는다.”이다. 따라서 검정 결과로 나오는 p-value값에 따라 데이터의 정규성을 확인할 수 있다. 샤피로-윌크 검정은 아래와 같이 shapiro.test함수를 통해 수행하며, data 자리에는 정규성 검정을 수행할 데이터 프레임을 지정한다. shapiro.test(data) 데이터가 정규분포를 따른다는 가정을 만족한 경우, t.test라는 함수를 이용하여 일표본-T검정을 수행한다. 반면 데이터가 정규성을 만족하지 않는 경우, wilcox.test 함수를 이용해 T-검정을 수행한다. t.test(x, alternative=c(&quot;two.sided&quot;,&quot;less&quot;,&quot;greater&quot;), mu=0) wilcox.test(x, alternative=c(&quot;two.sided&quot;,&quot;less&quot;,&quot;greater&quot;), mu=0) 인자 설명 x 표본으로부터 관측한 값(수치형 벡터) alternative 양측검정: “two.sided”입력단측검정: 표본평균이 특정값보다 작은지에 대해 검정을 수행할 시 “less”를 입력, 특정값보다 큰지에 대한 검정수행시 “greater”를 입력 mu 검정시 기준이 되는 값 Q. MASS 패키지의 cats데이터는 고양이들의 성별, 몸무게, 심장의 무게를 담고 있다. cats데이터에서 고양이들의 평균몸무게가 2.6kg인지 아닌지에 대한 통계적 검정을 수행하고, 결과를 해석해보자. (양측검정 수행, 유의수준=0.05) 검정을 수행하기에 앞서 설정할 수 있는 가설은 아래와 같다. 귀무가설(H0): 고양이들의 평균 몸무게는 2.6kg이다.대립가설(H1): 고양이들의 평균 몸무게는 2.6kg가 아니다. cats 데이터 확인 및 Bwt변수에 대한 정규성 검정 수행 library(MASS) head(cats) ## Sex Bwt Hwt ## 1 F 2.0 7.0 ## 2 F 2.0 7.4 ## 3 F 2.0 9.5 ## 4 F 2.1 7.2 ## 5 F 2.1 7.3 ## 6 F 2.1 7.6 str(cats) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Bwt: num 2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ... ## $ Hwt: num 7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ... shapiro.test(cats$Bwt) ## ## Shapiro-Wilk normality test ## ## data: cats$Bwt ## W = 0.95188, p-value = 6.731e-05 정규성 검정의 결과 p-value가 6.731e-05로 유의수준 0.05보다 작기 때문에 ‘데이터가 정규분포를 따른다’(=정규성을 만족한다.) 라는 귀무가설을 기각한다. 즉, cats 데이터의 Bwt 변수는 정규분포를 따르지 않으므로 wilcox.test 함수를 이용해 T-검정을 수행한다. cats 데이터에 대한 일표본 T-검정 수행 wilcox.test(cats$Bwt, mu=2.6, alternative=&quot;two.sided&quot;) ## ## Wilcoxon signed rank test with continuity correction ## ## data: cats$Bwt ## V = 5607, p-value = 0.02532 ## alternative hypothesis: true location is not equal to 2.6 표본평균이 특정값과 같은지에 대해 알아보는 양측검정을 수행하는 것이기 때문에 wilcox.test 함수의 alternative(검정방향)에는 “two.sided”값을 지정하면 된다. wilcox 검정 결과 p-value는 0.02532로 유의수준 0.05 보다 작다. 따라서 귀무가설 ’고양이들의 평균 몸무게(Bwt 변수값의 평균)는 2.6(kg)이다.’을 기각하며, 고양이들의 평균 몸무게는 2.6kg이 아니라는 결론을 내릴 수 있다. 3.2.2 대응표본 T-검정 (Paired Sample T-Test) 3.2.2.1 대응표본 T-검정이란? 단일모집단에 대해 두 번의 처리를 가했을 때, 두 개의 처리에 따른 평균의 차이를 비교하고자 할 때 사용하는 검정방법이다. 예를 들어 어느 기업에서 판매사원들의 역량 향상을 위해 두 가지 방법으로 직업교육을 실시하고 나서, 두 가지 교육방법에 따른 판매실적 평균에 차이가 있는지를 검정하고자 할 때 대응표본 t-검정을 사용할 수 있다. 이때 ’직업교육 방법’이 독립변수, 그에 따른 ’판매실적’이 종속변수가 된다. 하나의 모집단에서 크기가 n개인 하나의 표본을 추출한 후, 표본 내의 개체들에 대해서 두 번의 측정을 실시한다. 따라서 관측값들은 서로 독립적이지 않고 쌍(pair)으로 이루어져 있어 대응표본 t-검정을 짝지어진 t-검정 (matched pair t-test)이라고도 한다. 모집단과 표본은 하나씩이지만, 각 개체들에 대해 두 개씩이ㅡ 관측값이 존재하므로 모수는 두 개다. 표본 내에 있는 각 개체별로 짝지어진 관측값 사이에 차이가 있는지를 검정하므로 자료의 형태는 아래의 표와 같다. 개체 관측값1(A) 관측값2(B) 차이(A-B=D) 1 A1 B1 A1-B1=D1 2 A2 B2 A2-B2=D2 … … … … n An Bn An-Bn=Dn 3.2.2.2 대응표본 T검정의 가정 대응표본 t-검정에서는 모집단의 관측값이 정규성(정규분포를 만족한다는 가정)을 만족해야 한다. 종속변수는 연속형 변수이어야 한다. 3.2.2.3 대응표본 T검정의 단계 가설 검정 귀무가설(H0): 2개의 모평균 간에는 차이가 없다. (\\(\\mu_{x}-\\mu_{y}-D=0\\)) 대립가설(H1): 2개의 모평균 간에는 차이가 있다. (\\(\\mu_{x}-\\mu_{y}-D\\ne0\\)) - 양측검정 2개의 모평균 간의 차이는 0보다 크다. (\\(\\mu_{x}-\\mu_{y}-D&gt;0\\)) - 우단측검정 2개의 모평균 간의 차이는 0보다 작다. (\\(\\mu_{x}-\\mu_{y}-D&lt;0\\)) - 좌단측검정 유의수준 설정 검정통계량의 값 및 유의확률 계산 귀무가설의 기각여부 판단 및 의사결정 t.test(x, y, alternative=c(&quot;two.sided&quot;,&quot;less&quot;,&quot;greater&quot;), paired=FALSE, m=0) Q. 10명의 환자를 대상으로 수면영양제를 복용하기 전과 후의 수면시간을 측정하여 영양제의 효과가 있는지를 판단하고자 한다. 영양제 복용 전과 후의 평균 수면시간에 차이가 있는지를 알아보는데, 단측검정을 수행하여 영양제 복용 후에 수면시간이 더 늘어났는지를 검정해보자. 수면영양제를 복용하기 전과 후의 수면시간은 아래에 제시된 바와 같다. (표본이 정규성을 만족한다는 가정하에 단측검정 수행, 유의수준=0.05) 검정을 수행하기에 앞서 설정할 수 있는 가설은 아래와 같다.귀무가설(H0): 수면영양제를 복용하기 전과 후의 평균 수면시간에는 차이가 없다. (\\(\\mu_{x}-\\mu_{y}-D=0\\))대립가설(H1): 수면영양제를 복용하기 전과 후의 평균 수면시간 차이는 0보다 작다. 즉, 수면영양제를 복용한 후 평균수면시간이 늘어났다. (\\(\\mu_{x}-\\mu_{y}-D&lt;0\\)) 수면 영양제 복용 전 10명의 환자들의 수면시간: 7, 3, 4, 5, 2, 1, 6, 6, 5, 4수면 영양제 복용 후 10명의 환자들의 수면시간: 8, 4, 5, 6, 2, 3, 6, 8, 6, 5 데이터 입력 (data&lt;-data.frame(before=c(7,3,4,5,2,1,6,6,5,4), after=c(8,4,5,6,2,3,6,8,6,5))) ## before after ## 1 7 8 ## 2 3 4 ## 3 4 5 ## 4 5 6 ## 5 2 2 ## 6 1 3 ## 7 6 6 ## 8 6 8 ## 9 5 6 ## 10 4 5 대응표본 T-검정수행 t.test(data$before, data$after, alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: data$before and data$after ## t = -4.7434, df = 9, p-value = 0.0005269 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.6135459 ## sample estimates: ## mean of the differences ## -1 수면 영양제를 복용하기 전과 후의 평균 수면시간 차이가 비교하고자 하는 값(0)보다 작은지에 대하여 검정을 수행하기 때문에 alternative 인자에는 “less”를 입력한다. 대응표본 t-검정 수행 결과, 검정통계량(t값)은 -4.7434, df(자유도)는 9, 유의확률(p-value)은 0.0005269이다. p-value가 유의수준 0.05보다 작기 때문에 귀무가설을 기각하고, ’수면영양제를 복용하기 전과 후의 평균 수면시간의 차이는 통계적으로 유의하며, 영양제를 복용한 후 수면시간이 늘었다.’라는 결론을 내릴 수 있다. 3.2.3 독립표본 T-검정 (Independent Sample T-Test) 3.2.3.1 독립표본 T-검정이란? 두개의 독립된 모집단의 평균을 비교하고자 할 때 사용하는 검정방법이다. 예를 들어 성별에 따라 출근준비시간에 차이가 있는지를 통계적으로 검정하기 위해서 독립표본 t-검정을 사용할 수 있다. 이 때 그룹(집단)을 나누는 기준인 ’성별’이 독립변수이고, 그에 따른 관리값인 ’출근준비시간’이 종속변수이다. 두개의 모집단에서 크기가 n개인 표본을 각각 추출한 후 표본의 관측값들을 이용해 검정을 실시한다. 따라서 독립표본 t-검정에서는 모집단, 모수, 표본이 모두 두 개씩 존재한다. 3.2.3.2 독립표본 T-검정의 가정 두 모집단은 정규성을 만족해야 한다. 독립표본 t-검정에서 두 개의 모집단은 서로 독립적이어야 한다. 두 모집단의 분산이 서로 같음을 의미하는 등분산성 가정을 확인해야 한다. 등분산 가정은 비교하고자 하는 두 독립 집단의 모분산이 동일함을 의미하며, 등분산성 만족여부에 따라 다른 계산 방법이 사용된다. 따라서 이 가정을 확인하기 위해 독립표본 t-검정 수행 과정에서는 등분산 검정을 먼저 수행한 후 검정통계량을 계산한다. 독립변수는 범주형, 종속변수는 연속형이어야 한다. 3.2.3.3 독립표본 T-검정의 단계 가설검정 모수: 서로 독립된 두 모집단의 평균 (\\(mu_{1},mu_{2}\\)) 귀무가설(\\(H_{0}\\)) : 두 개의 모평균에는 차이가 없다. (\\(mu_{1}=mu_{2}\\)) 대립가설(\\(H_{1}\\)) : 두 개의 모평균에는 차이가 있다. (\\(mu_{1}\\ne mu_{2}\\)) - 양측검정 집단1의 모평균이 집단2의 모평균보다 크다. (\\(mu_{1}&gt;mu_{2}\\)) - 우단측검정 집단1의 모평균이 집단2의 모평균보다 작다. (\\(mu_{1}&lt;mu_{2}\\)) - 좌단측검정 유의수준 설정 등분산 검정 두 모집단이 등분산성을 만족하는지의 여부에 따라 유의확률과 검정통계량의 값이 다르게 계산된다. 따라서 독립표본 t-검정을 위해서는 반드시 등분산 검정이 선행되어야 한다. 귀무가설(\\(H_{0}\\)) : 두 집단의 분산이 동일하다. (\\(\\sigma_{1}^{2}=\\sigma_{2}^{2}\\)) 대립가설(\\(H_{1}\\)) : 두 집단의 분산이 동일하지 않다. (\\(\\sigma_{1}^{2}\\ne\\sigma_{2}^{2}\\)) 검정통계량의 값 및 유의확률 계산 귀무가설의 기각여부 판단 및 의사결정 유의확률(p-value) &lt; 유의수준(\\(\\alpha\\)) : 귀무가설을 기각하고, 대립가설을 채택한다. 유의확률(p-value) &gt; 유의수준(\\(\\alpha\\)) : 귀무가설을 기각하지 않는다. R에서 독립표본 t-검정을 수행하기에 앞서, 등분산 검정을 수행해야 하며 이를 위한 R의 다양한 함수들 중에서 var.test 함수의 문법을 알아보자. vat.test(x, y, alternative) var.test(formula, data, alternative) 등분산 검정의 과정을 거친 후 아래와 같이 t.test 함수를 이용해 독립표본 t-검정을 수행할 수 있다. t.test(x, y, alternative, var.equal=FALSE) t.test(formula, data, alternative, var.equal=FALSE) 인자 설명 x 모집단1로부터 측정한 관측값 (수치형 벡터) y 모집단2로부터 측정한 관측값 (수치형 벡터) formula data t-검정을 수행할 데이터명 alternative 양측검정시 “two.sided”, 단측검정시 “less”, “greater” 입력 equal 등분산성을 만족하는지의 여부 (TRUE 혹은 FALSE로 입력) Q. cats 데이터는 고양이들의 성별, 몸무게, 심장의 무게를 담고 있다. 고양이들의 성별에 따른 몸무게의 평균은 통계적으로 다르다고 할 수 있는지에 대한 검정을 수행하고, 결과를 해석해 보자. 검정을 수행하기에 앞서 설정할 수 있는 가설은 아래와 같다귀무가설: 고양이의 성별에 따른 평균 몸무게에는 통계적으로 유의한 차이가 없다.대립가설: 고양이의 성별에 따른 평균 몸무게에는 통계적으로 유의한 차이가 있다. 1) 독립 t검정을 수행하기에 앞서, 범주별 데이터값의 등분산성 검정 수행 library(MASS) data(&quot;cats&quot;) var.test(Bwt~Sex, data=cats) ## ## F test to compare two variances ## ## data: Bwt by Sex ## F = 0.3435, num df = 46, denom df = 96, p-value = 0.0001157 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.2126277 0.5803475 ## sample estimates: ## ratio of variances ## 0.3435015 등분산 검정의 결과 유의확률(p-value)이 0.0001157로 유의수준 0.05보다 매우 작기 때문에 귀무가설을 기각한다. 따라서 A, B 두 집단의 데이터는 등분산 가정을 만족한다고 할 수 없다. 2) 성별에 따른 몸무게가 등분산성을 만족하지 않는다는 조건 하에 독립 t검정을 수행 t.test(Bwt~Sex, data=cats, alternative=&quot;two.sided&quot;, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: Bwt by Sex ## t = -8.7095, df = 136.84, p-value = 8.831e-15 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.6631268 -0.4177242 ## sample estimates: ## mean in group F mean in group M ## 2.359574 2.900000 독립표본 t-검정 수행결과, 검정통계량(t값)은 -8.7095, df(자유도)는 136.84, 유의확률(p-value)은 8.831e-15이다. p-value가 0에 가까운 매우 작은 숫자로 유의수준 0.05 보다 작기 때문에 귀무가설을 기각한다. 따라서 ‘고양이들의 성별에 따른 평균 몸무게에는 통계적으로 유의한 차이가 존재한다.’ 라는 결론을 내릴 수 있다. 3.3 교차분석 교차분석이란 명목척도 혹은 순서척도와 같은 범주형 자료들 간의 상호 연관성을 알아볼 때 사용하는 방법이다. 두 범주형 변수에 대한 관련성을 파악하고 이를 통계적으로 검정하여 복잡한 상황에 대한 통찰력을 얻을 수 있다. 3.3.1 교차분석 개념 3.3.1.1 교차분석의 개념 및 특징 범주형 자료(명목/서열 수준)인 두 변수 간이ㅡ 관계를 알아보기 위해 실시하는 분석 기법이다. 적합성 검정, 독립성 검정, 동질성 검정에 사용되며, 카이제곱 검정 통계량을 이용한다. 3.3.1.2 교차표 3.3.2 적합성 검정 3.3.2.1 적합성 검정이란? 실험에서 얻어진 관측값들이 예상한 이론과 일치하는지 아닌지를 검정하는 방법이다. 관측값들이 어떠한 이론적 분포를 따르고 있는지를 알아볼 수 있다. 즉, 모집단 분포에 대한 가정이 옳게 됐는지를 관측 자료와 비교하여 검정하는 것이다. 3.3.2.2 가설설정 n개의 표본 자료를 k개의 범주로 분류한 뒤, 각 범주의 관측도수(O)와 주어진 확률 분포에 대해 각 범주에 속하는 기대도수(E)들이 적합하는지의 여부를 검정하는 것이다. 귀무가설: 실제 분포와 이론적 분포 간에는 차이가 없다. (두 분포가 일치한다) 대립가설: 실제 분포와 이론적 분포 간에는 차이가 있다. (두 분포가 일치하지 않는다) 3.3.2.3 검정 통계량 3.3.2.4 자유도 3.3.2.5 R을 이용한 적합성 검정 R에서 적합성 검정은 chisq.test 함수로 수행하며, 사용 문법은 아래와 같다. chisq.test(x, y, p) Q. MASS 패키지의 survey 데이터에서 W.Hnd 변수는 설문 응답자가 왼손잡이 인지 오른손잡이 인지를 나타낸다. R을 이용하여 W.Hnd 변수에 대한 분할표를 생성하고, 아래와 같은 가설에 대한 적합도 검정을 수행해 보자. 귀무가설: 전체 응답자 중 왼손잡이의 비율이 20%, 오른손잡이의 비율이 80%이다. 대립가설: 전체 응답자 중 왼손잡이의 비율이 20%, 오른손잡이의 비율이 80%라고 할 수 없다. data(survey, package=&quot;MASS&quot;) table(survey$W.Hnd) ## ## Left Right ## 18 218 data&lt;-table(survey$W.Hnd) chisq.test(data, p=c(0.2,0.8)) ## ## Chi-squared test for given probabilities ## ## data: data ## X-squared = 22.581, df = 1, p-value = 2.015e-06 유의확률(p-value)이 2.015e-06로 0.05 보다 작으므로 ‘전체 응답자 중 왼손잡이는 20%, 오른손잡이는 80%이다’ 라는 귀무가설을 기각한다. 3.3.3 독립성 검정 3.3.3.1 독립성 검정이란? 모집단이 2개의 변수 A, B에 의해 범주화되었을 때, 이 두 변수들 사이의 관계가 독립인지 아닌지를 검정하는 것을 의미한다. 검정 통계량 값을 계산할 때는 교차표를 활용한다. 3.3.3.2 가설 검정 모집단을 범주화하는 기준이 되는 두 변수 A, B가 서로 독립적으로 관측값에 영향을 미치는지의 여부를 검정하는 것이다. 귀무가설(\\(H_{0}\\)): 두 변수 사이에는 연관이 없다. (독립이다) 대립가설(\\(H_{1}\\)): 두 변수 사이에는 연관이 있다. (종속이다) 3.3.3.3 검정 통계량 3.3.3.4 자유도 3.3.3.5 R을 이용한 독립성 검정 [함수 사용법] xtabs(formula, data) table(범주형변수) # 도수분포표 생성 table(범주형변수1, 범주형변수2) # 두 변수간 이원분할표 생성 Q. MASS 패키지의 survey 데이터에서 Exer 변수는 설문 응답자가 얼마나 자주 운동을 하는지에 대해 Freq, Some, None의 범주로 값을 저장하고 있다. W.Hnd 변수는 설문 응답자가 왼손잡이인지 오른손 잡이인지에 대해 Left, Right의 두가지 범주로 값을 가지고 있다. 주로 사용하는 손과 운동의 빈도가 서로 독립인지를 확인하기 위해 분할표를 생성하고, 아래의 가설에 대한 독립성 검정을 수행해 보자. 3.3.4 동질성 검정 3.4 분산분석 (ANOVA) 3.4.1 분산분석의 개념 분산분석은 두 개 이상의 집단에서 그룹 평균간 차이를 그룹내 변동에 비교하여 살펴보는 통계분석 방법이다. 즉, 두 개 이상 집단들의 평균 간 차이에 대한 통계적 유의성을 검정 (두 개 이상 집단들의 평균을 비교) 분산분석의 분류는 아래와 같다. 분석구분 분석명칭 독립변수 개수 종속변수 개수 단일변량 분산분석 일원배치 분산분석 1개 1개 단일변량 분산분석 이원배치 분산분석 2개 1개 단일변량 분산분석 다원배치 분산분석 3개 이상 1개 다변량 분산분석 MANOVA 1개 이상 2개 이상 3.4.2 일원배치 분산분석 (One-way ANOVA) 3.4.2.1 일원배치 분산분석의 개념 분산분석에서 반응값에 대한 하나의 범주형 변수의 영향을 알아보기 위해 사용되는 검증방법이다. 모집단의 수에는 제한이 없으며, 각 표본의 수는 갖지 않아도 된다. F 검정 통계량을 이용한다. 3.4.2.2 일원배치 분산분석의 가정 각 집단의 측정치는 서로 독립적이며, 정규분포를 따른다. 각 집단 측정치의 분산은 같다. (등분산 가정) 3.4.2.3 분산분석표 요인 제곱합(SS) 자유도(df) 평균제곱(MS) 분산비(F) 처리 SSA k-1 (k: 집단의 수) MSA F=MSA/MSE 오차 SSE N-k (N: 관측수) MSE 전체 SST N-1 3.4.2.4 가설 검정 귀무가설: k개의 집단간 모평균에는 차이가 없다. 대립가설: k개의 집단간 모평균이 모두 같다고 할 수 없다. 3.4.2.5 사후 검정 사후검정이란 분산분석의 결과 귀무가설이 기각되어 적어도 한 집단에서 평균의 차이가 있음이 통계적으로 증명되었을 경우, 어떤 집단들에 대해서 평균의 차이가 존재하는지를 알아보기 위해 실시하는 분석이다. 사후분석의 종류로는 던칸의 MRT방법, 피셔의 최소유의차 방법, 튜키의 HSD방법, Scheffe의 방법 등이 있다. 3.4.2.6 R을 활용한 일원배치 분산분석 R에서 분산분석을 수행하기 위해 사용하는 함수는 aov이며, 주의할 점은 그룹을 구분하는 기준이 되는 변수는 반드시 팩터형이어야 한다는 것이다. aov(formula, data) 등분산 검정의 결과로 귀무가설이 기각되었을 경우, 어떠한 집단들 사이에서 통계적으로 유의한 차이가 있는지를 알아보기 위해 수행하는 사후분석에는 다양한 방법이 있다. 그 중 Tukey의 HSD 검정법을 수행할 수 있는 R의 TukeyHSD 함수는 아래와 같다. TukeyHSD(x, conf.level=0.95, ...) Q. iris 데이터를 이용하여 종별로 꽃받침의 폭의 평균이 같은지 혹은 차이가 있는지를 확인하기 위해 일원배치 분산분석을 수행해 보자. 검정을 수행하기에 앞서 설정할 수 있는 가설은 아래와 같다. 귀무가설: 세가지 종에 대해 Sepal.Width의 평균은 모두 같다. 대립가설: 적어도 하나의 종에 대한 Sepal.Width의 평균값에는 차이가 있다. 1) 분산분석 result&lt;-aov(Sepal.Width~Species, data=iris) #분산분석표 확인 summary(result) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Species 2 11.35 5.672 49.16 &lt;2e-16 *** ## Residuals 147 16.96 0.115 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 분산분석표를 통해 확인한 결과, SSA의 자유도는 2(집단의 수-1=3-1), SSE의 자유도는 147 (관측값의 수 - 집단의 수 = 150 -3) 임을 확인할 수 있다. 분석결과, p-value값(&lt;2e-16)이 매우 작게 나와 유의수준 0.05 하에서 귀무가설을 기각한다. 따라서 세가지 종에 따른 꽃받침 폭의 평균이 모두 동일하지는 않다고 결론 내릴 수 있다. 즉, 적어도 어느 하나의 종의 꽃받침 폭 평균값은 나머지 종들과는 통계적으로 유의한 차이가 있다고 말할 수 있다. 그렇다면, 세가지 종들 중 특히 어떤 종들간에 꽃받침의 폭에 차이가 있는지를 파악하기 위해 사후검정을 수행해 보자. 2) 사후검정 TukeyHSD(aov(Sepal.Width~Species, data=iris)) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = Sepal.Width ~ Species, data = iris) ## ## $Species ## diff lwr upr p adj ## versicolor-setosa -0.658 -0.81885528 -0.4971447 0.0000000 ## virginica-setosa -0.454 -0.61485528 -0.2931447 0.0000000 ## virginica-versicolor 0.204 0.04314472 0.3648553 0.0087802 사후분석에서는 귀무가설을 ’집단들 사이의 평균은 같다’로 두고, 대립가설을 ’집단들 사이의 평균은 같지 않다’로 둔다. 그리고 모든 집단 수준에 대해서 두 집단씩 짝을 지어 각각 다중비교를 수행한다. 예제의 사후분석 결과를 보면 versicolor-setosa, virginica-setosa, virginica-versicolor의 세가지 비교에 대해서 모두 수정된 p-value값 (p adj)이 0.05 보다 작으므로, 각각의 비교에 대한 귀무가설을 모두 기각한다. 즉 모든 종들에 대해서 꽃받침 폭의 평균값은 통계적으로 유의한 차이가 있다는 것을 알 수 있다. 또한 diff는 하이픈(-)의 왼쪽 집단과 오른쪽 짐단 간 반응값의 차이를 타나내는데, versicolor-setosa에 대한 diff값은 음수이므로, versicolor일 때보다 setosa일 때 곷받침의 폭이 통계적으로 유의하게 큰 값을 가진다고 해석할 수 있다. 3.4.3 이원배치 분산분석 (Two-way ANOVA) 3.4.3.1 이원배치 분산분석의 개념 분산분석에서 반응값에 대해 두 개의 범주형 변수 A, B의 영향을 알아보기 위해 사용되는 검정방법이다. 예를 들어 성별과 학년에 따른 시험점수의 차이에 대해 통계적으로 검정하기 위해 이원배치 분산분석을 사용할 수 있다. 두 독립변수 A, B 사이에 상관관계가 있는지를 살펴보는 교호작용(두 독립변수의 범주들의 조함으로 인해 반응변수에 미치는 특별한 영향)에 대한 검증이 반드시 진행되어야 한다. 3.4.3.2 이원배치 분산분석의 가정 각 집단 측정치의 분포는 정규분포이어야 한다. (정규성) 집단간 측정치의 분산은 같다. (등분산성) 3.4.3.3 주효과와 교호작용효과 이원배치 분산분석에서는 두 개의 독립변수값에 따르는 데이터의 주효과와 상호작용효과에 대한 검정을 수행한다. 주효과란 각각의 독립변수가 종속변수에 미치는 효과를 의미하며, 이를 검정하는 것을 주효과 검정이라 한다. 교효작용효과는 여러 독립변수들의 조합이 종속변수에 주는 영향을 의미한다. 즉 교호작용효과검정은 한 독립변수가 종속변수에 미치는 영향이 다른 독립변수의 수준에 따라서 달라지는지를 분석하는 것이다. 두 독립변수 A, B 사이에 상관관계가 존재할 경우, 교호작용이 있다는 의미이다. 교호작용이 없을 경우, 주효과 검정을 진행한다. 반면 교호작용이 있을 경우에는 검정이 무의미하다. 3.4.3.4 분산분석표 요인 자유도 제곱합 평균제곱합 F 요인A \\(I-1\\) (요인A의 수준수) SSA \\(MS_{A}=\\frac{SSA}{I-1}\\) \\(F_{A}=\\frac{MSA}{MSE}\\) 요인B \\(J-1\\) (요인B의 수준수) SSB \\(MS_{B}=\\frac{SSB}{J-1}\\) \\(F_{B}=\\frac{MSB}{MSE}\\) 상호작용 \\((I-1)(J-1)\\) SS~A*B~ \\(MS_{AB}=\\frac{SSAB}{(I-1)(J-1)}\\) \\(F_{AB}=\\frac{MSAB}{MSE}\\) 오차 \\(IJ(n-1)\\) SSE \\(MSE=\\frac{SSE}{IJ(n-1)}\\) 전체 SST \\(IJn-1\\) 3.4.3.5 가설 검정 귀무가설 \\(H_{0}\\): \\(\\alpha\\)변수에 따른 종속변수의 값(반응값)에는 차이가 없다. (\\(\\alpha_{1}=\\alpha_{2}=...=\\alpha_{a}=0\\)) \\(H_{0}\\): \\(\\beta\\)변수에 따른 종속변수의 값(반응값)에는 차이가 없다. (\\(\\beta_{1}=\\beta_{2}=...=\\beta_{b}=0\\)) \\(H_{0}\\): \\(\\alpha\\)과 \\(\\beta\\)변수의 상호작용 효과가 없다. (\\(\\alpha\\beta_{1}=\\alpha\\beta_{2}=...=\\alpha\\beta_{(a-1)(b-1)}=0\\)) 대립가설(H1) : Not H0 \\(H_{1}\\): \\(\\alpha\\)변수에 따른 종속변수의 값(반응값)에는 차이가 있다. \\(H_{1}\\): \\(\\beta\\)변수에 따른 종속변수의 값(반응값)에는 차이가 있다. \\(H_{1}\\): \\(\\alpha\\)과 \\(\\beta\\)변수의 상호작용 효과가 없다. 3.4.3.6 R을 활용한 이원배치 분산분석 [함수사용법] aov(formula, data) 두 개의 독립변수들 간의 상호작용효과를 시각화하기 위해서 interaction.plot 함수를 사용하여 상호작용효과 그래프를 그릴 수 있다. interaction.plot(x.factor, trace.factor, response) Q. mtcars 데이터는 32개의 차종에 대한 다양한 특성과 단위 연료당 주행거리를 담고 있다. am 변수는 변속기 종류이며, cyl변수는 실린더의 개수를 의미한다. 데이터를 분석에 적절한 형태로 전처리한 후, 변속기 종류와 실린더의 개수에 따라 주행거리 평균에 유의미한 차이가 존재하는지 이원 분산분석을 수행하고, 그 결과를 해석해 보자. 검정을 수행하기에 앞서 설정할 수 있는 가설은 아래와 같다. 주효과 검정에 대한 가설 귀무가설: 실린더 개수에 따른 주행거리의 차이는 존재하지 않는다. 대립가설: 실린더 개수에 따른 주행거리의 차이는 존재한다. 귀무가설: 변속기 종류에 따른 주행거리의 차이는 존재하지 않는다. 대립가설: 변속기 종류에 따른 주행거리의 차이는 존재한다. 상호작용효과 검정에 대한 가설 귀무가설: 변속기 종류와 실린더 개수 간에는 상호작용 효과가 없다. 대립가설: 변속기 종류와 실린더 개수 간에는 상호작용 효과가 있다. 1) 데이터 확인 및 전처리 data(&quot;mtcars&quot;) str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... # aov 함수를 사용하기 위해 독립변수인 cyl, am을 팩터형으로 변환 mtcars$cyl&lt;-as.factor(mtcars$cyl) mtcars$am&lt;-as.factor(mtcars$am) # cyl, am, mpg 변수들로만 구성된 분석용 데이터셋 생성 car&lt;-mtcars[,c(&quot;cyl&quot;, &quot;am&quot;, &quot;mpg&quot;)] str(car) ## &#39;data.frame&#39;: 32 obs. of 3 variables: ## $ cyl: Factor w/ 3 levels &quot;4&quot;,&quot;6&quot;,&quot;8&quot;: 2 2 1 2 3 2 3 1 1 2 ... ## $ am : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 1 1 1 1 1 1 1 ... ## $ mpg: num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... 2) 분산분석 수행 # 분산분석 수행 car_aov&lt;-aov(mpg~cyl*am, car) summary(car_aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## cyl 2 824.8 412.4 44.852 3.73e-09 *** ## am 1 36.8 36.8 3.999 0.0561 . ## cyl:am 2 25.4 12.7 1.383 0.2686 ## Residuals 26 239.1 9.2 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 cyl 변수에 대한 p-value는 0.05보다 작으므로, 주효과 검정에서 ’실린더 개수에 따른 주행거리 평균간 차이는 존재하지 않는다’는 귀무가설을 기각한다. 따라서 실린더 개수에 따라 주행거리간 유의미한 차이는 존재한다고 해석할 수 있다. am 변수에 대한 p-value는 0.0561로 0.05보다 크므로, 주효과 검정에서 ’변속기 종류에 따른 주행거리 평균간 차이는 존재하지 않는다’는 귀무가설을 기각하지 않는다. cyl 변수와 am 변수간의 상호작용효과에 대한 검정결과, p-value는 0.2686으로 0.05보다 크므로 귀무가설을 기각하지 않는다. 따라서 실린더 개수와 변속기 종류 간에는 교호작용이 존재하지 않는다는 것을 알 수 있다. Q. 실린더 개수와 변속기 종류 사이에 상호작용 효과가 있는지 없는지를 시각화 해주는 상호작용 그래프를 그린 후 이를 해석해 보자. interaction.plot(car$cyl, car$am, car$mpg, col=c(&quot;red&quot;, &quot;blue&quot;)) 일반적으로 상호작용 그래프에서 두 선이 서로 교차하고 있을 시에는 x축에 있는 독립변수와 그래프에서 시각화된 독립변수 간에는 상호작용이 존재한다고 해설할 수 있다. 3.5 상관분석 3.5.1 상관분석 개념 3.5.1.1 상관분석 상관분석이란 두 변수 간 관계의 정도를 알아보기 위한 분석방법이다. 상관계수는 데이터간 상관관계가 얼마나 강한지를 수치화한 값으로 두 변수 간 관련성의 정도를 의미한다. 상관계수 값이 클수록 데이터 간의 관계가 존재한다는 의미를 가진다. 하지만 상관계수가 크다고 변수간 인과관계가 존재하는 것은 아니다. 상관계수를 계산하는 방법으로는 피어슨 상관계수, 스피어만 상관계수, 켄달의 순위 상관계수 등이 있으며, 일반적으로 피어슨 상관계수를 가장 많이 사용한다. 3.5.1.2 공분산과 상관계수 공분산은 두 확률변수가 함께 변화하는지의 정도를 측정하는 값으로, 양의 상관관계가 존재할 경우 양수값을 가지고, 반대로 음의 상관관계가 존재할 경우 음수값을 가진다. 공분산을 통해 상관성의 경향을 파악할 수는 있지만, 두 변수의 측정 단위 크기에 따라 값이 음의 무한대에서 양의 무한대 사이에 존재하게 되므로 절대적인 상관성의 정도를 파악하기에는 한계가 있다. 따라서 공분산을 두 변수의 표준편차 곱으로 나누어 표준화 시킨 상관계수를 이용해 두 변수간 상관성의 정도를 파악한다. 3.5.1.3 상관계수의 해석 두 변수가 서로 독립이라면 상관계수는 0이나, 상관계수가 0이라고 해서 반드시 두 변수가 독립인 것은 아니다. 3.5.2 상관분석의 유형 3.5.2.1 피어슨 상관계수 피어슨 상관계수는 두 연속형 자료가 모두 정규성을 따른다는 가정하에 선형적 상관관계를 측정하며, 상관계수는 -1부터 1 사이의 값을 가진다. 가장 많이 사용하며, 일반적으로 상관계수는 피어슨 상관계수를 의미한다. 3.5.2.2 스피어만 상관계수 두 변수가 정규성을 만족하지 않는 경우 혹은 변수가 순위 및 순서 형태로 주어지는 경우에 사용한다. 실제 값을 사용하는 대신 데이터에 순위를 매긴 후 그 순위에 대한 상관계수를 산출하는 비모수적 방법이다. -1부터 1사이의 값을 가지며, 피어슨 상관계수와 달리 비선형 관계의 연관성을 파악할 수 있다. 또한 연속형 자료가 아닌 이산형 혹은 순서형 자료에도 적용이 가능하다. 3.5.2.3 켄달의 상관계수 켄달의 순위상관계수는 데이터가 \\((X_{i}, Y_{i})\\)와 같이 순서쌍으로 주어져 있을 때, Xi가 커짐에 따라 Yi도 커질 경우를 부합, Xi가 커짐에 따라 Yi가 작아질 경우를 비부합이라고 본다. 전체 데이터에서 비부합쌍에 대한 부합쌍의 비율로 상관계수를 산출한다. -1에서 1 사이의 값을 가지며, 순위상관계수가 1일 경우 데이터에서 부합쌍의 비율이 100%임을 나타내고 순위상관계수가 -1일 경우 비부합쌍의 비율이 100%임을 나타낸다. 순위상관계수가 0일 경우에는 두 변수 X와 Y는 상관성이 없음을 의미한다. 3.5.3 상관계수 검정 3.5.3.1 상관계수에 대한 검정 귀무가설: 변수1과 변수2 간에는 상관관계가 없다. (상관계수=0) 대립가설: 변수1과 변수2 간에는 상관관계가 없다. (상관계수!=0) 상관계수에 대한 검정 결과로 얻은 p-value 값이 0.05 이하인 경우, 귀무가설을 기각하게 되므로 데이터에서 산출한 상관계수를 활용할 수 있다. 3.5.3.2 R을 이용한 상관분석 [함수 사용법] cor(x, y, method=c(&quot;pearson&quot;,&quot;kendal&quot;,&quot;spearman&quot;),use) 인자 인자값 x y method 상관계수를 계산할 유형 use na값 처리방법 산출한 상관계수에 대한 가설 검정을 수행할 때는 cor.test를 사용한다. cor.test(x, y, alternative=c(&quot;two.sided&quot;, &quot;less&quot;, &quot;greater&quot;), method=c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;)) pairs(x, labels, ...) corrplot(corr, method, ...) Q1. airquality 데이터에서 Ozone, Slar.R, Wind, Temp 만으로 이루어진 데이터프레임 air를 생성하고, 네 가지 변수에 대한 상관계수를 산출해 보자. 단, 모든 변수값에 NA가 없는 데이터들만 이용하여 피어슨, 켄달, 스피어만 상관계수를 모두 산출하자. data(&quot;airquality&quot;) air&lt;-airquality[,c(1:4)] str(air) ## &#39;data.frame&#39;: 153 obs. of 4 variables: ## $ Ozone : int 41 36 12 18 NA 28 23 19 8 NA ... ## $ Solar.R: int 190 118 149 313 NA NA 299 99 19 194 ... ## $ Wind : num 7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ... ## $ Temp : int 67 72 74 62 56 66 65 59 61 69 ... #피어슨 상관계수 cor(air, use=&quot;pairwise.complete.obs&quot;, method=&quot;pearson&quot;) ## Ozone Solar.R Wind Temp ## Ozone 1.0000000 0.34834169 -0.60154653 0.6983603 ## Solar.R 0.3483417 1.00000000 -0.05679167 0.2758403 ## Wind -0.6015465 -0.05679167 1.00000000 -0.4579879 ## Temp 0.6983603 0.27584027 -0.45798788 1.0000000 #켄달 상관계수 cor(air, use=&quot;pairwise.complete.obs&quot;, method=&quot;kendall&quot;) ## Ozone Solar.R Wind Temp ## Ozone 1.0000000 0.2403194214 -0.4283602915 0.5862988 ## Solar.R 0.2403194 1.0000000000 0.0006785596 0.1442337 ## Wind -0.4283603 0.0006785596 1.0000000000 -0.3222418 ## Temp 0.5862988 0.1442336719 -0.3222417514 1.0000000 #스피어만 상관계수 cor(air, use=&quot;pairwise.complete.obs&quot;, method=&quot;spearman&quot;) ## Ozone Solar.R Wind Temp ## Ozone 1.0000000 0.3481864700 -0.5901551241 0.7740430 ## Solar.R 0.3481865 1.0000000000 -0.0009773325 0.2074275 ## Wind -0.5901551 -0.0009773325 1.0000000000 -0.4465408 ## Temp 0.7740430 0.2074275160 -0.4465407773 1.0000000 Temp와 Ozone 변수간 상관계수의 절대값이 가장 큰 것을 확인할 수 있다. Temp와 Ozone 간 피어슨 상관계수는 약 0.698로 두 변수는 양의 상관관계를 갖고 있음을 알 수 있다 . 반면, Solar.R과 Wind 변수간 피어슨 상관계수는 -0.056으로 절대값이 0에 가까워 상관성을 거의 가지고 있지 않음을 알 수 있다. Q2. air 데이터 내의 네 가지 변수 조합별 피어슨 상관계를 그래프로 시각화해 보자. air_cor&lt;-cor(air, use=&quot;pairwise.complete.obs&quot;) air_cor ## Ozone Solar.R Wind Temp ## Ozone 1.0000000 0.34834169 -0.60154653 0.6983603 ## Solar.R 0.3483417 1.00000000 -0.05679167 0.2758403 ## Wind -0.6015465 -0.05679167 1.00000000 -0.4579879 ## Temp 0.6983603 0.27584027 -0.45798788 1.0000000 pairs(air_cor) Q3. air 데이터의 Ozone과 Wind 변수에 대한 상관분석을 실시하고, 피어슨 상관계수에 대한 검정 결과를 해석해 보자. cor.test(air$Ozone, air$Wind, method=&quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: air$Ozone and air$Wind ## t = -8.0401, df = 114, p-value = 9.272e-13 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.7063918 -0.4708713 ## sample estimates: ## cor ## -0.6015465 검정결과 p-value가 9.272e-13 이므로 유의수준 0.05 하에서 귀무가설을 기각한다. Ozone과 Wind 변수간 상관계수는 0이 아니며, 계산된 -0.6015465를 상관계수로 활용할 수 있다. Ozone과 Wind간 상관계수는 음수이므로 둘 중 어느 한 변수값이 증가하면 다른 변수 값은 감소함을 알 수 있다. 절대값은 약 0.6이므로 두 변수는 약한 음의 상관관계를 가지고 있다고 해석할 수 있다. 3.6 회귀분석 3.6.1 회귀분석의 개념 하나 혹은 그 이상의 원인이 결과에 미치는 영향을 추정하여 식으로 표현할 수 있는 통계기법. 변수들 사이의 인과관계를 밝히고 모형을 적합하여 관심있는 변수를 예측하거나 추론하기 위해 사용하는 분석방법이다. 독립변수의 개수가 하나이면 단순선형회귀분석, 독립변수의 개수가 두 개 이상이면 다중선형회귀분석으로 분석할 수 있다. 3.6.1.1 선형회귀분석의 가정 독립변수와 종속변수 간의 선형성: 입력변수와 출력변수의 관계가 선형이어야 한다는 가정. 오차의 등분산성:오차(Error)란 종속변수의 예측값과 실제 관측값 간의 차이를 의미한다. 오차의 등분산성이란 오차의 분산은 독립변수 값과 무관하게 일정해야 한다는 가정이다. 잔차플롯(산점도)을 그렸을 때, 잔차와 독립변수간 아무런 관련성이 없게 점들이 무작위적으로 고르게 분포되어야 등분산성 가정을 만족하게 된다. 오차의 독립성: 오차들은 서로 독립적이라는 가정이다. 즉 예측값의 변화에 따라 오차항이 특정한 패턴을 가져서는 안된다. 오차의 정규성: 오차의 분포가 정규분포를 만족해야함을 의미한다. Q-Q plot, kolmogorov-Smirnov검정, Shapiro-Wilk 검정 등을 활용하여 정규성을 확인한다. 3.6.1.2 그래프를 활용한 선형회귀분석의 가정 검토 3.6.1.3 선형성 3.6.1.4 등분산성 3.6.1.5 정규성 3.6.2 단순선형회귀분석 3.6.2.1 단순선형회귀분석 (다변량 회귀분석) 하나의 독립변수가 종속변수에 미치는 영향을 추정할 수 있는 총계기법 다음과 같은 식으로 표현하며 \\(\\beta_{0}\\)는 절편, \\(\\beta_{1}\\)는 독립변수 \\(x_{1}\\)의 계수, \\(\\epsilon_{1}\\)는 오차를 나타낸다.\\(Y_{i}=\\beta_{0}+\\beta_{1}x_{1}+\\epsilon_{i}\\) 회귀분석은 회귀계수를 찾아 독립변수와 종속변수 사이의 구체적인 함수식을 생성하고, 이 회귀계수가 통계적으로 유의미한지를 파악한다. 또한 통계적으로 유의하다고 판단되는 회귀모형을 이용해 종속변수를 예측할 수 있다. 3.6.2.2 회귀분석시 검토사항 모형 내의 회귀계수가 유의한가? 회귀계수에 대한 t통계량의 p-value가 0.05보다 작으면 해당 회귀계수가 통계적으로 유의하다고 볼 수 있다. 회귀계수의 절대값이 클수록 종속변수에 더욱 큰 영향을 준다. 모형은 데이터를 얼마나 설명할 수 있는가? 결정계수(R2)를 확인한다. 결정계수는 0 ~ 1값을 가지며, 추정된 회귀식이 전체 데이터에서 설명할 수 있는 데이터의 비율을 의미한다. 따라서 높은 값을 가질수록 추정된 회귀식의 설명력이 높다고 할 수 있다. 다변량 회귀분석에서는 포함된 독립변수의 유의성과 가ㅗㄴ계없이 독립변수의 수가 많아지면 결정계수(R2)가 높아진다. 이러한 점을 보완하기 위해 수정된 결정계수(\\(R_{a}^{2}\\): adjusted R2)를 활용하여 모형의 설명력을 판단한다. 회귀모형은 통계적으로 유의한가? 회귀분석의 결과로 산출되는 F-통계량의 p-value가 0.05보다 작으면 해당 회귀식은 통계적으로 유의하다고 볼 수 있다. 모형이 데이터를 잘 적합하고 있는가? 모형의 잔차를 그래프로 그리고, 회귀진단을 수행하여 판단한다. 3.6.2.3 R을 이용한 단순선형회귀분석 [함수 사용법] lm(formula, data) Q. Cars93 데이터의 엔진크기를 독립변수, 가격을 종속변수로 설정하여 단순 선형 회귀분석을 실기한 후, 추정된 회귀모형에 대해 해석해 보자. library(MASS) data(&quot;Cars93&quot;) str(Cars93) ## &#39;data.frame&#39;: 93 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... # 단순선형 회귀모형 생성 (Cars93_lm &lt;- lm(Price~EngineSize, Cars93)) ## ## Call: ## lm(formula = Price ~ EngineSize, data = Cars93) ## ## Coefficients: ## (Intercept) EngineSize ## 4.669 5.563 # 모형 살펴보기: summary() 이용 # summary(): 주어진 인자에 대한 요약 정보 산출 summary(Cars93_lm) ## ## Call: ## lm(formula = Price ~ EngineSize, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.684 -4.627 -1.795 2.592 39.429 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.6692 2.2390 2.085 0.0398 * ## EngineSize 5.5629 0.7828 7.107 2.59e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.789 on 91 degrees of freedom ## Multiple R-squared: 0.3569, Adjusted R-squared: 0.3499 ## F-statistic: 50.51 on 1 and 91 DF, p-value: 2.588e-10 회귀계수 ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.6692 2.2390 2.085 0.0398 * ## EngineSize 5.5629 0.7828 7.107 2.59e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 회귀계수는 Coefficients 항목을 통해 확인할 수 있다. (Intercept)는 상수항을 나타내며, Estimate는 추정된 회귀계수, Std.Error는 표준오차, t value는 t통계량, Pr(&gt;|t|)는 독립변수의 Estimate에 대한 p-value를 의미한다. 회귀분석 결과를 기준으로 엔진크기(EngineSize)와 가격(Price) 사이에는 [Price = 4.669 + 5.5629*EngineSize] 라는 회귀식을 도출할 수 있다. 상수항과 독립변수의 EngineSize의 회귀계수에 대한 p-value가 모두 유의수준 0.05보다 작으므로 통계적으로 유의하다고 판단할 수 있다. 이 검정에 사용되는 귀무가설은 ‘계수(혹은 절편)은 0이다’이며, 대립가설은 ‘계수(혹은 절편)는 0이 아니다’ 이다. 모형의 설명력 ## Residual standard error: 7.789 on 91 degrees of freedom ## Multiple R-squared: 0.3569, Adjusted R-squared: 0.3499 결과의 아래쪽에 제시된 Adjusted R-squared(수정된 결정계수)값을 통해 모형의 설명력을 파악할 수 있다. 수정된 결정계수가 0.3499라는 것은 해당 회귀 모형이 현 데이터의 약 34.99%를 설명할 수 있다는 것을 의미한다. 모형의 통계적 유의성 ## F-statistic: 50.51 on 1 and 91 DF, p-value: 2.588e-10 summary를 수행한 결과의 맨 아래에 있는 F-통계량을 통해 모형의 통계적 유의성을 판단할 수 있다. F-통계량의 p-value 가 2.588e-10로 0.05보다 매우 작기 때문에 추정된 회귀 모형 ’Price = 4.6692 + 5.5629 * EngineSize’는 통계적으로 유의하다고 할 수 있다. 3.6.2.4 R을 이용한 선형회귀모형 진단 plot.lm 함수를 이용하면 생성된 선형회귀모형에 대한 다양한 그래프를 통해 잔차의 분포를 파악하고 모형을 평가할 수 있다. [함수 사용법] plot.lm(x, which) Q. 위 예제에서 생성한 선형회귀모델 Cars93_lm을 평가할 수 있는 다양한 그래프를 생성한 후 해석해 보자. par(mfrow=c(2,3)) plot(Cars93_lm, which=c(1:6)) Residuals vs Fitted : Residuals vs Fitted 그래프에서 x축은 회귀모형을 통해 예측된 y값이며, y축은 잔차를 나타낸다. 선형회귀모형은 오차가 정규분포를 따른다는 정규성을 가정하므로, 이 그래프에서 오차의 분포는 기울기가 0인 직선의 형태를 가지는 것이 이상적이다. Normal Q-Q : Normal Q-Q plot은 표준화된 잔차의 확률도이다. 정규성 가정을 만족한다면 그래프의 점들은 45도 각도의 직선을 이루는 형태를 띄어야 한다. Scale-Location : Scale-Location plot에서 x축은 회귀모형을 통해 예측된 y값이며, y축은 표준화 잔차를 나타낸다. 첫번째 그래프와 마찬가지로 기울기가 0인 직선의 형태가 관측되는 것이 이상적이다. 해당 직선에서 멀리 떨어진 점이 있다면, 그 지점에서 회귀모형이 y값을 잘 예측하지 못함을 나타낸다. 또한 이 점은 이상치일 가능성이 있다. Cook’s distance : Cook’s distance plot의 x축은 관측값을 순서대로 나열한 것이며, y축은 해당 지점의 쿡의 거리를 나타낸다. 쿡의 거리는 한 관측치가 회귀모형에 미치는 영향을 나타내는 측도이며, 일반적으로 1이상일 경우 매우 큰 영향을 주는 관측값으로 간주한다. Residuals vs Leverage : Residuals vs Leverage의 x축은 레버리지, y축은 표준화 잔차값을 나타낸다. 레버리지란 관측치가 다른 관측치 집단으로부터 떨어진 정도를 나타내며 설명변수가 얼마나 극단에 치우쳐 있는지를 보여준다. 쿡의 거리가 0.5 이상인 빨간 점선의 밖에 있는 점은 예측치를 크게 벗어난 관측치이다. Cook’s dist vs Leverage : 해당 그래프의 x축은 레버리지, y축은 쿡의 거리를 나타낸다. 레버리지와 쿡의 거리는 비례하는 관계에 있다. 3.6.2.5 선형회귀모형을 활용한 예측 생성한 회귀모형에 새로운 독립변수 값을 입력하여 종속변수 값을 예측할 수 있다. 이 때 예측의 방법에는 점추정과 구간추정의 두가지 방법을 사용한다. 점추정이란 특정한 값 하나로 종속변수 값을 예측하는 것이다. 따라서 예측값의 불확실성은 고려되지 않으며, 예측가능성이 가장 높은 단일값을 제시한다. 구간추정이란 불확실성을 고려하여 단일값이 아닌 범위값으로 종속변수를 예측하는 것이다. 구간추정에서는 회귀식의 계수에 대한 불확실성과 회귀식을 통해 도출된 값의 오차로 인한 불확실성을 고려하여 결과값을 예측한다. [함수사용법] predict.lm(object, newdata, interval=c(&quot;none&quot;,&quot;confidence&quot;,&quot;prediction&quot;), level) Q. Cars93 데이터의 엔진크기를 독립변수, 가격를 종속변수로 설정하여 회귀모형을 생성한 후, Cars93 데이터이ㅡ 5개 행을 랜덤으로 봅아 가격(Price)를 예측해보자. 예측시 predict 함수의 interval 인자값을 조정하여 그 결과를 비교해보자. # 회귀모형 생성 Cars93_lm &lt;- lm(Price~EngineSize, Cars93) # 실습을 위해 시드값 설정 set.seed(1234) # Cars93 데이터에서 랜덤으로 5개의 행번호를 추출하여 idx변수에 저장 (idx &lt;- sample(1:nrow(Cars93),5)) ## [1] 28 80 22 9 5 # 예측에 사용할 데이터셋 구성 test &lt;- Cars93[idx,] # 예측 수행1 (점추정) predict.lm(Cars93_lm, test, interval=&quot;none&quot;) ## 28 80 22 9 5 ## 21.35801 11.34472 23.02689 25.80836 24.13948 predict.lm 함수에서 interval 인자의 값을 “none”으로 지정하여 자동차의 가격을 예측하면 점추정을 수행해 단일값이 산출되는 것을 확인할 수 있다. # 예측 수행2 (회귀계수의 불확실성을 감안한 구간추정) predict.lm(Cars93_lm, test, interval=&quot;confidence&quot;) ## fit lwr upr ## 28 21.35801 19.672604 23.04341 ## 80 11.34472 8.555107 14.13433 ## 22 23.02689 21.145364 24.90842 ## 9 25.80836 23.426530 28.19019 ## 5 24.13948 22.078345 26.20061 interval의 인자값을 “confidence”로 지정하여 자동차의 가격을 예측한 결과를 살펴보자. fit은 점추정한 값이며 lwr은 구간의 최소값, upr은 구간의 최대값이다. 예를 들어 28번행의 자동차 가격 예측값은 21.35801 이며, 19.672604 ~ 23.04341 사이일 확률은 95%라고 해석할 수 있다. predict.lm(Cars93_lm, test, interval=&quot;prediction&quot;) ## fit lwr upr ## 28 21.35801 5.795423 36.92060 ## 80 11.34472 -4.375825 27.06526 ## 22 23.02689 7.441846 38.61194 ## 9 25.80836 10.155035 41.46169 ## 5 24.13948 8.531732 39.74723 마지막으로 interval 인자의 값을 “prediction”으로 설정하면 회귀계수의 불확실서오가 오차항을 함께 감안하여 자동차의 가격을 예측한다. 결과값에 대한 오차까지 감안했기 때문에 interval을 “confidence”로 설정했을 때보다 더 넓은 구간으로 자동차 가격을 예측한다. 3.6.3 다중선형회귀분석 (다변량 회귀분석) 다중선형회귀분석은 2개 이상의 독립변수가 종속변수에 미치는 영향을 추정하는 통계기법이다. 다중선형회귀분석은 중선형회귀분석 혹은 다변량 회귀분석이라고도 한다. 3.6.3.1 다중선형회귀분석 시 검토사항 데이터가 전제하는 가정을 만족시키는가? 회귀분석을 수행하고자 하는 데이터의 독립변수와 종속변수간 선형성, 오차의 독립성/등분산성/정규성 등을 만족하고 있는지 확인해야 한다. 모형 내의 회귀계수가 유의한가? 단변량 회귀분석에서 회귀계수의 유의성 검토와 마찬가지로 회귀계수에 대한 t통계량의 p-value값이 0.05보다 작으면 해당 회귀 계수가 통계적으로 유의하다고 볼 수 있다. 단, 다중회귀분석을 할 때는 모든 회귀계수가 유의한지를 검정한 후 해당 회귀식을 해석해야 한다. 회귀계수 절대값이 클수록 종속변수에 더 큰 영향을 주므로, 회귀분석 결과를 통해 여러 변수중 어떤 독립변수가 종속변수에 대한 영향력이 큰지를 파악할 수 있다. 모형은 데이터를 얼마나 설명할 수 있는가? 결정계수(R2) 혹은 수정된 결정계수(\\(R_{a}^{2}\\): adjusted R2)를 확인한다. 회귀모형은 통계적으로 유의한가? 회귀분석의 결과로 산출되는 F-통계량의 p-value 값이 0.05보다 작으면 해당 회귀식은 통계적으로 유의하다고 볼 수 있다. 5. 모형이 데이터를 잘 적합하고 있는가? 모형의 잔차와 종속변수에 대한 산점도를 그리고, 회귀진단을 수행하여 판단한다. 다중공선성 다중공선성은 회귀분석에서 독립변수들 간에 강한 상관관관계가 나타나는 문제이다. 이러한 다중공선성의 문제가 존재하면 정확한 회귀계수의 추정이 곤란하다. 따라서 독립변수들 간 상관관계가 있는지를 파악한 후, 다중공선성의 문제가 발생하면 문제가 있는 변수를 제거하거나 주성분회귀, 능형회귀모형 등을 적용하여 문제를 해결한다. 다중공선성을 검사하는 방법은 아래와 같다. 독립변수들 간의 상관계수를 구하여 상관성을 직접 파악 허용오차를 구했을 때 0.1이하이면 다중공선성 문제가 심각하다고 할 수 있다. 호용오차란 한 독립변수의 분산 중 다른 독립변수들에 의해서 설명되지 않는 부분을 의미하므로, 그 값이 작을수록 공선성은 높다고 볼 수 있다. 또한 허용오차는 0 ~ 1 사이의 값을 가진다. (허용오차=(1-\\(R_{i}^{2}\\)),\\(R_{i}^{2}\\)) 3.6.3.2 더미변수 3.6.3.2.1 범주형 변수 변환 3.6.3.2.2 lm함수의 범주형 변수 처리 iris_lm&lt;-lm(Petal.Length~Sepal.Length+Sepal.Width+Petal.Width+Species, iris) summary(iris_lm) ## ## Call: ## lm(formula = Petal.Length ~ Sepal.Length + Sepal.Width + Petal.Width + ## Species, data = iris) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.78396 -0.15708 0.00193 0.14730 0.65418 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.11099 0.26987 -4.117 6.45e-05 *** ## Sepal.Length 0.60801 0.05024 12.101 &lt; 2e-16 *** ## Sepal.Width -0.18052 0.08036 -2.246 0.0262 * ## Petal.Width 0.60222 0.12144 4.959 1.97e-06 *** ## Speciesversicolor 1.46337 0.17345 8.437 3.14e-14 *** ## Speciesvirginica 1.97422 0.24480 8.065 2.60e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2627 on 144 degrees of freedom ## Multiple R-squared: 0.9786, Adjusted R-squared: 0.9778 ## F-statistic: 1317 on 5 and 144 DF, p-value: &lt; 2.2e-16 Species 변수는 setosa, versicolor, verginica의 세가지 범주로 이루어져 있는 범주형 변수이다. summary 결과 중 Coefficients를 살펴본 바, Species 변수의 setosa 범주값을 기준으로 더미변수화가 수행되어 Species 변수가 Speciesversicolor와 Speciesverginica로 변환된 것을 살펴볼 수 있다. 회귀분석 결과 도출된 회귀식은 아래와 같다. Petal.Length = -1.11099 + 0.60801*Sepal.Length - 0.18052*Sepal.Width + 0.60222*Petal.Width + 1.46337*Speciesversicolor + 1.97422*Speciesverginica 3.6.3.3 R을 이용한 다중선형회귀분석 [함수 사용법] lm(formula, data) Q. Cars93 데이터에서 엔진크기, RPM, 무게를 독립변수로 설정하고 자동차 가격을 종속변수로 설정하여 다변량 회귀분석을 수행한 뒤 그 결과를 해석해 보자. library(MASS) str(Cars93) ## &#39;data.frame&#39;: 93 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... Price_lm&lt;-lm(Price~EngineSize+RPM+Weight, Cars93) summary(Price_lm) ## ## Call: ## lm(formula = Price ~ EngineSize + RPM + Weight, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.511 -3.806 -0.300 1.447 35.255 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -51.793292 9.106309 -5.688 1.62e-07 *** ## EngineSize 4.305387 1.324961 3.249 0.00163 ** ## RPM 0.007096 0.001363 5.208 1.22e-06 *** ## Weight 0.007271 0.002157 3.372 0.00111 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.504 on 89 degrees of freedom ## Multiple R-squared: 0.5614, Adjusted R-squared: 0.5467 ## F-statistic: 37.98 on 3 and 89 DF, p-value: 6.746e-16 1) 회귀모형의 포뮬러 ## Call: ## lm(formula = Price ~ EngineSize + RPM + Weight, data = Cars93) formula 부분에서 ~의 왼쪽에 있는 ‘Price’ 변수가 종속변수이고, ~의 오른쪽에 있는 ‘EnginSize’, ‘RPM’, ‘Weight’ 변수들이 독립변수에 해당한다. 또한 분석용 데이터는 Cars93임을 알 수 있다. 2) 회귀계수 ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -51.793292 9.106309 -5.688 1.62e-07 *** ## EngineSize 4.305387 1.324961 3.249 0.00163 ** ## RPM 0.007096 0.001363 5.208 1.22e-06 *** ## Weight 0.007271 0.002157 3.372 0.00111 ** Coefficients 항목을 통해 회귀계수를 확인해 본 결과, 상수항을 포함한 모든 회귀계수의 p-value 값이 0.05 보다 작은 것을 확인할 수 있다. 따라서 상수항과 세 변수에 대한 회귀계수는 모두 통계적으로 유의하다. 회귀분석 결과로 추정된 회귀식은 [Price = -51.793292 + 4.305387 * EngineSize + 0.007096 * RPM + 0.007271 * Weight] 이다. 3) 모형의 설명력 ## Residual standard error: 6.504 on 89 degrees of freedom ## Multiple R-squared: 0.5614, Adjusted R-squared: 0.5467 수정된 결정계수는 0.5467이므로 회귀모형이 전체 데이터의 약 54.67%를 설명할 수 있다. 수정된 결정계수 값이 조금 낮게 나타났기 때문에 해당 회귀식이 데이터를 적절하게 설명하고 있다고는 할 수 없다. 4) 모형의 통계적 유의성 ## F-statistic: 37.98 on 3 and 89 DF, p-value: 6.746e-16 F-통계량은 37.98이며, 유의확률이 6.746e-16이므로 유의수준 0.05 하에서 추정된 회귀모형이 통계적으로 매우 유의함을 알 수 있다. 결정계수가 낮기 때문에 모형이 데이터에 대해 가지는 설명력은 낮지만 회귀분석 결과에서 회귀계수들이 통계적으로 유의하므로, 자동차의 가격을 엔진크기와 RPM 그리고 무게로 추정할 수 있다. 3.6.3.4 최적화회귀방정식의 선택 모형 내 설명변수의 수가 증가할수록 데이터 관리에는 많은 노력이 요구된다. 따라서 상황에 따라 종속변수에 영향을 미치는 유의미한 독립변수들을 선택하여 최적의 회귀방정식을 도출하는 과정이 필요하다. 변수를 선택할 때는 F-통계량이나 AIC와 같은 특정 기준을 근거로 변수를 제거하거나 선택한다. F-통계량의 유의확률이 유의수준보다 큰 변수는 통계적으로 유의하지 않으므로 제거해야 하고, AIC와 같은 벌점화 기준을 가장 낮게 만드는 변수 조합을 선택해야 한다. 단계적 변수선택 (Stepwise Variable Selection) 전진 선택법: 절편만 있는 상수모형에서 시작하여 중요하다고 생각되는 설명변수부터 차례로 모형에 추가한다. 후진 제거법: 모든 독립변수를 포함한 모옇에서 출발하여 종속변수에 가장 적은 영향을 주는 변수부터 하나씩 제거하면서 더 이상 제거할 변수가 없을 때의 모형을 선택한다. 단계적 방법: 전진선택법에 의해 변수를 추가하면서 벌점화된 선택기준 3.6.3.5 R을 이용한 변수선택법 1) 패키지 로드 및 다중회귀모형 생성 library(MASS) summary(lm_a &lt;- lm(Price ~ EngineSize + RPM + Width + Length, Cars93)) ## ## Call: ## lm(formula = Price ~ EngineSize + RPM + Width + Length, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.756 -4.239 -0.497 2.534 35.598 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -20.151609 26.264641 -0.767 0.445 ## EngineSize 8.380637 1.445736 5.797 1.04e-07 *** ## RPM 0.007139 0.001445 4.942 3.65e-06 *** ## Width -0.654923 0.433125 -1.512 0.134 ## Length 0.136676 0.088223 1.549 0.125 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.823 on 88 degrees of freedom ## Multiple R-squared: 0.5227, Adjusted R-squared: 0.501 ## F-statistic: 24.1 on 4 and 88 DF, p-value: 1.762e-13 summary의 결과에서 모형의 유의성을 판단하기 위해 F-통계량을 확인한 결과, 유의확률이 1.762e-13이므로 생성된 회귀모형은 통계적으로 유의함을 확인할 수 있다. 하지만 입력변수들의 통계적 유의성을 검토해 본 결과, Width와 Length 변수의 회귀계수에 대한 유의확률이 0.05보다 큰 것을 확인할 수 있다. 적절한 모형을 선정하기 위해 유의확률이 가장 높은 Width 변수를 제외하고 다시 회귀모형을 생성해 lm_b에 저장해 보자. 2) 유의확률이 가장 높은 변수 Width를 제거하고 회귀모형(lm_b)을 다시 생성 summary(lm_b &lt;- lm(Price ~ EngineSize + RPM + Length, Cars93)) ## ## Call: ## lm(formula = Price ~ EngineSize + RPM + Length, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.478 -4.269 -0.378 2.004 36.681 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -52.601153 15.251540 -3.449 0.000862 *** ## EngineSize 7.110311 1.185062 6.000 4.18e-08 *** ## RPM 0.007492 0.001436 5.218 1.17e-06 *** ## Length 0.074112 0.078480 0.944 0.347549 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.872 on 89 degrees of freedom ## Multiple R-squared: 0.5103, Adjusted R-squared: 0.4938 ## F-statistic: 30.92 on 3 and 89 DF, p-value: 8.699e-14 Width 변수가 제거된 모형의 유의성을 검토한 결과, F-통계량에 대한 유의확률은 8.699e-14으로 유의하게 나타났다. 모든 변수들의 t통계량에 대한 유의확률이 0.05보다 낮아야 하지만 Length 변수의 유의확률이 0.05보다 높게 나타나 유의하지 않은 결과를 보인다. 따라서 유의확률이 가장 높은 Length 변수를 제외한 회귀모형(lm_c)을 다시 생성해 보자. 3) 유의확률이 가장 높은 변수 Length를 제거하고 회귀모형(lm_c)을 다시 생성 summary(lm_c&lt;-lm(Price ~ EngineSize + RPM, Cars93)) ## ## Call: ## lm(formula = Price ~ EngineSize + RPM, data = Cars93) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.636 -4.085 -0.946 1.645 36.543 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -40.977171 9.000017 -4.553 1.65e-05 *** ## EngineSize 7.913115 0.825140 9.590 2.03e-15 *** ## RPM 0.007457 0.001434 5.198 1.25e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.868 on 90 degrees of freedom ## Multiple R-squared: 0.5054, Adjusted R-squared: 0.4944 ## F-statistic: 45.99 on 2 and 90 DF, p-value: 1.74e-14 F-통계량을 확인한 결과 유의수준 0.05 하에서 모형이 통계적으로 유의함을 확인할 수 있다. 또한 다변량회귀식에 최종 선정된 EngineSize, RPM 변수에 대한 각각의 유의확률 값이 모두 통계적으로 유의하게 나타났다 .수정된 결정계수는 0.4944로 적합된 회귀식이 전체 데이터를 잘 설명하고 있다고 말하기는 힘들다. 회귀계수에 대한 유의확률을 기반으로 후진제거법을 수행하여 얻게된 회귀식은 Price = -40.977171 + 7.913115 * EngineSize + 0.007457 * RPM 이다. [함수 사용법] step(object, scope, direction, k) 인자 설명 object 변수선택을 진행할 회귀모형 scope 변수선택 과정에서 사용되는 모형의 범위list 내부에 모형의 상한은 upper, 하한은 lower에 지정 direction 변수선택 방법을 지정forward:전진선택법,backward:후진제거법,stepwise:단계적선택법 k 모형선택기준으로 AIC, BIC 등을 사용할지를 지정k=2: 모형선택기준으로 AIC 사용k=log(자료의수):모형 선택 기준으로 BIC 사용 Q. Cars93 데이터에서 엔진크기, 마력, RPM, 너비, 길이, 무게를 독립변수로 가지고, 자동차의 가격을 종속변수로 가지는 선형회귀모형을 생성해보자. 그 후 step 함수를 사용해 ’후진제거법’으로 변수 선택을 수행한 후 결과를 해석해 보자. lm_result&lt;-lm(Price~EngineSize+Horsepower+RPM+Width+Length+Weight, Cars93) step(lm_result, direction=&quot;backward&quot;) ## Start: AIC=322.11 ## Price ~ EngineSize + Horsepower + RPM + Width + Length + Weight ## ## Df Sum of Sq RSS AIC ## - EngineSize 1 1.69 2556.1 320.17 ## - RPM 1 19.71 2574.1 320.82 ## &lt;none&gt; 2554.4 322.11 ## - Length 1 119.55 2674.0 324.36 ## - Weight 1 209.73 2764.2 327.45 ## - Width 1 585.01 3139.4 339.29 ## - Horsepower 1 720.84 3275.3 343.22 ## ## Step: AIC=320.17 ## Price ~ Horsepower + RPM + Width + Length + Weight ## ## Df Sum of Sq RSS AIC ## - RPM 1 49.36 2605.5 319.95 ## &lt;none&gt; 2556.1 320.17 ## - Length 1 140.92 2697.0 323.16 ## - Weight 1 208.09 2764.2 325.45 ## - Width 1 593.56 3149.7 337.59 ## - Horsepower 1 1476.65 4032.8 360.57 ## ## Step: AIC=319.95 ## Price ~ Horsepower + Width + Length + Weight ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 2605.5 319.95 ## - Length 1 132.02 2737.5 322.54 ## - Weight 1 279.31 2884.8 327.42 ## - Width 1 562.10 3167.6 336.12 ## - Horsepower 1 1898.74 4504.2 368.86 ## ## Call: ## lm(formula = Price ~ Horsepower + Width + Length + Weight, data = Cars93) ## ## Coefficients: ## (Intercept) Horsepower Width Length Weight ## 53.005861 0.129653 -1.480623 0.152968 0.007339 후진제거법은 모든 독립변수가 포함된 모형에서 시작하여 유의미하지 않은 변수들을 차례로 제거한다. Start 단계를 살펴보면 EngineSize 변수가 제거되었을 때 AIC 값이 가장 낮아짐을 확인할 수 있다. AIC값은 작을수록 더 좋은 모델임을 뜻하므로 첫번째 단계에서는 EngineSize 변수가 제거된 모형이 선택되었다. 다음 단계에서 RPM 변수가 제거되었을 경우 AIC값이 319.95로 가장 낮아지는 것을 볼 수 있다. 따라서 RPM 변수가 제거된 모형이 선택되었다. 이후에는 모형에 아무런 변화가 없을때(none) AIC 값이 가장 작다. 따라서 변수선택을 중단하고, 최종적으로 EngineSize와 RPM 변수가 제거된 Price ~ Horsepower + Width + Length + Weight 형태의 포뮬러가 회귀모형으로 선택되었다. 적합된 회귀식은 Price = 53.005861 + 0.129653 * Horsepower = 1.480623 * Width + 0.152968 * Length + 0.007339 * Weight 이다. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
